<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.42">

  <meta name="author" content="Alexia Schneider alexia.schneider@umontreal.ca (UdeM), Clara Grometto clara.grometto@umontreal.ca (UdeM)">
  <meta name="dcterms.date" content="2025-10-09">
  <title>Atelier IA - La Correction automatique</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-2f366650f320edcfcf53d73c80250a32.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Atelier IA - La Correction automatique</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Alexia Schneider <code>alexia.schneider@umontreal.ca</code> (UdeM), Clara Grometto <code>clara.grometto@umontreal.ca</code> (UdeM) 
</div>
</div>
</div>

  <p class="date">2025-10-09</p>
</section>
<section id="plan-de-latelier" class="slide level2 scrollable">
<h2>Plan de l’atelier</h2>
<p>Théorie :</p>
<ol type="1">
<li>Rappels sur les fondements de l’IA</li>
<li>Problématique et annonce du plan</li>
<li>Mise en perspective</li>
<li>Définition</li>
<li>Présentation historico-technique des systèmes de GEC</li>
<li>Changement de paradigme : de l’ortho-typo à la reformulation voire la génération de contenu</li>
<li>Enjeux/conséquence (questions) <!-- - gain de temps 
    - uniformisation de la langue
    - système de valeurs 
    - influence de la machine --></li>
<li>Présentation des outils</li>
<li>conclusion/ce qu’il faut retenir (5min)</li>
</ol>
</section>
<section>
<section id="introduction" class="title-slide slide level1 center">
<h1>Introduction</h1>

</section>
<section id="présentation-et-objectif-des-ateliers" class="slide level2">
<h2>Présentation et objectif des ateliers</h2>
<p>Format : 4 séances de 2 heures, sans inscription, participation libre (à justifier pour le certificat des Humanités Numériques)</p>
<p>Théorie et pratique.</p>
<p>Objectifs de la série d’atelier :</p>
<ul>
<li>Comprendre les fondamentaux de l’IA et son histoire</li>
<li>Obtenir des notions critiques sur le fonctionnement profond des outils</li>
<li>Tester et s’approprier des outils d’IA</li>
<li>Maîtriser le vocabulaire de la discipline</li>
</ul>
<p>Objectifs de cet atelier :</p>
<ul>
<li>Cerner un cas d’usage courant des IA génératives : la correction ortho-typographique.</li>
<li>Contextualiser la correction (automatique)</li>
<li>S’interroger sur l’impact de ces nouvelles pratiques dans le travail de recherche.<br>
</li>
<li>Définir des critères pour effectuer un choix éclairé vis-à-vis des outils disponibles.</li>
</ul>
</section>
<section id="certificat-canadien-en-humanités-numériques" class="slide level2">
<h2>Certificat canadien en Humanités Numériques</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Certificat canadien en HN</figcaption>
<p><img data-src="../seances/img/ccdhn1.png"></p>
</figure>
</div>
<p><img data-src="../seances/img/ccdhn2.png" alt="Certificat canadien en HN"> <img data-src="../seances/img/ccdhn3.png" alt="Certificat canadien en HN"></p>
<p><a href="https://ccdhhn.ca/">Information sur le certificat</a></p>
</section>
<section id="ia-et-révision" class="slide level2">
<h2>IA et révision <!--slide d'intro générale--></h2>
<p>En quoi les outils d’aide à la rédaction basés sur l’IA transforme-t-ils le rapport des chercheur·euses à leur texte, au processus d’écriture et aux ?</p>
<p>Nous aborderons :</p>
<ul>
<li>l’histoire et la pratique de la correction éditoriale,</li>
<li>le basculement technique (du savoir-faire de l’ortho-typo à la reformulation automatisée),</li>
<li>les enjeux épistémologiques (déprise du texte),</li>
<li>et les enjeux sociolinguistiques/politiques (normalisation implicite, effacement des variations, standardisation de la langue académique).</li>
</ul>
</section></section>
<section>
<section id="les-fondamentaux-rappels-de-lintroduction" class="title-slide slide level1 center">
<h1>Les fondamentaux : rappels de l’introduction</h1>

</section>
<section id="quest-ce-que-lia" class="slide level2">
<h2>Qu’est ce que l’IA ?</h2>
<p>Des programmes informatiques que nous estimons à la hauteur de l’intelligence humaine ? Le développement des technologies fait évoluer cette définition de l’<em>intelligence</em> non seulement <em>artificielle</em> mais aussi <em>humaine</em>.</p>
<p>‘IA’ depuis 5 ans, a remplacé le ‘numérique’ des années 2010, et le ‘cyberespace’ des années 1990 et 2000.<span class="citation" data-cites="vitali-rosatiManifestePourEtudes2025a">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Vitali-Rosati 2025</a>)</span>.</p>
<p>Définition pratique pour ces ateliers: “un programme informatique qui effectue une prédiction.”</p>
</section>
<section id="rappels-de-lintroduction" class="slide level2">
<h2>Rappels de l’introduction</h2>
<ul>
<li>Les programmes d’IA réfèrent à des processus algorithmiques variés et pas seulement à des chatbots type ChatGPT.</li>
<li>L’IA est une discipline qui a plus de 75 ans (terme de 1956).</li>
<li><span class="citation" data-cites="turingComputingMachineryIntelligence1950">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Turing 1950</a>)</span> a orienté la discipline vers un modèle ‘chatbot’. <!-- ici expliquer Turing :  l'article Computing machinery intelligence a orienté la discipline vers une définition étroite de l'intelligence humaine comme intelligence sociale, ou capacité à feindre un échange social comme preuve d'humanité --></li>
<li>Les ‘saisons de l’IA’ suivent des phases d’approbation publique et de désintérêt pour le terme et les technologies qu’on place sous ce terme.</li>
<li>Ce qu’on fait entrer dans la catégorie d’“intelligent” a changé : le calcul savant est-il moins intelligent que le bavardage ?</li>
</ul>
</section>
<section id="rappels-historiques-sur-lia" class="slide level2">
<h2>Rappels historiques sur l’IA</h2>
<ul>
<li>Deux grandes approches en IA : une approche déductive (IA symbolique, système expert) vs.&nbsp;approche inductive (IA connexionniste, modèle de langue).</li>
<li>Un système expert peut être aussi complexe et énergivore qu’un LLM.</li>
<li>Un LLM (<em>large language model</em>) est la modélisation sous forme de vecteurs de chaque élément d’un grand corpus (<em>token</em> ~mot) par rapport à cet ensemble.</li>
</ul>
<p><a href="https://demo-atelier.streamlit.app/">Démo visuelle</a></p>
</section>
<section id="les-llms-en-contexte" class="slide level2">
<h2>Les LLMs en contexte</h2>
<ul>
<li>Pour les LLMs, la ‘compréhension’ du monde n’est basée sur aucun référent ou aucune règle définie : les réponses sont probabilistes.</li>
<li>Les hallucinations ne sont pas des anomalies, ce sont des erreurs que l’on qualifie a posteriori comme telle.</li>
<li>Après l’apprentissage de son corpus d’entrainement, une étape de <em>reinforcement learning</em> donne une saveur ou personnalité à un modèle.</li>
<li>Les LLMs reflètent les intérêts économiques de leurs concepteurices: nature ‘sycophantique’ avérée.</li>
<li>On peut influencer le calcul de probabilité d’un modèle (température, top-k, seed) et donc sa personnalité (déterministe vs.&nbsp;créatif).</li>
<li>On peut aussi ‘orienter’ le comportement d’un modèle avec un <em>system prompt</em>.<br>
</li>
<li>Chatbots = interfaces en langue naturelle : l’exploitation des capacités inductives d’un LLMs ne nécessite pas de passer par une telle interface. Ex : classification avec de l’apprentissage machine (<em>machine learning</em>).</li>
</ul>
</section></section>
<section>
<section id="mise-en-perspective" class="title-slide slide level1 center">
<h1>Mise en perspective <!--slide d'intro partie 1--></h1>
<div style="color: green;">
<p><em>C’est quoi la correction / révision ?</em></p>
<p><em>Historique technique des outils</em> <!--titre à changer--></p>
</div>
</section>
<section id="essayons-de-définir" class="slide level2">
<h2>Essayons de définir…</h2>
<p><strong>D’après le TLFi → CORRECTEUR, TRICE, subst. et adj.</strong></p>
<blockquote>
<p>Homme, femme qui s’arroge ou à qui est dévolu le rôle de corriger des défauts, de rectifier des erreurs sans pour autant infliger de punition corporelle.</p>
</blockquote>
<blockquote>
<p>TYPOGR. Ouvrier spécialisé qui, dans une imprimerie, est chargé de lire et de corriger les épreuves. <em>Les correcteurs ont deux maladies, les majuscules et les virgules, deux détails qui défigurent ou coupent le vers</em> (HUGO, Corresp., 1859, p.&nbsp;298).</p>
</blockquote>
<blockquote>
<p>Rem. 1. a) D’après la fonction, on distingue du correcteur qui révise les épreuves d’un journal le correcteur de labeur qui révise celles d’un ouvrage. b) D’après la hiérarchie on distingue les correcteurs en première (première épreuve), les correcteurs en second (ou en bon à tirer), les correcteurs en tierce (après la mise sous presse). 2. “Le correcteur femme existe aussi; mais <strong>cette espèce</strong>, du reste très rare”, travaille non pas dans l’atelier typographique, mais “au bureau du patron ou du prote” (d’apr. BOUTMY, Typogr. paris., 1874, p.&nbsp;29). <em>Sainte-Beuve dans la salle à manger, en famille, avec son secrétaire Troubat, sa correctrice d’épreuves, sa maîtresse</em> (GONCOURT, Journal, 1867, p.&nbsp;365).</p>
</blockquote>
<blockquote>
<p>TECHNOL. [Désigne un <strong>dispositif</strong>]</p>
</blockquote>
<blockquote>
<p>B. [<strong>L’instrument (matériel) de la correction</strong> dans diverses techniques]</p>
</blockquote>
<blockquote>
<p>C. [<strong>Le résultat</strong> lui-même]</p>
</blockquote>
</section>
<section id="on-peut-relever-un-certain-nombre-de-tensions" class="slide level2">
<h2>On peut relever un certain nombre de tensions</h2>
<ul>
<li>Entre l’homme et l’outil</li>
<li>Entre l’outil et le résultat</li>
</ul>
<p>J’en rajoute une autre : entre deux espace-temps différents :</p>
<ul>
<li>les protocoles éditoriaux établis au sein d’institutions</li>
<li>les pratiques de brouillonnages individuelles</li>
</ul>
</section>
<section id="la-révision-comme-protocole-éditorial" class="slide level2">
<h2>1. La révision comme protocole éditorial</h2>
<p>Définition donnée par le <em>Correcteur typographe</em> de Brossard de 1924 :</p>
<blockquote>
<p>La rectification, sur le plomb, des erreurs commises par le compositeur, ainsi que l’exécution des changements apportés par l’auteur à la composition du texte primitif sont connus sous la dénomination de correction. De, manière générale, ce mot s’emploie pour désigner toute modification, quelle, qu’elle soit : ajoutés, suppressions, transpositions, changements de texte, rectifications orthographiques, rappels de règles typographiques, etc. <span class="citation" data-cites="brossardCorrecteurTypographeRegles1924">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Brossard 1924-1934</a>)</span></p>
</blockquote>
<ul>
<li>Un savoir-faire qui nous vient du monde de l’imprimé</li>
<li>Passer de la copie à l’ouvrage</li>
<li>application des règles typographiques + reproduction fidèle et entière du manuscrit</li>
<li>un processus séquentiel (lecture → annotation → recomposition)</li>
<li>un processus itératif (premières, secondes épreuves, tierces)</li>
<li>un processus collectif (auteur.ice → correcteur.ice → auteur.ice → compositeur.ice)</li>
</ul>
<blockquote>
<p>Les auteurs ne se font point faute d’ailleurs de se prévaloir en ces circonstances de la liberté que leur accordent les usages, et l’on peut dire qu’en pratique le nombre des épreuves en placards ou en pages à fournir est illimité : suivant ses besoins, et sur sa demande, l’auteur peut recevoir successivement une première d’auteur, une deuxième, une troisième, et même plus si, d’après les corrections ou les modifications qu’il apporte au texte, il l’estime nécessaire : il est seul juge en cette matière, et généralement il ne remet le bon à mettre en pages ou, le cas échéant, le bon à tirer, que s’il répute le texte « amené à son état à peu près définitif ». <span class="citation" data-cites="brossardCorrecteurTypographeRegles1924">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Brossard 1924-1934</a>)</span></p>
</blockquote>
</section>
<section id="le-correcteur-est-le-chef-dorchestre-de-la-fabrique-du-livre" class="slide level2">
<h2>Le correcteur est le chef d’orchestre de la fabrique du livre</h2>

<img data-src="./img/signes.png" class="r-stretch quarto-figure-center"><p class="caption">Signes de correction ortho-typo</p></section>
<section id="les-acteurs-travaillent-lun-après-lautre-faute-après-faute" class="slide level2">
<h2>Les acteurs travaillent l’un après l’autre, faute après faute</h2>
<p>La composition est un processus terriblement laborieux</p>

<img data-src="./img/galee.jpg" class="r-stretch quarto-figure-center"><p class="caption">La casse et la galée</p></section>
<section id="science-ou-artisanat" class="slide level2">
<h2>Science ou artisanat ?</h2>
<h3 id="une-science">Une science ?</h3>
<p>Recommandation de <span class="citation" data-cites="ramatRamatTypographie2008">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Ramat 2008</a>)</span> :</p>
<blockquote>
<p>Nombre de lecture en correction</p>
<ul>
<li>une lecture très rapprochée pour découvrir les fautes d’orthographe et de typographie.</li>
<li>relire le texte sans s’occuper des fautes déjà mentionnées, s’attacher au fond et non plus à la forme.</li>
</ul>
</blockquote>
<ul>
<li>Vérification des pages et des notes</li>
<li>Figures et tableaux</li>
<li>Vérification des énumérations</li>
<li>Dates</li>
<li>Veiller à l’homogénéité de l’écriture inclusive</li>
<li>S’assurer que le système international d’unité est bien utilisé</li>
<li>Uniformité des abbréviations et des noms propres</li>
<li>Les capitales, les faces, la casse</li>
<li>Emploi normé de la ponctuation</li>
<li>Révision bibliographique</li>
<li>La composition et la mise en page (qu’on laisse de côté aujourd’hui)</li>
</ul>
<h3 id="un-travail-qui-relève-de-lartisanat-voire-un-art">Un travail qui relève de l’artisanat ? voire un art ?</h3>
<blockquote>
<p>L’inobservation des règles typographiques est, après la coquille, l’une des causes les plus fréquentes de correction : ce fait tient à l’ignorance dans laquelle trop d’ouvriers se trouvent des principes les plus élémentaires de leur art, au dédain même qu’ils affectent à leur égard, à la volonté et au désir de certains auteurs de s’affranchir des prescriptions d’un métier dont ils ne connaissent que des « bribes », à la <strong>multiplicité</strong> et aussi à <strong>un défaut de précision et de, fixité de ces prescriptions</strong> : celles-ci semblent en effet varier presque à l’infini, avec chaque région, avec chaque ville, avec chaque maison, avec chaque correcteur et, hélas! presque avec chaque labeur ; chacun ou chacune, a une marche particulière, ou un ensemble de règles typographiques qui leur est propre : dédale sans fin où se perdent même les meilleures volontés et où s’égarent les esprits les plus avertis. <span class="citation" data-cites="brossardCorrecteurTypographeRegles1924">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Brossard 1924-1934</a>)</span></p>
</blockquote>
</section>
<section id="la-correction-au-cœur-de-lécriture" class="slide level2" data-background-image="./img/brouillonproust.png" data-background-opacity="0.3">
<h2>2. La correction au cœur de l’écriture</h2>
<p>On peut aussi entendre révision au sens psycholinguistique =&gt; désigne une étape dans le processus scripturaire, étape liée à celle de la planification et de la textualisation.</p>
<ul>
<li>la linguistique génétique ou philologie préfère le mot « variante »</li>
<li>la didactique dira « correction »</li>
<li>« retouche », « remords »</li>
<li>individuelle et multiple</li>
</ul>
<p><strong>La continuité révision / écriture s’incarne dans les outils</strong>.</p>
<div style="color: green;">
<p>Les outils ne se contentent plus de pointer, on est dans le paradigme de la génération de texte.</p>
</div>
</section>
<section id="lécriture-et-le-numérique" class="slide level2" data-background-image="./img/delete.svg" data-background-opacity="0.2">
<h2>L’écriture et le numérique</h2>
<h3 id="rapidité">Rapidité</h3>
<p><span class="citation" data-cites="derridaPaperMachine2005">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Derrida 2005, 24</a>)</span></p>
<blockquote>
<p>It’s a different kind of timing, a different rythm. First of all you correct faster and in a more or less indefinite way. Previously, after a certain number of versions (corrections, reasures, cutting and pasting, Tippex), everything came to a halt – that was enough. Not that you thought the text was perfect, but, after a certain period of metamorphosis, the process was interrupted. With the computer, everything is rapid and so easy; you get to thinking that you can go on revising forever. An interminable revision, an infinite analysis is already on the horizon […]. During this same time you no longer retain the slightest visible or objective trace of corrections made the day before.</p>
</blockquote>
<blockquote>
<p>There was a temporal resistance, a thickness in the duration of erasure.</p>
</blockquote>
<h3 id="correcteurs-orthographiques-et-grammaticaux">Correcteurs orthographiques et grammaticaux</h3>
<ul>
<li>Facilité et rapidité de la correction ou révision</li>
<li>Développement des outils de correction // développement des traitements de texte</li>
<li>Logique de productivité</li>
</ul>
<div style="color: green;">
<p><strong>Les outils incarnent une vision du monde centrée sur la productivité et la rapidité</strong></p>
</div>
<!--break-->
</section></section>
<section>
<section id="histoire-de-la-gec" class="title-slide slide level1 center">
<h1>Histoire de la GEC</h1>

</section>
<section id="la-correction-derreur-grammaticales-automatique-grammar-error-correction" class="slide level2">
<h2>La correction d’erreur grammaticales automatique <em>Grammar Error correction</em></h2>
<p>Tâche de Traitement Automatique des Langues (TAL ou <em>Natural Language Processing</em>, NLP) voisine de la <strong>traduction automatique</strong> (TA ou <em>machine translation</em>, MT)</p>
<p>Système expert : limité par des grammaires complexes, questions de pragmatique et d’idiomaticité.</p>
<p>Systèmes inductifs ou approches <em>data-driven</em> : D’abord des classifieurs pour prédire le mots le plus probable dans une classe (préposition), puis <em>statistical machine learning</em> (SMT) dans les années 2010 et particulièrement <em>Neural machine translation</em> (NMT). <span class="citation" data-cites="wangComprehensiveSurveyGrammar2020 bryantGrammaticalErrorCorrection2023">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Wang et al. 2020</a>; <a href="#/bibliographie" role="doc-biblioref" onclick="">Bryant et al. 2023</a>)</span></p>
<p>NMT : Correspondance entre des phrases ou portions de phrases en entrée et des portions de phrases attestées en grand nombre (seq2seq) à partir de corpus parallèle. Le modèle algorithmique est entraîné sur une paire de langue (ex : français-&gt;anglais).</p>
</section>
<section id="traduction-automatique-et-llms" class="slide level2">
<h2>Traduction automatique et LLMs</h2>
<p>Un grand modèle de langue positionne chaque mot dans un espace vectoriel lors de sa phase d’apprentissage initiale à partir d’un grand volume de données en langue naturelle.</p>
<p>Afin de donner une réponse le LLM (GPT, Mistral, Qwen, Llama etc.) situe la requête utilisateur dans son espace vectoriel et sélectionne les tokens les plus probables à partir du contexte donné (la requête utilisateur ou <em>prompt</em> <strong>et</strong> les tokens qu’il a déjà généré).</p>
<p>Les LLMs sont donc <strong>généralistes</strong>, ils ne sont pas destinés à la traduction plus qu’à la correction d’erreurs grammaticales ou à l’écriture créative.</p>
</section>
<section id="llm-vs-nmt-pour-la-traduction-automatique" class="slide level2">
<h2>LLM vs NMT pour la Traduction automatique</h2>
<!-- si j'en parle c'est parce que la réflexion qui traverse le MT est la même que celle du GEC : vaut-il mieux un modèle qui fait plus d'erreurs mais qui sont prévisibles ou un modèle qui traduit mieux mais dont les fautes sont plus difficiles à cerner ? -->
<!-- Such divergences are well-documented in human translations (HT), where translators often make structural choices that vary significantly from the text originally written in the target language (Deng and Xue, 2017; Nikolaev et al., 2020). In contrast, traditional NMT outputs typically exhibit less diversity and more literal translations, lacking significant structural variation -->
<p>NMT : traduction littérale , modèle spécialisé</p>
<p>LLM : traduction plus idiomatique, tendance à la confabulation.</p>
<!-- > « We find that while LLMs often exhibit translation patterns more similar to human translations compared to traditional NMT models, they still diverge from originally authored text in the same language. Overall, we find that automatically translated sentences from both NMTs and LLMs are consistently identified with higher accuracy in O/T classification tasks than human-translated ones »  -->
<blockquote>
<p>« Furthermore, our frequency analysis of PoS tags reveals that LLMs align more closely with HT in their usage, especially in terms of adverbs, and auxiliary verbs, while NMT models tend to overproduce specific tags in shorter sentences. This suggests that LLMs, although not perfect, are making strides in mimicking human translation patterns. » <span class="citation" data-cites="sizovAnalysingTranslationArtifacts2024">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Sizov et al. 2024</a>)</span></p>
</blockquote>
<!-- >« indicate that LLMs tend to produce translations that are less literal compared to NMT models »  -->
<p>La fin de la NMT?</p>
<blockquote>
<p>« What’s more, IBM announced the deprecation of Watson Language Translator, its NMT service, encouraging users to migrate to — guess what? — WatsonX LLMs. This move establishes IBM as one of the first tech giants to sunset its NMT efforts and focus on LLMs for automated translation purposes. » <span class="citation" data-cites="ciesielskiNeuralMachineTranslation2024">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Ciesielski 2024</a>)</span></p>
</blockquote>
</section>
<section id="le-futur-de-la-traduction-automatique" class="slide level2">
<h2>Le futur de la traduction automatique</h2>
<blockquote>
<p>We anticipate that, soon, LLMs will become a viable enterprise solution for translation. This will likely come when we move towards task-specific LLMs trained specifically for translation. These models will be smaller and more practical to deploy and maintain than today’s massive foundational models. <span class="citation" data-cites="ciesielskiNeuralMachineTranslation2024">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Ciesielski 2024</a>)</span></p>
</blockquote>
<p>Les LLMs font la traduction et l’évaluation de la traduction.</p>
</section>
<section id="question-dévaluation" class="slide level2">
<h2>Question d’évaluation</h2>
<p>La traduction automatique : score BLEU (comparaison de la phrase traduite avec un référentiel de phrases bien traduites, score de proximité), WER (calcul du nombre de mot mal ou non traduit), METEOR etc.</p>
<p>La Grammar Error Correction (GEC) compare la phrase source (avec erreurs), la phrase corrigée et une phrase de référence (la <em>ground truth</em> donnée par un humain). Cette approche demande un corpus annoté en reference.</p>
</section>
<section id="métriques-traditionnelles-de-gec" class="slide level2">
<h2>Métriques traditionnelles de GEC</h2>
<ul>
<li>Edit-Based Metrics :
<ul>
<li>M² (MaxMatch) : On aligne les phrases corrigées par le système avec celles de référence (gold standard), puis on extrait les “edits” (opérations de correction : insertion, suppression, remplacement). On calcule précision, rappel, F0.5(donc précision pondérée deux fois plus que rappel).</li>
<li>ERRANT (Error Annotation Toolkit): alignement de l’hypothèse avec la phrase source et la phrase cible et classification du type d’erreur (morphologie, orthographe, syntaxe).</li>
</ul></li>
<li>Sentence-Based metrics:
<ul>
<li>GLEU (grammar-aware BLEU) : comparaison de n-grammes.</li>
</ul></li>
</ul>
<p>Ces mesures repose sur l’alignement entre une hypothèse et une référence figée.</p>
</section>
<section id="mesure-de-la-correction-sans-référence" class="slide level2">
<h2>Mesure de la correction sans référence</h2>
<p>Les métriques basées sur un corpus de référence limitent la correction a une forme seulement.</p>
<p>Mesure sans référence <span class="citation" data-cites="napolesTheresNoComparison2016">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Napoles, Sakaguchi, and Tetreault 2016</a>)</span>: comparaison directe de la phrase source (avec erreurs) et de la phrase corrigée avec un LLM.</p>
<p>Méthodes d’évaluation avec un LLM:</p>
<ul>
<li>Proximité/distance : Comparaison des vecteurs de la phrase source et celles de la phrase corrigée.</li>
<li>Perplexité/log-probabilité : plus une phrase est fluide plus elle est probable (donc correcte). <!-- log-probabilité : probabilité d'une phrase dans un modèle, le logarithme est utilisé car les proba sont très faibles
perplexité : inverse de la probabilité moyenne par mot, basse perplexité = LM trouve la phrase prévisible, fluide, naturelle. comparaison des scores de perplexité sur source puis hypothèse --></li>
<li>Spécialisation d’un LLM pour l’évaluation : <em>Machine learning</em> sur un corpus annoté avec des scores attribué ex: SOME <span class="citation" data-cites="yoshimuraReferencelessSubMetricsOptimized2020">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Yoshimura et al. 2020</a>)</span></li>
<li>LLM as judges : instruction en langues naturelles.</li>
</ul>
<blockquote>
<p>« The decrease in correlation as the LLM scale decreases, such as with Llama 2 and GPT-3.5, suggests the importance of the LLM scale. Especially, the decrease in correlation when adding fluent corrected sentences (“+ Fluent corr.”) compared to “Base” implies that smaller-scale LLMs may not adequately consider the fluency of sentences. Possible reasons for this include issues such as LLM’s tendency to produce the same scores (Appendix C) and the inability to interpret the context of prompts as expected by users. However, GPT-4 consistently demonstrated a high correlation and provided more stable evaluations compared to traditional metrics. » <span class="citation" data-cites="kobayashiLargeLanguageModels2024">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Kobayashi, Mita, and Komachi 2024</a>)</span></p>
</blockquote>
</section>
<section id="les-limites-des-llms-as-judge-pour-la-gec" class="slide level2">
<h2>Les limites des LLMs-as-judge pour la GEC</h2>
<ul>
<li>Pas toujours reproductible</li>
<li>Favorise les langues bien dotées. Ex Bengali <span class="citation" data-cites="maityHowReadyAre2024">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Maity, Deroy, and Sarkar 2024</a>)</span></li>
<li><span class="citation" data-cites="shankarWhoValidatesValidators2024a">Shankar et al. (<a href="#/bibliographie" role="doc-biblioref" onclick="">2024</a>)</span> et le <em>criteria drift</em> : on ne sait pas avant de l’avoir expérimenté ce que le LLM est capable de faire correctement. Autrement dit : l’évaluation est un processus itératif.</li>
</ul>
<!-- on entre dans une boucle où en pensant déléguer à un LLM la tâche de correction, on se retrouve à devoir itérativement penser la correction et l'évaluation proposée : finalement est-ce que notre capacité de correction n'est déplacée sur un nouvel outil mais toujours aussi nécessaire.  -->
</section>
<section id="changement-de-paradigme" class="slide level2">
<h2>Changement de paradigme</h2>
<div>
<p>Avant les LLM, les outils de ‘corrections’ sont spécialisés pour la correction ortho-typographique. Maintenant les outils de correction dépassent les limites de la simple correction grammaticale.</p>
<ul>
<li class="fragment">Reformulation.</li>
<li class="fragment">Génération de texte.</li>
<li class="fragment">Masquer l’utilisation d’une IA.</li>
</ul>
</div>
</section></section>
<section>
<section id="quels-enjeux" class="title-slide slide level1 center">
<h1>Quels enjeux ? <!--trouver un meilleur titre--></h1>
<div style="color: green;">
<p><em>Quelle valeur on accorde au travail de relecture et correction ?</em></p>
<p><em>Si écrire c’est avant tout réécrire : que signifie déléguer la (re)formulation à un LLM ?</em></p>
<p><em>Un gain de temps ?</em></p>
<p><em>Une déprise du texte ?</em></p>
</div>
</section>
<section id="homgénéisation-de-la-langue" class="slide level2">
<h2>Homgénéisation de la langue</h2>
<p>Mouvement de standardisation de la langue reposant sur une sur-norme « légitimée et maintenue par tout un édifice de croyances sur la nature de la langue et sur ce qui est correct ou incorrect, croyances qui sont dictées inévitablement par les valeurs sociales et esthétiques de la société concernée. » <span class="citation" data-cites="lodgeFrenchDialectStandard1993">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Lodge 1993</a>)</span></p>
<ul>
<li>Prépondérance des données standardisées voire générées par des LLMs dans le golden standard <span class="citation" data-cites="shumailovAIModelsCollapse2024">Guo et al. (<a href="#/bibliographie" role="doc-biblioref" onclick="">2024a</a>)</span></li>
<li>Problématique de l’« approche par défaut »<span class="citation" data-cites="paschalidisVersLangageSans2025">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Paschalidis 2025</a>)</span></li>
<li>Un idéal de clarté qui finit par s’auto-parodier (le fameux <em>style chatgpt</em>)</li>
</ul>
<blockquote>
<p>We show that while the core content of texts is retained when LLMs polish and rewrite texts, <strong>not only do they homogenize writing styles, but they also alter stylistic elements in a way that selectively amplifies certain dominant characteristics or biases while suppressing others - emphasizing conformity over individuality</strong>. By varying LLMs, prompts, classifiers, and contexts, we show that these trends are robust and consistent. <span class="citation" data-cites="sourati2025shrinkinglandscapelinguisticdiversity">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Sourati et al. 2025</a>)</span></p>
</blockquote>
<blockquote>
<p>Des compétences poussées en ingénierie de prompts sont nécessaires pour contourner les effets liés aux approches par défaut. Cependant, même avec l’expertise requise, les LLMs ont tendance à générer des réponses inexactes ou inventées, à <strong>revenir à leurs réglages par défaut</strong>, rendant les reformulations successives presque inévitables, parfois jusqu’à provoquer un effondrement du modèle. Par conséquent, cette <strong>« attraction par défaut »</strong> devient un paramètre dont il faut systématiquement tenir compte. <span class="citation" data-cites="paschalidisVersLangageSans2025">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Paschalidis 2025</a>)</span></p>
</blockquote>
<div style="color: green;">
<p><em>Si une formulation est fortement présente dans le corpus d’entraînement est-ce que c’est nécessairement la meilleure ? L’approche par défaut vaut-elle pour tous les contextes ?</em></p>
</div>
</section>
<section id="la-rédaction-académique-déprise-du-texte-déprise-du-sens" class="slide level2">
<h2>La rédaction académique : déprise du texte, déprise du sens ?</h2>
<ul>
<li>Tension entre rapidité et standards exigeants</li>
<li>Pouvoir rédiger dans un style “natif” même dans une langue étrangère</li>
</ul>
<div style="color: green;">
<p><em>Existe-t-il un seuil, une limite, au-delà de laquelle le recours aux LLMs constitue une perte de maîtrise du texte ?</em></p>
<p><em>Dire la même chose avec des mots différents change-t-il le sens ?</em></p>
</div>
</section>
<section id="clara" class="slide level2">
<h2>Uniformisation de la langue</h2>
<p>model collapse : <span class="citation" data-cites="shumailovAIModelsCollapse2024">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Shumailov et al. 2024</a>)</span></p>
<p>linguistic uniformisation : <span class="citation" data-cites="guoCuriousDeclineLinguistic2024">Guo et al. (<a href="#/bibliographie" role="doc-biblioref" onclick="">2024b</a>)</span></p>
<p>► est-ce qu’il y a un “style ChatGPT” ?</p>
</section>
<section id="lalignement-des-valeurs-et-le-système-de-valeurs" class="slide level2">
<h2>L’alignement des valeurs et le système de valeurs</h2>
<blockquote>
<p>« The problem of achieving agreement between our true preferences and the objective we put into the machine is called the value alignment problem: the values or objectives put into Value alignment problem the machine must be aligned with those of the human. » <span class="citation" data-cites="russellArtificialIntelligenceModern2022">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Russell and Norvig 2022, 23</a>)</span></p>
</blockquote>
<p>L’intelligence humaine commence là où celle de la machine s’arrête. Si on découvre de nouvelles capacités à la machine alors on enlève cette capicité de la définition de l’intelligence humaine. « More than fifteen years ago Hilary Putnam identified the old problem we face to this day: ‘The question that won’t go away is how much what we call intelligence presupposes the rest of human nature’ (1988: LET} » <span class="citation" data-cites="mccartyHumanitiesComputing2005">(<a href="#/bibliographie" role="doc-biblioref" onclick="">McCarty 2005, 41</a>)</span></p>
<p>Autrement dit, si on laisse à la machine cette tâche c’est qu’on tend à l’estimer comme peu valorisante dans notre système de valeur actuel.</p>
<div style="color: green;">
<p><em>Quelles conséquences est-ce que déléguer cette partie du travail a sur notre travail ? Et sur notre définition de l’humain ?</em></p>
</div>
</section>
<section id="des-petites-corrections-finales" class="slide level2">
<h2>Des ‘petites’ corrections finales ?</h2>
<blockquote>
<p>Currently, academic publishers only allow the use of ChatGPT and similar tools to improve the readability and language of research articles. However, the ethical boundaries and acceptable usage of AI in academic writing are still undefined, and neither humans nor AI detection tools can reliably identify text generated by AI <span class="citation" data-cites="homolakExploringAdoptionChatGPT2023">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Homolak 2023</a>)</span></p>
</blockquote>
<!-- pas de définition claire de la correction sur le plan académique = pas de limite non plus. 
Est-ce que refaire une table en utilisant un LLM càd en prenant le risque qu'il hallucine sur des données demande un usage cité de ChatGPT ? 
Si le contenu dépend du style, est-ce que la réécriture ne modifie pas le contenu original intellectuel ? 
Est-ce que faire un état de l'art (càd pas de production de nouveau contenu) avec chatGPT n'influence pas le travail de recherche ?  -->
<blockquote>
<p>It is being increasingly observed that content generated by ChatGPT is going undeclared and undetected, resulting in its appearance in articles published in scholarly journals. […] The general policy among publishers states that AI tools must not be used to create, alter or manipulate original research data and results (Elsevier., 2023; Roche, 2024).<span class="citation" data-cites="strzeleckiMyLastKnowledge2025">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Strzelecki 2025</a>)</span></p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Articles contenant des réponses de prompts</figcaption>
<p><img data-src="img/chatgptresponses.png"></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Articles contenant des réponses explicites de ChatGPT</figcaption>
<p><img data-src="img/chatgptresponses2.png"></p>
</figure>
</div>
<div style="color: green;">
<p><em>Est-ce que négliger la correction revient à négliger la lecture et l’écriture ?</em></p>
</div>
<!-- ici l'argumentaire c'est que comme on a laissé à ChatGPT la taĉhe de rédaction et possiblement de relecture finale on s'embête pas à relire la version de l'article soumise, donc on laisse des dingueries.  -->
<!-- 


## Quelle conséquence concrétement ?

deux points de vue : 
- La correction a un impact sur la manière dont le texte est reçu. Le pdv des outils : peaufiner pour 'convey at best' tes idées, respecter les idées de l'auteurice.
- "Écrire c'est réécrire." donc laisser la correction à la machine c'est laisser une partie importante du travail intellectuel. 
    - surtout si on considère les pratiques réelles où l'écriture est faite d'itération avec des étapes de corrections et des relectures. 
    - ce qui était rationalisé dans le monde de l'imprimé avec le système ddes 'épreuves' à al soumission d'un manuscrit. 

À quel moment est-ce que cette étape intervient ? Et quelle est la conséquence d'automatiser cette étape ? 

- au cours de la rédaction ? 
    - évanouissement des versions intermédiaires (suppression vs. versioning) ?
- à la fin de la rédaction ?  -->
</section>
<section id="effet-nivelant-et-influence-de-la-machine" class="slide level2">
<h2>Effet nivelant et influence de la machine</h2>
<p>Les moins bons traducteurs sont aidés par la TA mais les meilleurs traducteurs sont désavantagés par la TA. Effet limitant car tendance à se laisser influencer : réduction des intuitions de traduction et de la créativité traductionnelle.<span class="citation" data-cites="schumacherPosteditionTraductionAutomatique2023">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Schumacher 2023</a>)</span></p>
<p>Une influence pas négligeable : même quand un.e participant.e n’a plus les recommandations de la machine, iel reproduit les erreurs des recommandations <span class="citation" data-cites="vicenteHumansInheritArtificial2023">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Vicente and Matute 2023</a>)</span> : délégation cognitive ou <em>cognitive offloading</em></p>
<div style="color: green;">
<p><em>Comment est-ce qu’on peut prendre conscience de ces biais (inconscients) ?</em></p>
</div>
</section></section>
<section>
<section id="quelques-outils" class="title-slide slide level1 center">
<h1>Quelques outils</h1>

</section>
<section id="outils-généralistes" class="slide level2">
<h2>Outils généralistes</h2>
<p>LLMs non spécialisé : ChatGPT, Mistral, Llama, Claude etc., modèles téléchargés localement (ollama).</p>
<p>Tenir compte des biais du modèle et de son interaction avec lui.</p>
</section>
<section id="leffet-ai-powered" class="slide level2">
<h2>L’effet ‘AI-powered’</h2>
<p>La correction automatique existe avant ChatGPT et les LLM offraient des techniques poussées de GEC mais il fallait encore que de <strong>nouveaux usages s’ancrent</strong> et qu’il y ait un <strong>intérêt économique à maintenir l’utilisateur sur la même plateforme</strong> d’où l’intégration de LLM dans l’outil.</p>
</section></section>
<section>
<section id="outils-spécialisés" class="title-slide slide level1 center">
<h1>Outils spécialisés</h1>

</section>
<h3 id="les-outils-historiques-francophones">Les outils historiques (francophones)</h3>
<p><strong><a href="https://www.antidote.info">Antidote</a></strong></p>
<p>Sources sur les technologies d’Antidotes :</p>
<p><a href="https://www.antidote.info/fr/blogue/nouvelles/reformulation-et-intelligence-artificielle-antidote">Reformulation et IA (décembre 2023)</a></p>
<p><a href="août 2025">ChatGPT peut-il remplacer Antidote ?</a>(https://www.antidote.info/fr/blogue/astuces-et-conseils/chatgpt-peutil-remplacer-antidote)</p>
<p>Une combinaison d’outils spécialisés et utilisant des techniques diverses.</p>
<p><strong><a href="https://www.prolexis.com/">ProLexis</a></strong> (pas de vidéos youtube depuis 3 ans, ProLexis7) Outil professionel, analyseur syntaxique, interface à l’ancienne, <a href="https://www.youtube.com/watch?v=xTxBdv-zpIY">powerpoint à l’ancienne</a>.</p>
<h3 id="les-nouveaux-outils">Les nouveaux outils</h3>
<p><a href="https://www.editpad.org/">EditPad</a> : AI detector, humanize AI text, Plagiarim checker, paraphrasing tool, story generator, text summarizer, AI essay writer etc. Probablement juste ChatGPT hooked à une interface avec un system-prompt. Apparamment mauvais according to <span class="citation" data-cites="bordalejoScarletCloakForest2025">Bordalejo et al. (<a href="#/bibliographie" role="doc-biblioref" onclick="">2025</a>)</span></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>screenshot editpad</figcaption>
<p><img data-src="img/editpad.png"></p>
</figure>
</div>
<p>Corriger = masquer que le texte ne vient pas d’une machine, ou chercher à le détecter?</p>
<p><a href="https://www.writefull.com/">Writefull</a>: Title generator, Abstract generator, paraphraser, academizer.</p>
<p>Effet de mode = disparition et apparition de solutions miracles (down le 22 septembre, up le 30 septembre mais bug)</p>
<p><a href="https://www.grammarly.com/">Grammarly</a> donne une note à partir des critères de formalité, 4 niveaux : correctness (corrige erreurs grammaticales), clarity (reformulation) engagement (option payante), delivery (payant), plagiarism detection (payant). Option ‘generative AI’ avec des prompts pre-écrits qui restreignent l’usage. Et un browser plugin qui permet de s’en servir avec tous les sites google (docs, gmail, youtube comments).</p>
<p><em>improve</em> est une option liée à “Generative AI” juste ‘améliorer’.</p>
<!-- "Grammarly is the AI communication partner trusted by over 40 million people, 50,000 organizations, and people at 96% of the Fortune 500." -->
<p><a href="https://quillbot.com/">quillbot</a></p>
<blockquote>
<p>“Is QuillBot considered AI writing? 2 years ago Updated Everyone’s talking about AI writing these days, and debate over its use — and misuse — rages. QuillBot has helped you grow and improve as a writer, but you may wonder if using it is considered AI writing. Good question. <strong>The short answer is “no.” QuillBot’s tools have specific uses, such as correcting grammar or paraphrasing sentences. It’s up to you to use the feedback and suggestions to create content that is solely your own.</strong> ChatGPT and similar AI writers, on the other hand, can generate essay-length text from a few prompts. That writing can then be presented with no changes. Since QuillBot is not considered AI writing, most plagiarism checkers will not flag its use.</p>
</blockquote>
<blockquote>
<p>That said, we make no guarantees if someone uses QuillBot on text generated by a tool like ChatGPT. Why not play it safe and craft the content yourself? (With QuillBot’s help, of course!)</p>
</blockquote>
<section id="intégration-dans-tous-les-autres-outils" class="slide level2">
<h2>Intégration dans tous les autres outils</h2>
<p>Prise de note :</p>
<p><a href="https://www.notion.com/">Notion</a> : génération de texte.</p>
<p><a href="https://evernote.com/fr-fr">Evernote</a>: RAG</p>
<p>Rédaction de mail etc.</p>
</section></section>
<section>
<section id="conclusion" class="title-slide slide level1 center">
<h1>Conclusion</h1>

</section>
<section id="à-retenir" class="slide level2">
<h2>À retenir</h2>
<ul>
<li>La correction est un processus itératif qui implique une phase d’écriture, de lecture, d’annotation et de réécriture : l’IA a transformé ce paradigme à toutes les étapes.</li>
<li>Les premiers correcteurs automatiques se sont concentrés sur la correction ortho-typographiques, avec les systèmes de GEC complexes depuis les années 2000 ces outils traitent de reformulation</li>
<li>La Grammar Error Correction est une tâche voisine de la Traduction automatique : les technologies sous jacentes sont partagées</li>
<li>L’évaluation de la GEC et de la TA fait écho aux processus d’évaluation propre à la correction par un humain.</li>
<li>Avec l’ancrage de nouvelles pratiques discrètes de l’IA, on assiste à une nouvelle phase : la correction comme écriture et comme masquage de l’utilisation d’IA générative. Et l’intégration d’outils dit d’IA dans toutes les applications de traitement de texte etc.</li>
<li>Les promesses de gain de temps et de productivité cachent des enjeux économiques forts : on ne peut que rester méfiants face aux biais de ces outils tout en prennant conscience de ses propres influences.</li>
</ul>
</section>
<section id="prochaines-séances" class="slide level2">
<h2>Prochaines séances</h2>
<ul>
<li><em>Les systèmes d’exploitation</em> le 6 novembre avec Louis-Olivier</li>
<li><em>La Synthèse des sources et la recherche d’information</em> le 15 janvier 2026.</li>
</ul>
</section>
<section id="bibliographie" class="slide level2 smaller scrollable">
<h2>Bibliographie</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-bordalejoScarletCloakForest2025" class="csl-entry" role="listitem">
Bordalejo, Barbara, Davide Pafumi, Frank Onuh, A. K. M. Iftekhar Khalid, Morgan Slayde Pearce, and Daniel Paul O’Donnell. 2025. <span>“<span>‘<span>Scarlet Cloak</span> and the <span>Forest Adventure</span>’</span>: A Preliminary Study of the Impact of <span>AI</span> on Commonly Used Writing Tools.”</span> <em>International Journal of Educational Technology in Higher Education</em> 22 (1). <a href="https://doi.org/10.1186/s41239-025-00505-5">https://doi.org/10.1186/s41239-025-00505-5</a>.
</div>
<div id="ref-brossardCorrecteurTypographeRegles1924" class="csl-entry" role="listitem">
Brossard, L. E. du texte. 1924-1934. <em><span>Correcteur typographe. Les r<span>è</span>gles typographiques / L. -E. Brossard</span></em>.
</div>
<div id="ref-bryantGrammaticalErrorCorrection2023" class="csl-entry" role="listitem">
Bryant, Christopher, Zheng Yuan, Muhammad Reza Qorib, Hannan Cao, Hwee Tou Ng, and Ted Briscoe. 2023. <span>“Grammatical <span>Error Correction</span>: <span>A Survey</span> of the <span>State</span> of the <span>Art</span>.”</span> <em>Computational Linguistics</em>, September, 643–701. <a href="https://doi.org/10.1162/coli_a_00478">https://doi.org/10.1162/coli_a_00478</a>.
</div>
<div id="ref-ciesielskiNeuralMachineTranslation2024" class="csl-entry" role="listitem">
Ciesielski, Jourik. 2024. <span>“Neural <span>Machine Translation Versus Large Language Models</span>.”</span> https://multilingual.com/magazine/june-2024/neural-machine-translation-versus-large-language-models/.
</div>
<div id="ref-derridaPaperMachine2005" class="csl-entry" role="listitem">
Derrida, Jacques. 2005. <em>Paper <span>Machine</span></em>. Stanford University Press.
</div>
<div id="ref-guo2024curiousdeclinelinguisticdiversity" class="csl-entry" role="listitem">
Guo, Yanzhu, Guokan Shang, Michalis Vazirgiannis, and Chloé Clavel. 2024a. <span>“The Curious Decline of Linguistic Diversity: Training Language Models on Synthetic Text.”</span> <a href="https://arxiv.org/abs/2311.09807">https://arxiv.org/abs/2311.09807</a>.
</div>
<div id="ref-guoCuriousDeclineLinguistic2024" class="csl-entry" role="listitem">
———. 2024b. <span>“The <span>Curious Decline</span> of <span>Linguistic Diversity</span>: <span>Training Language Models</span> on <span>Synthetic Text</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2311.09807">https://doi.org/10.48550/arXiv.2311.09807</a>.
</div>
<div id="ref-homolakExploringAdoptionChatGPT2023" class="csl-entry" role="listitem">
Homolak, Jan. 2023. <span>“Exploring the Adoption of <span>ChatGPT</span> in Academic Publishing: Insights and Lessons for Scientific Writing.”</span> <em>Croatian Medical Journal</em> 64 (3): 205–7. <a href="https://doi.org/10.3325/cmj.2023.64.205">https://doi.org/10.3325/cmj.2023.64.205</a>.
</div>
<div id="ref-kobayashiLargeLanguageModels2024" class="csl-entry" role="listitem">
Kobayashi, Masamune, Masato Mita, and Mamoru Komachi. 2024. <span>“Large <span class="nocase">Language Models Are State-of-the-Art Evaluator</span> for <span>Grammatical Error Correction</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2403.17540">https://doi.org/10.48550/arXiv.2403.17540</a>.
</div>
<div id="ref-lodgeFrenchDialectStandard1993" class="csl-entry" role="listitem">
Lodge, R. Anthony. 1993. <em>French, from Dialect to Standard</em>. London ; New York : Routledge.
</div>
<div id="ref-maityHowReadyAre2024" class="csl-entry" role="listitem">
Maity, Subhankar, Aniket Deroy, and Sudeshna Sarkar. 2024. <span>“How <span class="nocase">Ready Are Generative Pre-trained Large Language Models</span> for <span>Explaining Bengali Grammatical Errors</span>?”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2406.00039">https://doi.org/10.48550/arXiv.2406.00039</a>.
</div>
<div id="ref-mccartyHumanitiesComputing2005" class="csl-entry" role="listitem">
McCarty, Willard. 2005. <em>Humanities <span>Computing</span></em>. Paperback edition. Basingstoke, Hampshire: Palgrave Macmillan.
</div>
<div id="ref-napolesTheresNoComparison2016" class="csl-entry" role="listitem">
Napoles, Courtney, Keisuke Sakaguchi, and Joel Tetreault. 2016. <span>“There’s <span>No Comparison</span>: <span class="nocase">Reference-less Evaluation Metrics</span> in <span>Grammatical Error Correction</span>.”</span> In <em>Proceedings of the 2016 <span>Conference</span> on <span>Empirical Methods</span> in <span>Natural</span> <span>Language Processing</span></em>, 2109–15. Austin, Texas: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/D16-1228">https://doi.org/10.18653/v1/D16-1228</a>.
</div>
<div id="ref-paschalidisVersLangageSans2025" class="csl-entry" role="listitem">
Paschalidis, Aristotelis Ioannis. 2025. <span>“<span>Vers un langage sans relief ? L’impact de l’IA sur nos mots</span>.”</span> {UNESCO}. <em>222e session du Conseil ex<span>é</span>cutif, 1-16 octobre 2025</em>.
</div>
<div id="ref-ramatRamatTypographie2008" class="csl-entry" role="listitem">
Ramat, Aurel. 2008. <em><span>Ramat de la typographie</span></em>. Montr<span>é</span>al: Aurel Ramat, <span>é</span>diteur *.
</div>
<div id="ref-russellArtificialIntelligenceModern2022" class="csl-entry" role="listitem">
Russell, Stuart J., and Peter Norvig. 2022. <em>Artificial Intelligence: A Modern Approach</em>. Fourth edition, global edition. Prentice <span>Hall</span> Series in Artificial Intelligence. Boston: Pearson.
</div>
<div id="ref-schumacherPosteditionTraductionAutomatique2023" class="csl-entry" role="listitem">
Schumacher, Perrine. 2023. <span>“<span>La post-<span>é</span>dition de traduction automatique en contexte d’apprentissage</span>.”</span> PhD thesis, Li<span>è</span>ge: Universite de Liege.
</div>
<div id="ref-shankarWhoValidatesValidators2024a" class="csl-entry" role="listitem">
Shankar, Shreya, J. D. Zamfirescu-Pereira, Björn Hartmann, Aditya G. Parameswaran, and Ian Arawjo. 2024. <span>“Who <span>Validates</span> the <span>Validators</span>? <span>Aligning LLM-Assisted Evaluation</span> of <span>LLM Outputs</span> with <span>Human Preferences</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2404.12272">https://doi.org/10.48550/arXiv.2404.12272</a>.
</div>
<div id="ref-shumailovAIModelsCollapse2024" class="csl-entry" role="listitem">
Shumailov, Ilia, Zakhar Shumaylov, Yiren Zhao, Nicolas Papernot, Ross Anderson, and Yarin Gal. 2024. <span>“<span>AI</span> Models Collapse When Trained on Recursively Generated Data.”</span> <em>Nature</em> 631 (8022): 755–59. <a href="https://doi.org/10.1038/s41586-024-07566-y">https://doi.org/10.1038/s41586-024-07566-y</a>.
</div>
<div id="ref-sizovAnalysingTranslationArtifacts2024" class="csl-entry" role="listitem">
Sizov, Fedor, Cristina España-Bonet, Josef Van Genabith, Roy Xie, and Koel Dutta Chowdhury. 2024. <span>“Analysing <span>Translation Artifacts</span>: <span>A Comparative Study</span> of <span>LLMs</span>, <span>NMTs</span>, and <span>Human Translations</span>.”</span> In <em>Proceedings of the <span>Ninth Conference</span> on <span>Machine Translation</span></em>, 1183–99. Miami, Florida, USA: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/2024.wmt-1.116">https://doi.org/10.18653/v1/2024.wmt-1.116</a>.
</div>
<div id="ref-sourati2025shrinkinglandscapelinguisticdiversity" class="csl-entry" role="listitem">
Sourati, Zhivar, Farzan Karimi-Malekabadi, Meltem Ozcan, Colin McDaniel, Alireza Ziabari, Jackson Trager, Ala Tak, Meng Chen, Fred Morstatter, and Morteza Dehghani. 2025. <span>“The Shrinking Landscape of Linguistic Diversity in the Age of Large Language Models.”</span> <a href="https://arxiv.org/abs/2502.11266">https://arxiv.org/abs/2502.11266</a>.
</div>
<div id="ref-strzeleckiMyLastKnowledge2025" class="csl-entry" role="listitem">
Strzelecki, Artur. 2025. <span>“<span>‘<span>As</span> of My Last Knowledge Update’</span>: <span>How</span> Is Content Generated by <span><span class="smallcaps">ChatGPT</span></span> Infiltrating Scientific Papers Published in Premier Journals?”</span> <em>Learned Publishing</em> 38 (1): e1650. <a href="https://doi.org/10.1002/leap.1650">https://doi.org/10.1002/leap.1650</a>.
</div>
<div id="ref-turingComputingMachineryIntelligence1950" class="csl-entry" role="listitem">
Turing, A. M. 1950. <span>“Computing <span>Machinery</span> and <span>Intelligence</span>.”</span> <em>Mind</em> LIX (236): 433–60. <a href="https://doi.org/10.1093/mind/LIX.236.433">https://doi.org/10.1093/mind/LIX.236.433</a>.
</div>
<div id="ref-vicenteHumansInheritArtificial2023" class="csl-entry" role="listitem">
Vicente, Lucía, and Helena Matute. 2023. <span>“Humans Inherit Artificial Intelligence Biases.”</span> <em>Scientific Reports</em> 13 (1): 15737. <a href="https://doi.org/10.1038/s41598-023-42384-8">https://doi.org/10.1038/s41598-023-42384-8</a>.
</div>
<div id="ref-vitali-rosatiManifestePourEtudes2025a" class="csl-entry" role="listitem">
Vitali-Rosati, Marcello. 2025. <span>“Manifeste Pour Des <span class="nocase"><span>É</span>tudes Critiques</span> de l’<span>Intelligence Artificielle</span>.”</span> <em>Culture Num<span>é</span>rique. Pour Une Philosophie Du Num<span>é</span>rique</em>.
</div>
<div id="ref-wangComprehensiveSurveyGrammar2020" class="csl-entry" role="listitem">
Wang, Yu, Yuelin Wang, Jie Liu, and Zhuo Liu. 2020. <span>“A <span>Comprehensive Survey</span> of <span>Grammar Error Correction</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2005.06600">https://doi.org/10.48550/arXiv.2005.06600</a>.
</div>
<div id="ref-yoshimuraReferencelessSubMetricsOptimized2020" class="csl-entry" role="listitem">
Yoshimura, Ryoma, Masahiro Kaneko, Tomoyuki Kajiwara, and Mamoru Komachi. 2020. <span>“<span>SOME</span>: <span class="nocase">Reference-less Sub-Metrics Optimized</span> for <span>Manual Evaluations</span> of <span>Grammatical Error Correction</span>.”</span> In <em>Proceedings of the 28th <span>International Conference</span> on <span>Computational Linguistics</span></em>, edited by Donia Scott, Nuria Bel, and Chengqing Zong, 6516–22. Barcelona, Spain (Online): International Committee on Computational Linguistics. <a href="https://doi.org/10.18653/v1/2020.coling-main.573">https://doi.org/10.18653/v1/2020.coling-main.573</a>.
</div>
</div>
</section></section>
<section id="merci-à-vous" class="title-slide slide level1 center">
<h1>Merci à vous !</h1>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>