<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.42">

  <meta name="dcterms.date" content="2025-10-09">
  <title>2e séance atelier IA - révision et correction automatique</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-2f366650f320edcfcf53d73c80250a32.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">2e séance atelier IA - révision et correction automatique</h1>

<div class="quarto-title-authors">
</div>

  <p class="date">2025-10-09</p>
</section>
<section class="slide level2">

<!-- Antidote : creuser modèle -->
<!-- vérif les modèles utilisés chez Grammarly, antidote, quillbot -->
</section>
<section id="plan-de-latelier" class="slide level2 scrollable">
<h2>Plan de l’atelier</h2>
<p>Théorie :</p>
<ol type="1">
<li class="fragment">Rappels sur les fondements de l’IA (30min) (AS)</li>
<li class="fragment">Présentation historico-technique des systèmes de GEC (15min) (AS)</li>
<li class="fragment">Changement de paradigme : de l’ortho-typo à la reformulation voire la génération de contenu (10min) (CG + AS)</li>
<li class="fragment">Problématique : quel csq sur le travail de recherche ? (CG)</li>
<li class="fragment">Changement de système de valeur : négligence dans cette étape de relecture et correction qui a des csq épistémologiques (CG) (30min avec discussion)</li>
<li class="fragment">Langue = norme et normalisation politique (CG) (10min)</li>
<li class="fragment">Présentation des outils (AS) (25min avec discussion)</li>
<li class="fragment">conclusion/ce qu’il faut retenir (5min)</li>
</ol>
</section>
<section id="présentation-et-objectif-des-ateliers" class="slide level2">
<h2>Présentation et objectif des ateliers</h2>
<p>Format : 4 séances de 2heures, sans inscription, participation libre (à justifier pour le certificat des Humanités Numériques)</p>
<p>Théorie et pratique.</p>
<p>Objectifs de la série d’atelier :</p>
<ul>
<li class="fragment">Comprendre les fondamentaux de l’IA et son histoire</li>
<li class="fragment">Obtenir des notions critiques sur le fonctionnement profond des outils</li>
<li class="fragment">Tester et s’approprier des outils d’IA</li>
<li class="fragment">Maîtriser le vocabulaire de la discipline</li>
</ul>
<p>Objectifs de cet atelier :</p>
<ul>
<li class="fragment">Cerner un cas d’usage courant des IA générative : la correction ortho-typographique.</li>
<li class="fragment">S’interroger l’impact de ces nouvelles pratiques dans le travail de recherche.</li>
<li class="fragment">Tester et comparer des outils courants.</li>
<li class="fragment">Définir des critères pour effectuer un choix éclairé vis-à-vis des outils disponibles</li>
</ul>
</section>
<section id="certificat-canadien-en-humanités-numériques" class="slide level2">
<h2>Certificat canadien en Humanités Numériques</h2>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Certificat canadien en HN</figcaption>
<p><img data-src="../seances/img/ccdhn1.png"></p>
</figure>
</div>
<p><img data-src="../seances/img/ccdhn2.png" alt="Certificat canadien en HN"> <img data-src="../seances/img/ccdhn3.png" alt="Certificat canadien en HN"></p>
<p><a href="https://ccdhhn.ca/">Information sur le certificat</a></p>
</section>
<section id="quest-ce-que-lia" class="slide level2">
<h2>Qu’est ce que l’IA ?</h2>
<p>Des programmes informatiques qui nous semblent dignes d’être comparé aux humains : une définition qui évolue avec les technologies.</p>
<p>Peut-être depuis 2020, le dernier mot à la mode après ‘numérique’ dans les années 2010, et cyberespace dans les années 1990 et 2000.<span class="citation" data-cites="vitali-rosatiManifestePourEtudes2025">(<a href="#/quelle-évaluation-des-corrections-ou-des-modèles" role="doc-biblioref" onclick="">Vitali-Rosati 2025</a>)</span>.</p>
<ul>
<li class="fragment">Définition pratique pour ces ateliers: un programme informatique qui effectue une prédiction.</li>
</ul>
</section>
<section id="rappels-de-lintroduction" class="slide level2">
<h2>Rappels de l’introduction</h2>
<ul>
<li class="fragment">Les programmes d’IA réfèrent à des processus algorithmiques variés et pas seulement à des chatbots type ChatGPT. <!-- ici expliquer Turing :  l'article Computing machinery intelligence a orienté la discipline vers une définition étroite de l'intelligence humaine comme intelligence sociale, ou capacité à feindre un échange social comme preuve d'humanité --></li>
<li class="fragment">L’histoire de l’IA montre qu’il y a des phases d’approbation publique et de désintérêt pour le terme et les technologies qu’il désigne.</li>
<li class="fragment">Ce qu’on fait entrer dans la catégorie d’“intelligent” a changé. <!-- pourquoi le calcul savant, précis n'est plus considéré comme intelligent ? --></li>
<li class="fragment">Deux grandes approches en IA : une approche déductive (IA symbolique, système expert) vs.&nbsp;déductive (IA connexionniste, modèle de langue).</li>
<li class="fragment">un système expert peut être aussi complexe et énergivore qu’un LLM.</li>
<li class="fragment">Concernant les LLMs : systèmes d’IA n’ont pas de connaissance du réel ou de ‘compréhension’ : les réponses sont probabilistes.</li>
<li class="fragment">Les hallucinations ne sont pas des anomalies, ce sont des erreurs que l’on qualifie a postériori comme telle.</li>
<li class="fragment">Chatbots = interfaces en langue naturelle : l’exploitation des capacités inductives d’un LLMs ne nécessite pas de passer par une telle interface. Ex : classification.</li>
<li class="fragment">Les modèles propriétaires (pas en libre accès) ont des intérêts économiques : nature ‘sycophantique’ avérée.</li>
</ul>
</section>
<section id="historique" class="slide level2">
<h2>Historique</h2>
<ul>
<li class="fragment"><p>élément historiques : passage de système experts exemples (MT) à modèles data-driven (SMT puis NMT sur corpus parallèle en MT) -&gt; des modèles spécialisés dans la classification. -&gt; depuis 20 ans, des approches statistiques à la correction càd mise en parallèle d’une phrase en entrée et d’une phrase ou séquence présente dans le jeu de donnée.</p></li>
<li class="fragment"><p>LLM généraliste : même modèle que NMT donc prédiction mais pas de spécialisation sur la tâche de correction ou traduction.</p></li>
</ul>
<p><strong>Avant les LLM les outils de ‘corrections’ sont seuleemnt sur la correction ortho-typographique (on y reviendra) Maintenant les outils qui promettent de la correction dépassent les limites de la simple correction grammaticale.</strong></p>
</section>
<section id="pourquoi-est-ce-que-les-outils-incorporent-ajd-du-ai-powered-et-quel-impact-sur-nos-pratqieus-de-recherches-et-denseignement" class="slide level2">
<h2>Pourquoi est-ce que les outils incorporent ajd du ‘AI powered’ et quel impact sur nos pratqieus de recherches et d’enseignement</h2>
<ul>
<li class="fragment">les Systèmes existaient avant ChatGPT et opéraient de la même façon mais il fallait</li>
<li class="fragment">Des nouveaux usages, un ancrage</li>
<li class="fragment">intérêt économique à maintenir l’utilisateur sur la même plateforme donc intégration de LLM dans l’outil. (mais probablement juste une requête).</li>
</ul>
</section>
<section id="la-correction" class="slide level2">
<h2>La correction</h2>
<!-- peut-être proposer des exemples, prendre son temps ? -->
<ul>
<li class="fragment">une étape négligée ou dévaluée ? quelle place dans notre système de valeurs ?</li>
<li class="fragment">qu’est-ce qui entre réellement dans cette étape ?
<ul>
<li class="fragment">corrections orthographiques,</li>
<li class="fragment">corrections typographiques,</li>
<li class="fragment">vérification de la mise en page, <!-- (veuve et orphelin) --></li>
<li class="fragment">traduction,</li>
<li class="fragment">vérification des sources,</li>
<li class="fragment">amélioration du style, ton.</li>
<li class="fragment">reformulation selon le lectorat pressenti (prise en compte de la situation d’énonciation)</li>
</ul>
<!-- répétition, niveau de langue, terminologie, alléger les phrases -->
<ul>
<li class="fragment">amélioration du contenu.</li>
</ul></li>
</ul>
<p>La correction bibliographique : ‘la barrière du dernier kilomètre’ <span class="citation" data-cites="monjourBarriereDernierKilometre2025">(<a href="#/quelle-évaluation-des-corrections-ou-des-modèles" role="doc-biblioref" onclick=""><strong>monjourBarriereDernierKilometre2025?</strong></a>)</span></p>
</section>
<section id="quelle-conséquence-concrétement" class="slide level2">
<h2>Quelle conséquence concrétement ?</h2>
<p>deux points de vue : - La correction a un impact sur la manière dont le texte est reçu. Le pdv des outils : peaufiner pour ‘convey at best’ tes idées, respecter les idées de l’auteurice. - “Écrire c’est réécrire.” donc laisser la correction à la machine c’est laisser une partie importante du travail intellectuel. - surtout si on considère les pratiques réelles où l’écriture est faite d’itération avec des étapes de corrections et des relectures. - ce qui était rationalisé dans le monde de l’imprimé avec le système ddes ‘épreuves’ à al soumission d’un manuscrit.</p>
<p>À quel moment est-ce que cette étape intervient ? Et quelle est la conséquence d’automatiser cette étape ?</p>
<ul>
<li class="fragment">au cours de la rédaction ?
<ul>
<li class="fragment">évanouissement des versions intermédiaires (suppression vs.&nbsp;versioning) ?</li>
</ul></li>
<li class="fragment">à la fin de la rédaction ?</li>
</ul>
</section>
<section id="changement-de-paradigme" class="slide level2">
<h2>Changement de paradigme</h2>
<p>de la correction ortho-typo à la reformulation au fait de masquer le fait que le texte ait été écrit par une IA.</p>
</section>
<section id="lalignement-des-valeurs-et-le-système-de-valeurs" class="slide level2">
<h2>L’alignement des valeurs et le système de valeurs</h2>
<blockquote>
<p>« The problem of achieving agreement between our true preferences and the objective we put into the machine is called the value alignment problem: the values or objectives put into Value alignment problem the machine must be aligned with those of the human. » <span class="citation" data-cites="russellArtificialIntelligenceModern2022a">(<a href="#/quelle-évaluation-des-corrections-ou-des-modèles" role="doc-biblioref" onclick="">Russell and Norvig 2022, 23</a>)</span></p>
</blockquote>
<p>L’intelligence humaine commence là où celle de la machine s’arrête. Si on découvre de nouvelles capacités à la machine alors on enlève cette capicité de la définition de l’intelligence humaine.</p>
<p>Autrement dit, si on laisse à la machine cette tâche c’est qu’on tend à l’estimer comme peu valorisante dans notre système de valeur actuel. Quelles conséquences est-ce que déléguer cette partie du travail a sur notre travail ?</p>
</section>
<section id="des-petites-corrections-finales" class="slide level2">
<h2>Des ‘petites corrections finales’ ?</h2>
<blockquote>
<p>Currently, academic publishers only allow the use of ChatGPT and similar tools to improve the readability and language of research articles. However, the ethical boundaries and acceptable usage of AI in academic writing are still undefined, and neither humans nor AI detection tools can reliably identify text generated by AI <span class="citation" data-cites="homolakExploringAdoptionChatGPT2023">(<a href="#/quelle-évaluation-des-corrections-ou-des-modèles" role="doc-biblioref" onclick=""><strong>homolakExploringAdoptionChatGPT2023?</strong></a>)</span></p>
</blockquote>
<!-- pas de définition claire de la correction sur le plan académique = pas de limite non plus. 
Est-ce que refaire une table en utilisant un LLM càd en prenant le risque qu'il hallucine sur des données demande un usage cité de ChatGPT ? 
Si le contenu dépend du style, est-ce que la réécriture ne modifie pas le contenu original intellectuel ? 
Est-ce que faire un état de l'art (càd pas de production de nouveau contenu) avec chatGPT n'influence pas le travail de recherche ?  -->
<blockquote>
<p>It is being increasingly observed that content generated by ChatGPT is going undeclared and undetected, resulting in its appearance in articles published in scholarly journals. […] The general policy among publishers states that AI tools must not be used to create, alter or manipulate original research data and results (Elsevier., 2023; Roche, 2024).<span class="citation" data-cites="strzeleckiMyLastKnowledge2025">(<a href="#/quelle-évaluation-des-corrections-ou-des-modèles" role="doc-biblioref" onclick=""><strong>strzeleckiMyLastKnowledge2025?</strong></a>)</span></p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Articles contenant des réponses de prompts</figcaption>
<p><img data-src="img/chatgptresponses.png"></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Articles contenant des réponses explicites de ChatGPT</figcaption>
<p><img data-src="img/chatgptresponses2.png"></p>
</figure>
</div>
<!-- ici l'argumentaire c'est que comme on a laissé à ChatGPT la taĉhe de rédaction et possiblement de relecture finale on s'embête pas à relire la version de l'article soumise, donc on laisse des dingueries.  -->
</section>
<section id="quest-ce-que-la-relecture-correction" class="slide level2">
<h2>Qu’est-ce que la relecture-correction ?</h2>
<ul>
<li class="fragment">correction ortho-typo</li>
<li class="fragment">des énoncés grammaticalement justes ⇒ la grammaire c’est que des règles de combinaison, purement syntaxique, combinatoire sans sémantique. Règles systématiques et productives. Computation de séquences.</li>
<li class="fragment">des énoncés qui font sens ⇒ sémantiquement correctes</li>
<li class="fragment">adéquation avec une situation d’énonciation ⇒ implique la pragmatique</li>
<li class="fragment">le style qui flirt avec les limites du correct</li>
<li class="fragment">la reformulation c’est encore autre chose</li>
</ul>
</section>
<section id="les-étapes-de-la-correction" class="slide level2 scrollable">
<h2>Les étapes de la correction</h2>
<!-- à valider avec Clara -->
<ol type="1">
<li class="fragment">la lecture</li>
<li class="fragment">établir des critères de corrections : orthographes = règles de la langue, mais style etc.</li>
<li class="fragment">l’annotation = proposition</li>
<li class="fragment">la réécriture</li>
</ol>
</section>
<section id="de-limportance-du-versionage" class="slide level2 scrollable">
<h2>De l’importance du versionage</h2>
<p>Le LLM et l’interaction avec le LLM réduit les étapes de la correction au delà de son automatisation. Le LLM réécrit, il n’annote pas<sup>1</sup>, ne demande pas de clarifications ur les instructions données même si elles sont floues (‘améliore le texte’ est une instruction valide).</p>
<p>Un processus de suppression qui est similaire aux logiques des éditeurs de texte WYSIWYG vs.&nbsp;le versionage qui rend compte du processus, entre dans une dimension de traçabilité et d’interprétabilité des choix effectués.</p>
<!-- ici une illustration sur le versionage ? -->
<aside><ol class="aside-footnotes"><li id="fn1"><p>on peut cependant prompter un modèle pour qu’il le fasse.</p></li></ol></aside></section>
<section id="sota-gec-grammar-error-correction" class="slide level2">
<h2>SOTA GEC = Grammar Error correction</h2>
<p>Tâche de NLP voisine de la <strong>traduction automatique</strong>.</p>
<p>Système expert : très limités pour cette tâche. Grammaire = beaucoup de règles, parfois des règles d’idiomaticité pure (des colocations fortes).</p>
<p>Systèmes inductifs ou approches <em>data-driven</em> :</p>
<p>D’abord des classifieurs pour prédire le mots le plus probable dans une classe (préposition), puis statistical machine learning (STM) dans les années 2010 et particulièrement Neural machine translation (NMT). <span class="citation" data-cites="wangComprehensiveSurveyGrammar2020 bryantGrammaticalErrorCorrection2023">(<a href="#/quelle-évaluation-des-corrections-ou-des-modèles" role="doc-biblioref" onclick=""><strong>wangComprehensiveSurveyGrammar2020?</strong></a>; <a href="#/quelle-évaluation-des-corrections-ou-des-modèles" role="doc-biblioref" onclick=""><strong>bryantGrammaticalErrorCorrection2023?</strong></a>)</span></p>
<p>NMT : Correspondance entre des phrases ou portions de phrases en entrée et des portions de phrases attestées en grand nombre (seq2seq) à partir de corpus parallèle. Le modèle algorithmique est entraîné sur une paire de langue (français-&gt;anglais).</p>
</section>
<section id="traduction-automatique-et-llms" class="slide level2">
<h2>Traduction automatique et LLMs</h2>
<p>Un grand modèle de langue positionne chaque mot dans un espace vectoriel lors de sa phase d’apprentissage initiale à partir d’un grand volume de données en langue naturelle.</p>
<p>Afin de retrouver donner une réponse le LLM généraliste comme GPT, Mistral, Qwen, Llama, situe la requête utilisateur dans son espace vectoriel et sélectionne les tokens les plus probables à partir du contexte donné (la requête utilisateur ou <em>prompt</em> <strong>et</strong> les tokens qu’il a déjà généré).</p>
<p>Les LLMs sont donc généralistes, ils ne sont pas destinés à la traduction plus qu’à la correction d’erreurs grammaticales ou l’écriture créative.</p>
<p>Such divergences are well-documented in human translations (HT), where translators often make structural choices that vary significantly from the text originally written in the target language (Deng and Xue, 2017; Nikolaev et al., 2020). In contrast, traditional NMT outputs typically exhibit less diversity and more literal translations, lacking significant structural variation</p>
</section>
<section id="llm-vs-nmt-qualitativement" class="slide level2">
<h2>LLM vs NMT qualitativement</h2>
<p>NMT + littéral, + spécialisé LLM + verbeux (confabulation) mais plus proche de la traduction humaine pour ça.</p>
<p>« We find that while LLMs often exhibit translation patterns more similar to human translations compared to traditional NMT models, they still diverge from originally authored text in the same language. Overall, we find that automatically translated sentences from both NMTs and LLMs are consistently identified with higher accuracy in O/T classification tasks than human-translated ones » <span class="citation" data-cites="sizovAnalysingTranslationArtifacts2024">(<a href="#/quelle-évaluation-des-corrections-ou-des-modèles" role="doc-biblioref" onclick=""><strong>sizovAnalysingTranslationArtifacts2024?</strong></a>)</span></p>
<p>« Furthermore, our frequency analysis of PoS tags reveals that LLMs align more closely with HT in their usage, especially in terms of adverbs, and auxiliary verbs, while NMT models tend to overproduce specific tags in shorter sentences. This suggests that LLMs, although not perfect, are making strides in mimicking human translation patterns. » (idem)</p>
<p>« indicate that LLMs tend to produce translations that are less literal compared to NMT models »</p>
<p>« What’s more, IBM announced the deprecation of Watson Language Translator, its NMT service, encouraging users to migrate to — guess what? — WatsonX LLMs. This move establishes IBM as one of the first tech giants to sunset its NMT efforts and focus on LLMs for automated translation purposes. » <span class="citation" data-cites="ciesielskiNeuralMachineTranslation2024">(<a href="#/quelle-évaluation-des-corrections-ou-des-modèles" role="doc-biblioref" onclick=""><strong>ciesielskiNeuralMachineTranslation2024?</strong></a>)</span></p>
</section>
<section id="limites-exposées" class="slide level2">
<h2>Limites exposées</h2>
<ul>
<li class="fragment"><p>avec la MT on a 50 ans d’évaluation et de mesure statistiquues pour évaluer (score BLEU etc) mais pas avec la correction parcequ’on néglige ĉa.</p></li>
<li class="fragment"><p>si on transpos eles ccl de l’article [<span class="citation" data-cites="sizovAnalysingTranslationArtifacts2024">(<a href="#/quelle-évaluation-des-corrections-ou-des-modèles" role="doc-biblioref" onclick=""><strong>sizovAnalysingTranslationArtifacts2024?</strong></a>)</span> on voit que LLM = conversationnel, + idiomatique mais pas + expert ! Et surtout, les traducteurs apprécient travailler avec des NMT (!! syst neuronaux spécialisés) parce que erreurs prévisibles ! Output convainquant au premier abrood car ressemble au langue naturelle mais erreurs plus subtiles plus difficile à détecter.</p></li>
</ul>
</section>
<section id="le-futur-de-la-traduction-automatique" class="slide level2">
<h2>Le futur de la traduction automatique</h2>
<p>We anticipate that, soon, LLMs will become a viable enterprise solution for translation. This will likely come when we move towards task-specific LLMs trained specifically for translation. These models will be smaller and more practical to deploy and maintain than today’s massive foundational models. <span class="citation" data-cites="ciesielskiNeuralMachineTranslation2024">(<a href="#/quelle-évaluation-des-corrections-ou-des-modèles" role="doc-biblioref" onclick=""><strong>ciesielskiNeuralMachineTranslation2024?</strong></a>)</span></p>
</section>
<section id="back-to-gec" class="slide level2">
<h2>Back to GEC</h2>
<p>Lectures à faire :</p>
<p><span class="citation" data-cites="kobayashiLargeLanguageModels2024">(<a href="#/quelle-évaluation-des-corrections-ou-des-modèles" role="doc-biblioref" onclick=""><strong>kobayashiLargeLanguageModels2024?</strong></a>)</span>; <span class="citation" data-cites="maityHowReadyAre2024">(<a href="#/quelle-évaluation-des-corrections-ou-des-modèles" role="doc-biblioref" onclick=""><strong>maityHowReadyAre2024?</strong></a>)</span></p>
<p>Kobayashi, M., Mita, M., &amp; Komachi, M. (2024). Large Language Models Are State-of-the-Art Evaluator for Grammatical Error Correction (No.&nbsp;arXiv:2403.17540). arXiv. https://doi.org/10.48550/arXiv.2403.17540</p>
<p>Maity, S., Deroy, A., &amp; Sarkar, S. (2024). How Ready Are Generative Pre-trained Large Language Models for Explaining Bengali Grammatical Errors? (No.&nbsp;arXiv:2406.00039). arXiv. https://doi.org/10.48550/arXiv.2406.00039</p>
</section>
<section id="avant-présentation-outils" class="slide level2 scrollable">
<h2>Avant présentation outils</h2>
<ol start="6" type="1">
<li class="fragment">Langue = norme et normalisation politique (Clara)</li>
</ol>
</section>
<section id="outils-généralistes" class="slide level2">
<h2>Outils généralistes</h2>
<p>LLMs non entraînés : ChatGPT, modèles téléchargés localement (ollama).</p>
<ul>
<li class="fragment">trad auto : comparaison montre que les llm généraliste sosnt conversationnels mais pas experts. Influence du prompt (à base d’exemple, description de la tâche).</li>
</ul>
<!-- interprétation donnée ChainForge -->
<ul>
<li class="fragment">des modèles ‘généraliste’ avec une forte préférence pour l’anglais : quelle place pour les formes dialectales, pour les langues minoritaires. ?</li>
</ul>
<p>Càd qu’un LLM est toujours orienté.</p>
</section>
<section id="outils-spécialisés-correction-écriture-académique" class="slide level2">
<h2>Outils spécialisés (correction, écriture académique)</h2>
<p>https://www.editpad.org/ : AI detector, humanize AI text, Plagiarim checker, paraphrasing tool, story generator, text summarizer, AI essay writer etc. Probablement juste ChatGPT hooked à une interface avec un system-prompt. Apparamment mauvais according to <span class="citation" data-cites="bordalejoScarletCloakForest2025">Bordalejo et al. (<a href="#/quelle-évaluation-des-corrections-ou-des-modèles" role="doc-biblioref" onclick="">2025</a>)</span></p>

<img data-src="img/editpad.png" class="r-stretch quarto-figure-center"><p class="caption">screenshot editpad</p><p>maintenant corriger = masquer que le texte ne vient pas d’un humain, ou chercher à le détecter</p>
<p><a href="https://www.writefull.com/">https://www.writefull.com/</a></p>
<p>Effet de mode = disparition et apparition de solutions miracles</p>
<p><a href="https://www.grammarly.com/">Grammarly</a> donne une note à partir des critères de formalité, 4 niveaux : correctness (corrige erreurs grammaticales), clarity (reformulation) engagement(option payante), delivery (payant), plagiarism detection (payant). Avec un ‘generative AI’ avec des prompts pre-écrit. -&gt; un browser plugin qui permet de s’en servir avec tous les sites google (docs, gmail, youtube comments).</p>
<p>‘improve’ is an option of Generative AI. As is, just ‘improve’.</p>
<p>“Grammarly is the AI communication partner trusted by over 40 million people, 50,000 organizations, and people at 96% of the Fortune 500.”</p>
<p><a href="https://quillbot.com/">quillbot</a></p>
<p>Is QuillBot considered AI writing?</p>
<pre><code>2 years ago Updated </code></pre>
<p>Everyone’s talking about AI writing these days, and debate over its use — and misuse — rages. QuillBot has helped you grow and improve as a writer, but you may wonder if using it is considered AI writing. Good question. <strong>The short answer is “no.” QuillBot’s tools have specific uses, such as correcting grammar or paraphrasing sentences. It’s up to you to use the feedback and suggestions to create content that is solely your own.</strong> ChatGPT and similar AI writers, on the other hand, can generate essay-length text from a few prompts. That writing can then be presented with no changes. Since QuillBot is not considered AI writing, most plagiarism checkers will not flag its use.</p>
<p>That said, we make no guarantees if someone uses QuillBot on text generated by a tool like ChatGPT. Why not play it safe and craft the content yourself? (With QuillBot’s help, of course!)</p>
<p>Antidote : https://www.antidote.info/fr/blogue/nouvelles/reformulation-et-intelligence-artificielle-antidote</p>
<p>Des choix</p>
<p>ProLexis</p>
</section>
<section id="interrogation" class="slide level2">
<h2>Interrogation</h2>
<p>Est-ce que ces outils sont vraiment spécialisés ? Et comment le sont-ils ?</p>
<p>il semble que les options de ‘generative AI’ sont simplement des prompts envoyés à un LLM via une API, ces outils ne possèdent pas forcément ‘leur modèle’, sinon ils ont fait du fine-tuning. Si l’utilisation du LLM est orientée par les dev du logiciel, il s’agit bien du même processus (l’utilisateurice peut seulement choisir une ‘reformulation’ du ton par exemple).</p>
<p>Les avantages possibles qu’il pourrait y avoir : la sécurité des données (prompts cryptés) mais ce n’est même pas amené.</p>
<p>On voit que les outils se dirigent vers la ‘détection du plagiat’ et de la détection du l’‘utilisation d’IA’ : est-ce que on est dans unelogique de correction ou pas plut^to une logique de maquillage d’usages considérés par les maison d’édition et les universités comme illégitimes ?</p>
<!-- en fait toutes les applications de texte ajd propose de l'IA : Evernote, Notion, ont des options de générative AI pour la correction et parfois pour la génération de texte. Avec par exemple Evernote qui ajoute du RAG -->
</section>
<section id="quelle-évaluation-des-corrections-ou-des-modèles" class="title-slide slide level1 smaller scrollable">
<h1>Quelle évaluation des corrections ou des modèles ?</h1>
<p>Formaliser une méthodologie pour l’évaluation :</p>
<p>critères :</p>
<ul>
<li class="fragment">évaluation quantitative</li>
<li class="fragment">évaluation qualitative</li>
</ul>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-bordalejoScarletCloakForest2025" class="csl-entry" role="listitem">
Bordalejo, Barbara, Davide Pafumi, Frank Onuh, A. K. M. Iftekhar Khalid, Morgan Slayde Pearce, and Daniel Paul O’Donnell. 2025. <span>“<span>‘<span>Scarlet Cloak</span> and the <span>Forest Adventure</span>’</span>: A Preliminary Study of the Impact of <span>AI</span> on Commonly Used Writing Tools.”</span> <em>International Journal of Educational Technology in Higher Education</em> 22 (1). <a href="https://doi.org/10.1186/s41239-025-00505-5">https://doi.org/10.1186/s41239-025-00505-5</a>.
</div>
<div id="ref-russellArtificialIntelligenceModern2022a" class="csl-entry" role="listitem">
Russell, Stuart J., and Peter Norvig. 2022. <em>Artificial Intelligence: A Modern Approach</em>. Fourth edition, global edition. Prentice <span>Hall</span> Series in Artificial Intelligence. Boston: Pearson.
</div>
<div id="ref-vitali-rosatiManifestePourEtudes2025" class="csl-entry" role="listitem">
Vitali-Rosati, Marcello. 2025. <span>“Manifeste Pour Des <span class="nocase"><span>É</span>tudes Critiques</span> de l’<span>Intelligence Artificielle</span>.”</span> <em>Culture Num<span>é</span>rique. Pour Une Philosophie Du Num<span>é</span>rique</em>.
</div>
</div>
</section>


    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>