[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ateliers IA pour les SHS",
    "section": "",
    "text": "‘IA’ est le terme qui a envahit nos discours depuis quelques années. Vous saturez ? Nous aussi ! Cette série d’atelier vise à outiller chercheurs et chercheuses en SHS pour comprendre les fondements de cette discipline afin de dépasser à la fois les discours marketing qui imprègnent malgré nous l’espace public et les propos alarmistes des derniers réfractaires.\n\n\nIntroduire à la communauté universitaire en SHS les fondements de l’étude critique des IA avec une stratégie d’apprentissage par la prise en main. Aucun pré-requis en informatique n’est nécessaire : apportez simplement votre ordinateur.\n\nSensibiliser sur l’impact des nouvelles outils sur les pratiques de recherche et d’édition en contexte universitaire\nOrienter les chercheur.se.s vers des outils d’IA adaptés à la recherche et allignés avec les préconisations éthiques actuelles.\nEclaircir les amalgames courants au sujet de l’IA et les chatbots par l’acquisition de connaissances fondamentales en IA."
  },
  {
    "objectID": "25-10-09_correctionAtelierIA.html",
    "href": "25-10-09_correctionAtelierIA.html",
    "title": "2e séance atelier IA - révision",
    "section": "",
    "text": "Date : 9 octobre 2025\n\n\n(format de 2h) 1. Présentation de la série d’atelier 2. Qu’est-ce que l’IA ? 3. Rappel de la 1e séance : histoire, ce qu’il fallait retenir de la 1e séance 4. Place et importance de la correction 5. Outils généralistes 6. Outils spécialisés (été 2025) 7. Pistes pour l’évaluation des outils 8. Conclusions"
  },
  {
    "objectID": "25-10-09_correctionAtelierIA.html#plan",
    "href": "25-10-09_correctionAtelierIA.html#plan",
    "title": "2e séance atelier IA - révision",
    "section": "",
    "text": "(format de 2h) 1. Présentation de la série d’atelier 2. Qu’est-ce que l’IA ? 3. Rappel de la 1e séance : histoire, ce qu’il fallait retenir de la 1e séance 4. Place et importance de la correction 5. Outils généralistes 6. Outils spécialisés (été 2025) 7. Pistes pour l’évaluation des outils 8. Conclusions"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Intro",
    "section": "",
    "text": "Présentation de la série d’atelier\nQu’est-ce que l’IA ?\nIntérêt d’étudier l’IA pour les SHS\nRetours historiques\nTypologie des IA\nCas d’usage et modélisation experte (ELIZA)\nCas d’usage et modélisation distributionnelle/vectorielle (vectorisation et prédiction)\nLes LLMs\nUsages des LLMs hors chatbots (demo)\nLLMs et chatbots (Duck.ai + Ollama)\nConclusions"
  },
  {
    "objectID": "intro.html#plan",
    "href": "intro.html#plan",
    "title": "Intro",
    "section": "Plan",
    "text": "Plan\n\nPrésentation de la série d’atelier\nQu’est-ce que l’IA ?\nIntérêt d’étudier l’IA pour les SHS\nRetours historiques\nTypologie des IA\nCas d’usage et modélisation experte (ELIZA)\nCas d’usage et modélisation distributionnelle/vectorielle (vectorisation et prédiction)\nLes LLMs\nUsages des LLMs hors chatbots (demo)\nLLMs et chatbots (Duck.ai + Ollama)\nConclusions"
  },
  {
    "objectID": "intro.html#présentation-et-objectif-des-ateliers",
    "href": "intro.html#présentation-et-objectif-des-ateliers",
    "title": "Intro",
    "section": "Présentation et objectif des ateliers",
    "text": "Présentation et objectif des ateliers\nFormat : 4 séances de 2heures, sans inscription, participation libre (à justifier pour le certificat des Humanités Numériques)\nThéorie et pratique en alternance au cours des deux heures.\nObjectifs de la série d’atelier :\n\nComprendre les fondamentaux de l’IA et son histoire\nObtenir des notions critiques sur le fonctionnement profond des outils\nTester et s’approprier des outils d’IA\nMaîtriser le vocabulaire de la discipline\n\nObjectifs de cet atelier :\n\nComprendre les différentes formes d’IA\nComprendre les enjeux liés à l’utilisation des LLM\nUtiliser de l’IA en dehors d’une interface de tchat.\nTester les paramètres des chatbots\nInstaller localement des modèles de langue."
  },
  {
    "objectID": "intro.html#quest-ce-que-lia",
    "href": "intro.html#quest-ce-que-lia",
    "title": "Intro",
    "section": "Qu’est ce que l’IA ?",
    "text": "Qu’est ce que l’IA ?\n\nTout et rien : exemples : chatbot, détection sur des imageries médicales, HTR, DeepBlue.\nle dernier mot à la mode. Le ‘numérique’ des années 2020. (Vitali-Rosati 2025)."
  },
  {
    "objectID": "intro.html#quest-ce-que-lia-1",
    "href": "intro.html#quest-ce-que-lia-1",
    "title": "Intro",
    "section": "Qu’est-ce que l’IA ?",
    "text": "Qu’est-ce que l’IA ?\nDéfinition pratique : “un programme informatique qui effectue une prédiction.”"
  },
  {
    "objectID": "intro.html#lia-et-les-shs",
    "href": "intro.html#lia-et-les-shs",
    "title": "Intro",
    "section": "L’IA et les SHS",
    "text": "L’IA et les SHS\nÀ quoi sert d’étudier l’IA pour les chercheur.se.s en SHS ?"
  },
  {
    "objectID": "intro.html#lia-et-les-shs-1",
    "href": "intro.html#lia-et-les-shs-1",
    "title": "Intro",
    "section": "L’IA et les SHS",
    "text": "L’IA et les SHS\nÀ quoi sert d’étudier l’IA pour les chercheur.se.s en SHS"
  },
  {
    "objectID": "intro.html#lia-et-les-shs-2",
    "href": "intro.html#lia-et-les-shs-2",
    "title": "Intro",
    "section": "L’IA et les SHS",
    "text": "L’IA et les SHS\nQue peuvent faire les SHS pour l’IA ?\n\nparticiper à la réflexion actuelle sur son utilisation :\n\npositionnements de revues et de conférences sur son utilisation (pose un cadre, parfois un précédent)\n\nproposer une théorie critique de l’IA décentrées de l’effet ‘benchmarking’\nproposer une avis sur l’utilisation de ces outils qui soit propre à sa discipline."
  },
  {
    "objectID": "intro.html#exemples-de-prises-de-position",
    "href": "intro.html#exemples-de-prises-de-position",
    "title": "Intro",
    "section": "Exemples de prises de position",
    "text": "Exemples de prises de position\n\nBoth SUP and JHUP have increasingly embraced, tested, and deployed some AI tools and policies. Barbara has been clear in her support of responsible uses of AI and the necessity of leveraging these early days to stake a claim within the quickly evolving landscape. Like SUP, JHUP is building and testing its own tools for marketing, accessibility, and analytics, efforts which place our presses in a position to potentially build services that might in the future even benefit other university presses. (Mulliken 2025)\n\n\nwe offer recommendations for citing generative AI, defined as a tool that “can analyze or summarize content from a huge set of information, including web pages, books and other writing available on the internet, and use that data to create original new content” (Weed). (“How Do I Cite Generative AI in MLA Style?” 2023)\n\n\nThe uncomfortable truth for researchers and publishers who oppose AI slowly taking over human review is that they might not be able to prevent it. Should a researcher use AI to write the first pass of peer review and not disclose it — in contravention of publisher guidelines — that might not be detectable, says Hosseini, who is also one of the editors of the journal Accountability in Research. And if AI reviews become widespread, that could change the practice of science, says Priem. “Every researcher can run their own bespoke review service over the preprint/dataset landscape, flagging/extracting only the science they care about (at any “quality” level) they want that day,” he wrote on X earlier this year. That could start to eat into the roles of journals, by taking away the certification that peer review mediated by journals provides, he says. (Naddaf 2025)"
  },
  {
    "objectID": "intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-1",
    "href": "intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-1",
    "title": "Intro",
    "section": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 1)",
    "text": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 1)\n1940s : Science-fiction et roman d’Isaac Asimov Runaround en 1942.\nTuring (1950) : ‘can machines think?’\n‘intelligence artificielle’ : 1956\n\n« The word Artificial Intelligence was then officially coined about six years later, when in 1956 Marvin Minsky and John McCarthy (a computer scientist at Stanford) hosted the approximately eight-week-long Dartmouth Summer Research Project on Artificial Intelligence (DSRPAI) at Dartmouth College in New Hampshire. » (Haenlein and Kaplan 2019, 7)\n\n1966 : ELIZA (Weizenbaum 1966)\n1990-2000s : pic des systèmes experts et des arbres de décision. DeepBlue d’IBM (Campbell, Hoane, and Hsu 2002)."
  },
  {
    "objectID": "intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-2",
    "href": "intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-2",
    "title": "Intro",
    "section": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 2)",
    "text": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 2)\n2010s : pic des systèmes d’IA avec une modélisation distributionnelle du language (vecteur). Word2Vec (Mikolov et al. 2013), GloVE (Pennington, Socher, and Manning 2014). Parmi les avancées majeures de cette modélisation on compte le mécanisme d’attention (Vaswani et al. 2017) et l’encodage bidirectionnel BERT (Devlin et al. 2019) qui permettent des modèles très performants comme le GPT-3 d’OpenAI (Brown et al. 2020).\nActuellement : tendance à l’hybridation (Marcus 2020)"
  },
  {
    "objectID": "intro.html#typologie-de-lia",
    "href": "intro.html#typologie-de-lia",
    "title": "Intro",
    "section": "Typologie de l’IA",
    "text": "Typologie de l’IA\n\nApproche experte : modélisation d’un programme à partir de règles précises. Les règles doivent être applicables à de nouvelles données pour faire une prédiction.\nApproche distributionnelle : modélisation d’un programme à partir d’un grand volume de données. Ce sont les motifs de répétitions qui permettent à la machine d’émettre une prédiction."
  },
  {
    "objectID": "intro.html#ce-quil-faut-retenir",
    "href": "intro.html#ce-quil-faut-retenir",
    "title": "Intro",
    "section": "Ce qu’il faut retenir",
    "text": "Ce qu’il faut retenir\n\ndeux modélisations : une approche top-down et une approche sample-based.\n‘des saisons’ en IA càd que certaines approches attirent l’attention à un moment donné, actuellement IA = chatbot voire ChatGPT.\nl’IA réfère à des algorithmes qui permettent d’automatiser une prise de décision et pas seulement à des programmes de génération textuelle."
  },
  {
    "objectID": "25-07_programme_ateliersIA2526.html",
    "href": "25-07_programme_ateliersIA2526.html",
    "title": "Programme Atelier IA certificat",
    "section": "",
    "text": "Séance 1 : Introduction aux théories et à l’historique de l’IA et typologie des outils.\nDate : 11 septembre\nPrompt injection, hacker un LLM :\npartir d’une phrase d’exemple simple puis faire son découpage.\ntâche détection de spam :\nDÉCOUVRE TON CADEAU\nDemande de renseignements\n‘hallucination’ -&gt;\n\n\nSéance 2 : Thématique révision et correction automatique.\nDate 9 octobre\nDifférence entre un outil spécialisé et non-spécialisé.\n\nOutils généralistes\nChatGPT, LLM non entrainés.\n\n\nOutils spécialisés (correction, écriture académique)\nhttps://www.editpad.org/ : AI detector, humanize AI text, Plagiarim checker, paraphrasing tool, story generator, text summarizer, AI essay writer etc. Probablement juste ChatGPT hooked à une interface avec un system-prompt. Apparamment mauvais according to @bordalejoScarletCloakForest2025\nhttps://www.writefull.com/\nhttps://www.grammarly.com/\n\n\n\nSéance 3 : Thématique recherche d’information et synthèse des sources.\nDate: 15 janvier\n\n\nSéance 4 : Synthèse des outils et méthodologies pour l’évaluation qualitative et quantitative.\nDate : 12 mars"
  },
  {
    "objectID": "intro.html#bibliographie",
    "href": "intro.html#bibliographie",
    "title": "Intro",
    "section": "Bibliographie",
    "text": "Bibliographie\n\n\n\n\nBrown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. “Language Models Are Few-Shot Learners.” arXiv. https://doi.org/10.48550/arXiv.2005.14165.\n\n\nCampbell, Murray, A. Joseph Hoane, and Feng-hsiung Hsu. 2002. “Deep Blue.” Artificial Intelligence 134 (1): 57–83. https://doi.org/10.1016/S0004-3702(01)00129-1.\n\n\nConnelly, Daniel. n.d. “Eliza.py.” Eliza Emulation Python. https://dhconnelly.com/paip-python/docs/paip/eliza.html. Accessed August 20, 2025.\n\n\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.” In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), edited by Jill Burstein, Christy Doran, and Thamar Solorio, 4171–86. Minneapolis, Minnesota: Association for Computational Linguistics. https://doi.org/10.18653/v1/N19-1423.\n\n\nFujinaga, Ichiro. 2025. “On the virtues of lazy machines.” {Keynote}. Montréal.\n\n\nHaenlein, Michael, and Andreas Kaplan. 2019. “A Brief History of Artificial Intelligence: On the Past, Present, and Future of Artificial Intelligence.” California Management Review 61 (4): 5–14. https://doi.org/10.1177/0008125619864925.\n\n\n“How Do I Cite Generative AI in MLA Style?” 2023. MLA Style Center.\n\n\nKnuth, D. E. 1984. “Literate Programming.” The Computer Journal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nMarcus, Gary. 2020. “The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence.” arXiv. https://doi.org/10.48550/arXiv.2002.06177.\n\n\nMikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. “Efficient Estimation of Word Representations in Vector Space.” arXiv. https://doi.org/10.48550/arXiv.1301.3781.\n\n\nMulliken, Jasmine. 2025. “2025 AUPresses Week-in-Residence Report.”\n\n\nNaddaf, Miryam. 2025. “AI Is Transforming Peer Review — and Many Scientists Are Worried.” Nature 639 (8056): 852–54. https://doi.org/10.1038/d41586-025-00894-7.\n\n\nPennington, Jeffrey, Richard Socher, and Christopher Manning. 2014. “GloVe: Global Vectors for Word Representation.” In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), edited by Alessandro Moschitti, Bo Pang, and Walter Daelemans, 1532–43. Doha, Qatar: Association for Computational Linguistics. https://doi.org/10.3115/v1/D14-1162.\n\n\nTuring, A. M. 1950. “Computing Machinery and Intelligence.” Mind LIX (236): 433–60. https://doi.org/10.1093/mind/LIX.236.433.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need.” arXiv. https://doi.org/10.48550/arXiv.1706.03762.\n\n\nVitali-Rosati, Marcello. 2025. “Manifeste Pour Des Études Critiques de l’Intelligence Artificielle.” Culture Numérique. Pour Une Philosophie Du Numérique.\n\n\nWeizenbaum, Joseph. 1966. “ELIZA—a Computer Program for the Study of Natural Language Communication Between Man and Machine.” Communications of the ACM 9 (1): 36–45. https://doi.org/10.1145/365153.365168."
  },
  {
    "objectID": "intro.html#partons-dun-exemple",
    "href": "intro.html#partons-dun-exemple",
    "title": "Intro",
    "section": "Partons d’un exemple",
    "text": "Partons d’un exemple\nObjectif : obtenir un programme capable de classer une phrase selon une thématique prédéfinie.\nExemple : Classification d’un texte en “parle de fruit” vs. “ne parle pas de fruit”."
  },
  {
    "objectID": "intro.html#modéliser-une-approche-experte",
    "href": "intro.html#modéliser-une-approche-experte",
    "title": "Intro",
    "section": "Modéliser une approche experte",
    "text": "Modéliser une approche experte\n\nfaire appel à un expert : un humain pour déterminer les règles qui définissent ce qui est une phrase parlant de fruits.\nexemple de règle possible : liste de mots comme ‘pomme, pommes, banane, poire etc.’ ordre des mots ou POS pour distinguer ‘orange’ couleur du fruit par exemple.\n\nUne approche qui sembler simpliste en apparence mais qui :\n\npeut s’avérer très complexe (ex: traduction)\nest la base de systèmes très performants\nentre dans une logique de lazy computing (Fujinaga 2025)\nrévèle les tâches de bas niveau pour passer d’une chaîne de caractères à un ensemble de caractéristiques : tokenisation, POS-tagging.\n\nProgramme de démo"
  },
  {
    "objectID": "intro.html#exemple-dun-programme-conversationnel-génération-textuelle-avec-une-approche-experte-eliza",
    "href": "intro.html#exemple-dun-programme-conversationnel-génération-textuelle-avec-une-approche-experte-eliza",
    "title": "Intro",
    "section": "Exemple d’un programme conversationnel /génération textuelle avec une approche experte ELIZA",
    "text": "Exemple d’un programme conversationnel /génération textuelle avec une approche experte ELIZA\nTry it yourself : ELIZA\n\nEliza is a pattern-matching automated psychiatrist. Given a set of rules in the form of input/output patterns, Eliza will attempt to recognize user input phrases and generate relevant psychobabble responses. Each rule is specified by an input pattern and a list of output patterns. A pattern is a sentence consisting of space-separated words and variables. (Connelly n.d.)\n\nExemple de literate programming (Knuth 1984) :\nLire le code d’ELIZA"
  },
  {
    "objectID": "intro.html#modélisation-vectorielle-et-machine-learning",
    "href": "intro.html#modélisation-vectorielle-et-machine-learning",
    "title": "Intro",
    "section": "Modélisation vectorielle et machine learning",
    "text": "Modélisation vectorielle et machine learning\n\npartir d’un ensemble important d’exemples\ntravail d’annotation par un humain/expert: ground truth ou vérité de terrain.\n1 token = une caractéristique\ncomptage des tokens dans l’ensemble du jeu de données et dans chaque phrase/document.\nreprésentation vectorielle = coordonnées dans un espace vectoriel à n dimensions.\n\nVisualisation de traitement basique (NER, POS et vectorisation)\n\n\nmême traitement est effectué sur de nouvelles données\ndifférentes logiques pour classer la nouvelle donnée :\n\nK-Nearest Neighbor\nRegression logistique\n\n\nPoints forts :\n\nadaptable à des nouvelles données, notamment avec une tokenisation fragmentée"
  },
  {
    "objectID": "intro.html#les-llms",
    "href": "intro.html#les-llms",
    "title": "Intro",
    "section": "Les LLMs",
    "text": "Les LLMs\nExemple de LLMs : GPT-4, Mixtral, Gemini, Llama, Qwen, DeepSeek etc.\nLarge Language Models : 1. modélisation vectorielle de chaque mot de la langue par rapport à sa fréquence d’apparition en contexte avec chacun des autres mots de la langue, 2. spécialisation sous forme de couche neuronale pour une tâche ou une fonction précise. 3. query et calcul pour chaque donnée en entrée du token le plus probable en sortie"
  },
  {
    "objectID": "intro.html#duck.ai",
    "href": "intro.html#duck.ai",
    "title": "Intro",
    "section": "Duck.ai",
    "text": "Duck.ai\nduck.ai permet de comparer des modèles en interfaces chat tout en conservant des données privées : https://duck.ai"
  },
  {
    "objectID": "intro.html#ollama",
    "href": "intro.html#ollama",
    "title": "Intro",
    "section": "Ollama",
    "text": "Ollama\nIl est pourtant possible de faire tourner un SLM (small language model) localement. Pour ce faire : ollama est une bibliothèque qui permet de télécharger et d’utiliser localement un LLMs.\ntéléchargement\nhttps://ollama.com/download\ncommand line\nollama run llama3.2\n““” -&gt; pour des instructions longues\nollama list -&gt; liste des modèles téléchargés et utilisables\nollama rm llama3.2 -&gt; supprime un modèle"
  },
  {
    "objectID": "intro.html#paramètres-dun-modèle",
    "href": "intro.html#paramètres-dun-modèle",
    "title": "Intro",
    "section": "Paramètres d’un modèle",
    "text": "Paramètres d’un modèle\nPlusieurs paramètres importants et contrôlable :\n\nle seed :les LLMs ont une variable aléatoire dans leur paramètre : le seed permet d’utiliser toujours le même ordre aléatoire, càd d’obtenir pour un même prompt toujours la même réponse et ainsi de rendre reproductible une réponse.\nla température: détermine le degré d’utilisation de la variable aléatoire (mas o menos)\ntop_k : Reduces the probability of generating nonsense. A higher value (e.g. 100) will give more diverse answers, while a lower value (e.g. 10) will be more conservative. (Default: 40)\ntop_p: Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value (e.g., 0.5) will generate more focused and conservative text. (Default: 0.9)"
  },
  {
    "objectID": "intro.html#model-steering",
    "href": "intro.html#model-steering",
    "title": "Intro",
    "section": "model Steering",
    "text": "model Steering\nhttps://github.com/ollama/ollama/blob/main/docs/modelfile.md\nCréer un nouveau document ‘Modelfile’ sans extension touch Modelfile\nFROM llama3.2\nPARAMETER temperature 1\ntop_k 100\ntop_p 1\nseed 17\nSYSTEM \"Tu es un chien\"\nollama create chien -f Modelfile\nollama run chien"
  },
  {
    "objectID": "intro.html#limites-des-interfaces-de-chat",
    "href": "intro.html#limites-des-interfaces-de-chat",
    "title": "Intro",
    "section": "Limites des interfaces de chat",
    "text": "Limites des interfaces de chat\n\nles chatbots ont des limites : on peut ‘hacker un LLM’ avec du prompt injection ou autres techniques de Jailbreaking.\n\nIncitent database\n\nHidden prompts reportedly were discovered in at least 17 academic preprints on arXiv that purportedly instructed AI tools to deliver only positive peer reviews. The lead authors are reportedly affiliated with 14 institutions in eight countries, including Waseda University, KAIST, Peking University, and the University of Washington. The alleged concealed instructions, some of which were reportedly embedded using white text or tiny fonts, were purportedly intended to influence any reviewers who rely on AI tools. (https://incidentdatabase.ai/cite/1135)\n\n\nil n’y a pas d’hallucinations, toutes les générations produites par un LLMs ont la même teneur de vérité du pdv de l’outil : le modèle ne peut pas évaluer sa réponse à l’aune d’une ground truth comme dans sa phase d’entraînement.\nProblèmes et réflexions pour les SHS :\n\nuniformisation des pratiques, des modes de pensées : l’interface de chat est une façon de formaliser son problème, quid de la recherhce de solution en interrogeant des moteurs de recherche, des bdd ou archives spécialisées ?\nDerrière l’apparente accessibilité de l’interface de chat, est-ce qu’on ne risque pas de creuser l’écart de la littératie numérique ?\nEst-ce que ces connaissances spécifiques, comme celles du code, qui impliquent des capacités de raisonnement alternatives, ne risquent pas de se retrouver suelement dans une forme d’élite intellectuelle ?"
  },
  {
    "objectID": "intro.html#llms-et-non-chatbot",
    "href": "intro.html#llms-et-non-chatbot",
    "title": "Intro",
    "section": "LLMs et non chatbot",
    "text": "LLMs et non chatbot\nClassification (de token, de texte)"
  },
  {
    "objectID": "intro.html#llms-et-chatbot",
    "href": "intro.html#llms-et-chatbot",
    "title": "Intro",
    "section": "LLMs et chatbot",
    "text": "LLMs et chatbot\nParce que les LLMs sont lourds (plusieurs Gigas) et parce qu’il est coûteux en énergie d’effectuer les calculs qui permettent de déterminer le prochain token (plusieurs GPU), l’usage le plus courant des LLMs est via un site qui va interroger le modèle sur un serveur distant. C’est la forme ChatGPT, Mistral.ai, etc."
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "Ateliers IA pour les SHS",
    "section": "",
    "text": "‘IA’ est le terme qui a envahit nos discours depuis quelques années. Vous saturez ? Nous aussi ! Cette série d’atelier vise à outiller chercheurs et chercheuses en SHS pour comprendre les fondements de cette discipline afin de dépasser à la fois les discours marketing qui imprègnent malgré nous l’espace public et les propos alarmistes des derniers réfractaires.\n\n\nIntroduire à la communauté universitaire en SHS les fondements de l’étude critique des IA avec une stratégie d’apprentissage par la prise en main. Aucun pré-requis en informatique n’est nécessaire : apportez simplement votre ordinateur.\n\nSensibiliser sur l’impact des nouvelles outils sur les pratiques de recherche et d’édition en contexte universitaire\nOrienter les chercheur.se.s vers des outils d’IA adaptés à la recherche et allignés avec les préconisations éthiques actuelles.\nEclaircir les amalgames courants au sujet de l’IA et les chatbots par l’acquisition de connaissances fondamentales en IA."
  },
  {
    "objectID": "index.html#programme",
    "href": "index.html#programme",
    "title": "Ateliers IA pour les SHS",
    "section": "Programme",
    "text": "Programme\nSéances de 2 heures, sans inscription, participation libre.\nBibliothèques des Lettres et Sciences Humaines (15h30 - 17h30)\nSéance 1 : jeudi 11 septembre 2025 15:30: Introduction : comment distinguer l’IA de ChatGPT\nQu’est-ce qu’on entend exactement par Intelligence Artificielle aujourd’hui ? Pour ne pas se sentir dépassé par le discours ambiant sur ces nouvelles technologies et leurs grandes promesses, on vous propose une séance de rattrapage sur les fondements de l’IA. Venez apprendre la place des chatbots dans l’histoire de la discipline et comprendre l’intérêt d’étudier l’IA du point de vue des SHS.\n-&gt; Alexia Schneider & Marcello Vitali-Rosati\nSéance 2 : jeudi 09 octobre 2025 15:30 IA et la correction textuelle automatique : quels outils et quelles limites ?\nLes outils d’IA générative se sont désormais immiscés dans tous nos logiciels d’édition, aussi bien pour la rédaction de mail, de documents textuels que pour de l’assistance à la rédaction de fiction ou de dissertation, mais comment faire la différence entre toutes les formes de corrections possibles et mesurer l’intérêt et l’impact de ces outils dans nos pratiques. Cet atelier vise à outiller les chercheur.se.s en SHS sur les outils existants et offrir des pistes pour mesurer leur impact dans leurs pratiques individuelles.\n-&gt; Alexia Schneider & Clara Grometto\nSéance 3 : jeudi 15 janvier 2026 15:30 Synthèse des sources et Recherche d’Information\nOn vous a sûrement déjà dit que pour limiter les erreurs des IA génératives et pour s’assurer qu’une machine rende les bonnes informations, il fallait passer par un RAG. Mais qu’est-ce qu’un RAG et comment est-ce que ça fontionne exactement ? Dans cet atelier vous apprendrez à disséquer un outils de Recherche d’information associé à un outil de synthèse de texte.\n-&gt; Alexia Schneider\nSéance 4 : jeudi 12 mars 2026 15:30 Documentation des nouvelles pratiques liées à l’utilisation de l’IA : préconisations pour les SHS\nVoilà maintenant quelques années que l’IA est devenue monnaie courante et l’heure est désormais à la pérénisation des guides d’utilisation et des limites définies par les institutions de recherche et d’enseignement. Cet atelier présente les lignes directrices adoptées par les institutions en SHS ainsi que les méthodes de documentation existantes de ces nouvelles pratiques de rédaction, de correction et de recherche d’information."
  },
  {
    "objectID": "sept11/intro.html#plan",
    "href": "sept11/intro.html#plan",
    "title": "Intro",
    "section": "Plan",
    "text": "Plan\n\nPrésentation de la série d’atelier\nQu’est-ce que l’IA ?\nIntérêt d’étudier l’IA pour les SHS\nRetours historiques\nTypologie des IA\nCas d’usage et modélisation experte (ELIZA)\nCas d’usage et modélisation distributionnelle/vectorielle (vectorisation et prédiction)\nLes LLMs\nUsages des LLMs hors chatbots (demo)\nLLMs et chatbots (Duck.ai + Ollama)\nConclusions"
  },
  {
    "objectID": "sept11/intro.html#présentation-et-objectif-des-ateliers",
    "href": "sept11/intro.html#présentation-et-objectif-des-ateliers",
    "title": "Intro",
    "section": "Présentation et objectif des ateliers",
    "text": "Présentation et objectif des ateliers\nFormat : 4 séances de 2heures, sans inscription, participation libre (à justifier pour le certificat des Humanités Numériques)\nThéorie et pratique en alternance au cours des deux heures.\nObjectifs de la série d’atelier :\n\nComprendre les fondamentaux de l’IA et son histoire\nObtenir des notions critiques sur le fonctionnement profond des outils\nTester et s’approprier des outils d’IA\nMaîtriser le vocabulaire de la discipline\n\nObjectifs de cet atelier :\n\nComprendre les différentes formes d’IA\nComprendre les enjeux liés à l’utilisation des LLM\nUtiliser de l’IA en dehors d’une interface de tchat.\nTester les paramètres des chatbots\nInstaller localement des modèles de langue."
  },
  {
    "objectID": "sept11/intro.html#quest-ce-que-lia",
    "href": "sept11/intro.html#quest-ce-que-lia",
    "title": "Intro",
    "section": "Qu’est ce que l’IA ?",
    "text": "Qu’est ce que l’IA ?\n\nTout et rien : exemples : chatbot, détection sur des imageries médicales, HTR, DeepBlue.\nle dernier mot à la mode. Le ‘numérique’ des années 2020. (Vitali-Rosati 2025)."
  },
  {
    "objectID": "sept11/intro.html#quest-ce-que-lia-1",
    "href": "sept11/intro.html#quest-ce-que-lia-1",
    "title": "Intro",
    "section": "Qu’est-ce que l’IA ?",
    "text": "Qu’est-ce que l’IA ?\nDéfinition pratique : “un programme informatique qui effectue une prédiction.”"
  },
  {
    "objectID": "sept11/intro.html#lia-et-les-shs",
    "href": "sept11/intro.html#lia-et-les-shs",
    "title": "Intro",
    "section": "L’IA et les SHS",
    "text": "L’IA et les SHS\nÀ quoi sert d’étudier l’IA pour les chercheur.se.s en SHS ?"
  },
  {
    "objectID": "sept11/intro.html#lia-et-les-shs-1",
    "href": "sept11/intro.html#lia-et-les-shs-1",
    "title": "Intro",
    "section": "L’IA et les SHS",
    "text": "L’IA et les SHS\nÀ quoi sert d’étudier l’IA pour les chercheur.se.s en SHS"
  },
  {
    "objectID": "sept11/intro.html#lia-et-les-shs-2",
    "href": "sept11/intro.html#lia-et-les-shs-2",
    "title": "Intro",
    "section": "L’IA et les SHS",
    "text": "L’IA et les SHS\nQue peuvent faire les SHS pour l’IA ?\n\nparticiper à la réflexion actuelle sur son utilisation :\n\npositionnements de revues et de conférences (pose un cadre, parfois un précédent)\n\nproposer une théorie critique de l’IA décentrées de l’effet ‘benchmarking’ (i.e. comparaison des modèles ou des entreprises qui les mettent à disposition)\nproposer une avis sur l’utilisation de ces outils qui soit propre à sa discipline (ex: distinguer des usages en fonction des besoins particuliers de son domaine)."
  },
  {
    "objectID": "sept11/intro.html#exemples-de-prises-de-position",
    "href": "sept11/intro.html#exemples-de-prises-de-position",
    "title": "Intro",
    "section": "Exemples de prises de position",
    "text": "Exemples de prises de position\n\nBoth SUP and JHUP have increasingly embraced, tested, and deployed some AI tools and policies. Barbara has been clear in her support of responsible uses of AI and the necessity of leveraging these early days to stake a claim within the quickly evolving landscape. Like SUP, JHUP is building and testing its own tools for marketing, accessibility, and analytics, efforts which place our presses in a position to potentially build services that might in the future even benefit other university presses. (Mulliken 2025)\n\n\nwe offer recommendations for citing generative AI, defined as a tool that “can analyze or summarize content from a huge set of information, including web pages, books and other writing available on the internet, and use that data to create original new content” (Weed). (“How Do I Cite Generative AI in MLA Style?” 2023)\n\n\nThe uncomfortable truth for researchers and publishers who oppose AI slowly taking over human review is that they might not be able to prevent it. Should a researcher use AI to write the first pass of peer review and not disclose it — in contravention of publisher guidelines — that might not be detectable, says Hosseini, who is also one of the editors of the journal Accountability in Research. And if AI reviews become widespread, that could change the practice of science, says Priem. “Every researcher can run their own bespoke review service over the preprint/dataset landscape, flagging/extracting only the science they care about (at any “quality” level) they want that day,” he wrote on X earlier this year. That could start to eat into the roles of journals, by taking away the certification that peer review mediated by journals provides, he says. (Naddaf 2025)\n\n\nBuilding critical AI literacies is a process of empowerment that enables students and citizens to exercise independent judgment about whether or if to use this very new and largely untested commercial technology. (rutgersCriticalAILiteracies2024?)"
  },
  {
    "objectID": "sept11/intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-1",
    "href": "sept11/intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-1",
    "title": "Intro",
    "section": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 1)",
    "text": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 1)\n1940s : Science-fiction et roman d’Isaac Asimov Runaround en 1942.\nTuring (1950) : ‘can machines think?’\n‘intelligence artificielle’ : 1956\n\n« The word Artificial Intelligence was then officially coined about six years later, when in 1956 Marvin Minsky and John McCarthy (a computer scientist at Stanford) hosted the approximately eight-week-long Dartmouth Summer Research Project on Artificial Intelligence (DSRPAI) at Dartmouth College in New Hampshire. » (Haenlein and Kaplan 2019, 7)\n\n1966 : ELIZA (Weizenbaum 1966)\n1990-2000s : pic des systèmes experts et des arbres de décision. DeepBlue d’IBM (Campbell, Hoane, and Hsu 2002)."
  },
  {
    "objectID": "sept11/intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-2",
    "href": "sept11/intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-2",
    "title": "Intro",
    "section": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 2)",
    "text": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 2)\n2010s : pic des systèmes d’IA avec une modélisation distributionnelle du language (vecteur). Word2Vec (Mikolov et al. 2013), GloVE (Pennington, Socher, and Manning 2014). Parmi les avancées majeures de cette modélisation on compte le mécanisme d’attention (Vaswani et al. 2017) et l’encodage bidirectionnel BERT (Devlin et al. 2019) qui permettent des modèles très performants comme le GPT-3 d’OpenAI (Brown et al. 2020).\nActuellement : tendance à l’hybridation de ces modèles : Neuro-Symbolic Integration, Semantic Web Machine Learning (Marcus 2020; Breit et al. 2023)"
  },
  {
    "objectID": "sept11/intro.html#typologie-de-lia",
    "href": "sept11/intro.html#typologie-de-lia",
    "title": "Intro",
    "section": "Typologie de l’IA",
    "text": "Typologie de l’IA\n\nApproche experte ou modèle symbolique : modélisation d’un programme à partir de règles précises. Les règles doivent être applicables à de nouvelles données pour faire une prédiction.\nApproche inductive ou modèle d’apprentissage machine (machine learning) : modélisation d’un programme à partir d’un grand volume de données. Ce sont les motifs de répétitions qui permettent à la machine d’émettre une prédiction."
  },
  {
    "objectID": "sept11/intro.html#ce-quil-faut-retenir",
    "href": "sept11/intro.html#ce-quil-faut-retenir",
    "title": "Intro",
    "section": "Ce qu’il faut retenir",
    "text": "Ce qu’il faut retenir\n\nL’IA réfère à plusieurs type de modélisations pour la prédiction : une approche déductive et une approche inductive.\nOn parle ‘des saisons’ de l’IA pour évoquer l’attrait public de la discipline et son avancée depuis les années 1950.\nPar conséquent, certaines approches attirent l’attention à un moment donné, actuellement IA = chatbot voire ChatGPT.\nL’IA réfère à des algorithmes qui permettent d’automatiser une prise de décision et pas seulement à des programmes de génération textuelle."
  },
  {
    "objectID": "sept11/intro.html#partons-dun-exemple",
    "href": "sept11/intro.html#partons-dun-exemple",
    "title": "Intro",
    "section": "Partons d’un exemple",
    "text": "Partons d’un exemple\nObjectif : obtenir un programme capable de classer une phrase selon une thématique prédéfinie.\nExemple : Classification d’un texte soit en “parle de fruit” soit en “ne parle pas de fruit”.\nVocabulaire :\ndocument : ici une phrase\nclasses : ensemble thématique de la classification. Ex : “fruit” et “non fruit” pour la classification binaire de notre exemple.\njeu de données : ensemble des documents\napprentissage supervisé : méthode d’apprentissage machine à partir de classes connues.\napprentissage non-supervisé : méthode d’apprentissage machine sans connaître les classes à l’avance : a pour objectif de déterminer les caractéristiques discriminantes d’un jeu de données.\nvérité de terrain ou ground truth : annotation effectuée par un humain sur l’ensemble du jeu de données."
  },
  {
    "objectID": "sept11/intro.html#modéliser-une-approche-experte",
    "href": "sept11/intro.html#modéliser-une-approche-experte",
    "title": "Intro",
    "section": "Modéliser une approche experte",
    "text": "Modéliser une approche experte\n\nfaire appel à un expert : un humain pour déterminer les règles qui définissent ce qui est une phrase parlant de fruits.\nexemple de règle possible : liste de mots comme ‘pomme, pommes, banane, poire etc.’ ordre des mots ou POS pour distinguer ‘orange’ couleur du fruit par exemple.\n\nUne approche qui sembler simpliste en apparence mais qui :\n\npeut s’avérer très complexe (ex: traduction)\nest la base de systèmes très performants\nentre dans une logique de lazy computing (Fujinaga 2025)\nrévèle les tâches de bas niveau pour passer d’une chaîne de caractères à un ensemble de caractéristiques : tokenisation, POS-tagging.\n\nProgramme de démo"
  },
  {
    "objectID": "sept11/intro.html#exemple-dun-programme-conversationnel-génération-textuelle-avec-une-approche-experte-eliza",
    "href": "sept11/intro.html#exemple-dun-programme-conversationnel-génération-textuelle-avec-une-approche-experte-eliza",
    "title": "Intro",
    "section": "Exemple d’un programme conversationnel /génération textuelle avec une approche experte ELIZA",
    "text": "Exemple d’un programme conversationnel /génération textuelle avec une approche experte ELIZA\nTry it yourself : ELIZA\n\nEliza is a pattern-matching automated psychiatrist. Given a set of rules in the form of input/output patterns, Eliza will attempt to recognize user input phrases and generate relevant psychobabble responses. Each rule is specified by an input pattern and a list of output patterns. A pattern is a sentence consisting of space-separated words and variables. (Connelly n.d.)\n\nExemple de literate programming (Knuth 1984) :\nLire le code d’ELIZA"
  },
  {
    "objectID": "sept11/intro.html#modélisation-vectorielle-et-machine-learning",
    "href": "sept11/intro.html#modélisation-vectorielle-et-machine-learning",
    "title": "Intro",
    "section": "Modélisation vectorielle et machine learning",
    "text": "Modélisation vectorielle et machine learning\n\npartir d’un ensemble important d’exemples\ntravail d’annotation par un humain/expert: ground truth ou vérité de terrain.\n1 token = une caractéristique\ncomptage des tokens dans l’ensemble du jeu de données et dans chaque phrase/document.\nreprésentation vectorielle = coordonnées dans un espace vectoriel à n dimensions.\n\nVisualisation de traitement basique (NER, POS et vectorisation)\n\n\nmême traitement est effectué sur de nouvelles données\ndifférentes logiques pour classer la nouvelle donnée :\n\nK-Nearest Neighbor\nRegression logistique\n\n\nPoints forts :\n\nadaptable à des nouvelles données, notamment avec une tokenisation fragmentée"
  },
  {
    "objectID": "sept11/intro.html#les-llms",
    "href": "sept11/intro.html#les-llms",
    "title": "Intro",
    "section": "Les LLMs",
    "text": "Les LLMs\nExemple de LLMs : GPT-4, Mixtral, Gemini, Llama, Qwen, DeepSeek etc.\nLarge Language Models : 1. Encodage : Word embeddings ou plongement de mots obtenu par rapport à sa fréquence d’apparition en contexte avec chacun des autres mots de la langue à partir d’un volume de données textuelle gigantesque. Modèles de type BERT : encodage bilatéral avec méchanisme d’attention. 2. Spécialisation du modèle sous forme de couches neuronales pour une tâche ou une fonction précise. 3. Query et calcul pour chaque donnée en entrée du token le plus probable en sortie."
  },
  {
    "objectID": "sept11/intro.html#llms-et-non-chatbot",
    "href": "sept11/intro.html#llms-et-non-chatbot",
    "title": "Intro",
    "section": "LLMs et non chatbot",
    "text": "LLMs et non chatbot\nClassification (de token, de texte)"
  },
  {
    "objectID": "sept11/intro.html#llms-et-chatbot",
    "href": "sept11/intro.html#llms-et-chatbot",
    "title": "Intro",
    "section": "LLMs et chatbot",
    "text": "LLMs et chatbot\nParce que les LLMs sont lourds (plusieurs Gigas) et parce qu’il est coûteux en énergie d’effectuer les calculs qui permettent de déterminer le prochain token (plusieurs GPU), l’usage le plus courant des IA générative est via un site qui va interroger le modèle sur un serveur distant. C’est la forme ChatGPT, Mistral.ai, etc."
  },
  {
    "objectID": "sept11/intro.html#duck.ai",
    "href": "sept11/intro.html#duck.ai",
    "title": "Intro",
    "section": "Duck.ai",
    "text": "Duck.ai\nduck.ai permet de comparer des modèles en interfaces chat tout en conservant des données privées."
  },
  {
    "objectID": "sept11/intro.html#ollama",
    "href": "sept11/intro.html#ollama",
    "title": "Intro",
    "section": "Ollama",
    "text": "Ollama\nIl est possible de faire tourner un SLM (small language model) localement. Pour ce faire : ollama est une bibliothèque qui permet de télécharger et d’utiliser localement un LLMs.\nInstallation et utilisation de Ollama\nTéléchargement de Ollama\nUtilisation de Ollama en invite de commande\nVia l’invite de commande\nollama run llama3.2 -&gt; télécharge et lance le modèle.\n““” -&gt; pour des instructions longues\n/show info -&gt; information sur le modèle téléchargé\nollama list -&gt; liste des modèles téléchargés et utilisables\nollama rm llama3.2 -&gt; supprime un modèle"
  },
  {
    "objectID": "sept11/intro.html#paramètres-dun-modèle",
    "href": "sept11/intro.html#paramètres-dun-modèle",
    "title": "Intro",
    "section": "Paramètres d’un modèle",
    "text": "Paramètres d’un modèle\n\nLe seed (nombre que l’on peut choisir): les LLMs ont une variable aléatoire au moment de l’encodage des données et au moment du requêtage : le seed permet d’utiliser toujours le même ordre aléatoire, càd d’obtenir pour un même prompt toujours la même réponse. Enjeu de reproductibilité.\nLa température (valeur de 0 à 1): détermine le degré d’utilisation de la variable aléatoire. Une température élevée signifie que le modèle sera plus “créatif” car il donnera plus probablement un token qui a une probabilité absolue moindre dans son contexte.\ntop_k (valeur de 0 à 100): variable qui réduit la probabilité de générer des tokens absurdes. Une valeur élevée donne des réponses plus variées et une valeur basse des réponses plus conservatrices. (Défaut 40)\ntop_p (valeur de 0 à 1): Fonctionne avec le top_k. Une valeur haute donne un texte varié, une valeur basse, un texte conservateur. (Défaut: 0,9)\n\nSource : Documentation Ollama"
  },
  {
    "objectID": "sept11/intro.html#model-steering",
    "href": "sept11/intro.html#model-steering",
    "title": "Intro",
    "section": "Model Steering",
    "text": "Model Steering\nReconduire un modèle consiste à lui fournir des ordres qui vont modifier son comportement pour toutes les interactions.\nTutoriel\nCréer un nouveau document ‘Modelfile’ sans extension.\nLinux : cat &gt; Modelfile puis CTRL+C :\n\nFROM llama3.2 PARAMETER temperature 1 top_k 100 top_p 1 seed 17 SYSTEM “Tu es un chien”\n\npuis CTRL+SHIFT+D et CTRL+D\nWindows cmd (Win+R): echo 'FROM llama3.2 PARAMETER temperature 1 top_k 100 top_p 1 seed 17 SYSTEM \"Tu es un chien\"' &gt; Modelfile (CTRL+SHIFT+D)\nOu c/c manuellement :\n\nFROM llama3.2 PARAMETER temperature 1 top_k 100 top_p 1 seed 17 SYSTEM “Tu es un chien”\n\nollama create chien -f Modelfile\nollama run chien"
  },
  {
    "objectID": "sept11/intro.html#limites-des-interfaces-de-chat",
    "href": "sept11/intro.html#limites-des-interfaces-de-chat",
    "title": "Intro",
    "section": "Limites des interfaces de chat",
    "text": "Limites des interfaces de chat\n\nles chatbots ont des limites : on peut ‘hacker un LLM’ avec du prompt injection ou autres techniques de jailbreaking.\n\nIncitent database\n\nHidden prompts reportedly were discovered in at least 17 academic preprints on arXiv that purportedly instructed AI tools to deliver only positive peer reviews. The lead authors are reportedly affiliated with 14 institutions in eight countries, including Waseda University, KAIST, Peking University, and the University of Washington. The alleged concealed instructions, some of which were reportedly embedded using white text or tiny fonts, were purportedly intended to influence any reviewers who rely on AI tools. (https://incidentdatabase.ai/cite/1135)\n\n\nil n’y a pas d’hallucinations, toutes les générations produites par un LLMs ont la même teneur de vérité du pdv de l’outil : le modèle ne peut pas évaluer sa réponse à l’aune d’une ground truth comme dans sa phase d’entraînement."
  },
  {
    "objectID": "sept11/intro.html#bibliographie",
    "href": "sept11/intro.html#bibliographie",
    "title": "Intro",
    "section": "Bibliographie",
    "text": "Bibliographie\n\n\n\n\nBreit, Anna, Laura Waltersdorfer, Fajar J. Ekaputra, Marta Sabou, Andreas Ekelhart, Andreea Iana, Heiko Paulheim, et al. 2023. “Combining Machine Learning and Semantic Web: A Systematic Mapping Study.” ACM Computing Surveys 55 (14s): 313:1–41. https://doi.org/10.1145/3586163.\n\n\nBrown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. “Language Models Are Few-Shot Learners.” arXiv. https://doi.org/10.48550/arXiv.2005.14165.\n\n\nCampbell, Murray, A. Joseph Hoane, and Feng-hsiung Hsu. 2002. “Deep Blue.” Artificial Intelligence 134 (1): 57–83. https://doi.org/10.1016/S0004-3702(01)00129-1.\n\n\nConnelly, Daniel. n.d. “Eliza.py.” Eliza Emulation Python. https://dhconnelly.com/paip-python/docs/paip/eliza.html. Accessed August 20, 2025.\n\n\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.” In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), edited by Jill Burstein, Christy Doran, and Thamar Solorio, 4171–86. Minneapolis, Minnesota: Association for Computational Linguistics. https://doi.org/10.18653/v1/N19-1423.\n\n\nFujinaga, Ichiro. 2025. “On the virtues of lazy machines.” {Keynote}. Montréal.\n\n\nHaenlein, Michael, and Andreas Kaplan. 2019. “A Brief History of Artificial Intelligence: On the Past, Present, and Future of Artificial Intelligence.” California Management Review 61 (4): 5–14. https://doi.org/10.1177/0008125619864925.\n\n\n“How Do I Cite Generative AI in MLA Style?” 2023. MLA Style Center.\n\n\nKnuth, D. E. 1984. “Literate Programming.” The Computer Journal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nMarcus, Gary. 2020. “The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence.” arXiv. https://doi.org/10.48550/arXiv.2002.06177.\n\n\nMikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. “Efficient Estimation of Word Representations in Vector Space.” arXiv. https://doi.org/10.48550/arXiv.1301.3781.\n\n\nMulliken, Jasmine. 2025. “2025 AUPresses Week-in-Residence Report.”\n\n\nNaddaf, Miryam. 2025. “AI Is Transforming Peer Review — and Many Scientists Are Worried.” Nature 639 (8056): 852–54. https://doi.org/10.1038/d41586-025-00894-7.\n\n\nPennington, Jeffrey, Richard Socher, and Christopher Manning. 2014. “GloVe: Global Vectors for Word Representation.” In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), edited by Alessandro Moschitti, Bo Pang, and Walter Daelemans, 1532–43. Doha, Qatar: Association for Computational Linguistics. https://doi.org/10.3115/v1/D14-1162.\n\n\nTuring, A. M. 1950. “Computing Machinery and Intelligence.” Mind LIX (236): 433–60. https://doi.org/10.1093/mind/LIX.236.433.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need.” arXiv. https://doi.org/10.48550/arXiv.1706.03762.\n\n\nVitali-Rosati, Marcello. 2025. “Manifeste Pour Des Études Critiques de l’Intelligence Artificielle.” Culture Numérique. Pour Une Philosophie Du Numérique.\n\n\nWeizenbaum, Joseph. 1966. “ELIZA—a Computer Program for the Study of Natural Language Communication Between Man and Machine.” Communications of the ACM 9 (1): 36–45. https://doi.org/10.1145/365153.365168."
  },
  {
    "objectID": "sept11/intro.html#approche-inductive-la-modélisation-vectorielle-et-le-machine-learning",
    "href": "sept11/intro.html#approche-inductive-la-modélisation-vectorielle-et-le-machine-learning",
    "title": "Intro",
    "section": "Approche inductive : la modélisation vectorielle et le machine learning",
    "text": "Approche inductive : la modélisation vectorielle et le machine learning\n1e étape Modélisation des données\n\nConstitution d’un corpus : obtenir un ensemble important de documents.\nAttribution d’une classe à chaque document : annotation par un humain/expert, ground truth ou vérité de terrain.\nEncodage : Comptage des tokens dans l’ensemble du jeu de données et dans chaque phrase/document.\nOn obtient une représentation vectorielle = coordonnées dans un espace vectoriel à n dimensions.\n\n\nReprésentation vectorielle ou word embeddings2e étape Détermination de la logique de prédiction\nDifférentes logiques permettent de distinguer les données entre elles. Quelques exemples d’apprentissage machine classique :\n\nK-Nearest Neighbor -&gt; le token apartient à la même classe que ses voisins (au nombre K)\nArbre de décision -&gt; on construit un arbre de questions fermées qui dessine le jeu de données.\nRegression logistique -&gt; une ligne sépare l’espace vectoriel entre les deux classes\n\n3e étape Apprentissage\n\nDivision du jeu de données en données d’entrainement et données de test.\nCalcul des poids de chaque token (régression logistique ou arbre de décision) sur les données d’entrainement.\nPrédiction sur les données de test\nComparaison avec la vérité de terrain\nAjustement des poids : réitération de l’apprentissage si les prédictions sont insatisfaisantes. (Cette étape est très énergivore)\n\n4e étape Evaluation ou utilisation du modèle sur de nouvelles données\n\nDe nouvelles données (données d’évaluation sur une phase expériementale) qui n’ont jamais été vues par la machine, sont vectorisées aussi.\nLe programme entraîné effectue ses prédictions sur ces données."
  },
  {
    "objectID": "sept11/intro.html#en-résumé",
    "href": "sept11/intro.html#en-résumé",
    "title": "Intro",
    "section": "En résumé",
    "text": "En résumé\nModèle de langue = modélisation de la langue dans son ensemble + capacité de prédiction.\nLes LLMs font de la prédiction de token :\n\nla génération de texte n’est pas la première ni la seule utilisation des LLMs.\nsoliciter un LLM pour générer un texte demande de recalculer le token le plus probable à chaque token -&gt; coût énergétique important."
  },
  {
    "objectID": "sept11/intro.html#études-critiques-de-lia",
    "href": "sept11/intro.html#études-critiques-de-lia",
    "title": "Intro",
    "section": "Études critiques de l’IA",
    "text": "Études critiques de l’IA\nDiscipline émergeante : Critical AI revue lancée en 2023.\nPistes de réflexions :\n\nUniformisation des pratiques et des modes de pensées : l’interface de chat est une façon de formaliser son problème, quid de la recherche de solution en interrogeant des moteurs de recherche, des bases de données ou des archives spécialisées ?\nDerrière l’apparente accessibilité de l’interface de chat, est-ce qu’on ne risque pas de creuser l’écart de la littératie numérique ?\nEst-ce que ces connaissances spécifiques, comme celles du code, qui impliquent des capacités de raisonnement alternatives, ne risquent pas de se retrouver suelement dans une forme d’élite intellectuelle ?\nComment peut-on définir une littéracie propre aux outils d’IA ?\nQuelle posture adopter ? Faut-il interdire l’usage dans la recherche ou l’enseignement, obliger une déclaration d’utilisation/citation ou encore laisser faire selon les usages et opter pour une approche pédagogique ?"
  },
  {
    "objectID": "sept11/intro.html#ce-quil-faut-retenir-1",
    "href": "sept11/intro.html#ce-quil-faut-retenir-1",
    "title": "Intro",
    "section": "Ce qu’il faut retenir",
    "text": "Ce qu’il faut retenir\n\nL’IA est amalgamé aux LLMs et en particulier aux interfaces de chatbots mais cela recouvre en réalité des processus algorithmiques variés.\nL’histoire de l’IA a montré qu’il y a des phases tant dans les approches valorisées que dans l’approbation de l’‘intelligence artificielle’ opposée à l’intelligence humaine.\nun système expert (symbolique) peut être aussi complexe et ‘intelligent’ qu’un LLM.\nLes systèmes d’IA n’ont pas de connaissance du réel et sont des modèles purement probabilistes.\nLes ‘halllucinations’ ne sont pas des anomalies, ce sont des erreurs que l’on qualifie a postériori comme telles.\nLes systèmes inductifs sont appropriés pour certaines tâches : classification, production de résumé. Leur point fort reste leur adaptabilité à de nouveaux contextes.\nLes chatbots sont des interfaces qui permettent un échange homme-machine en langue naturelle : l’exploitation des capacités inductives d’un LLMs ne nécessite pas de passer par une telle interface. Ex : classification, processus expérimental plus adapté à une utilisation sans cette interface."
  },
  {
    "objectID": "sept11/intro.html#ressources-vues-pendant-latelier",
    "href": "sept11/intro.html#ressources-vues-pendant-latelier",
    "title": "Intro",
    "section": "Ressources vues pendant l’atelier",
    "text": "Ressources vues pendant l’atelier\nDuck.ai\nOllama et documentation\nspaCy\nIncident Database AI\nCritical AI journal"
  },
  {
    "objectID": "ressources.html",
    "href": "ressources.html",
    "title": "Ressources des ateliers",
    "section": "",
    "text": "Programme de démo\n\n\n\nDuck.ai\nNeuronpedia\nOllama et documentation\nChainForge\n\n\n\nspaCy\nnltk"
  },
  {
    "objectID": "ressources.html#démonstration-pour-les-ateliers",
    "href": "ressources.html#démonstration-pour-les-ateliers",
    "title": "Ressources des ateliers",
    "section": "",
    "text": "Programme de démo"
  },
  {
    "objectID": "ressources.html#chatbots",
    "href": "ressources.html#chatbots",
    "title": "Ressources des ateliers",
    "section": "",
    "text": "Duck.ai\nNeuronpedia\nOllama et documentation\nChainForge"
  },
  {
    "objectID": "ressources.html#librairies-python-pour-le-traitement-automatique-des-langues",
    "href": "ressources.html#librairies-python-pour-le-traitement-automatique-des-langues",
    "title": "Ressources des ateliers",
    "section": "",
    "text": "spaCy\nnltk"
  },
  {
    "objectID": "oct09/25-10-09_correctionAtelierIA.html",
    "href": "oct09/25-10-09_correctionAtelierIA.html",
    "title": "2e séance atelier IA - révision",
    "section": "",
    "text": "Date : 9 octobre 2025\n\n\n(format de 2h) 1. Présentation de la série d’atelier 2. Qu’est-ce que l’IA ? 3. Rappel de la 1e séance : histoire, ce qu’il fallait retenir de la 1e séance 4. Place et importance de la correction 5. Outils généralistes 6. Outils spécialisés (été 2025) 7. Pistes pour l’évaluation des outils 8. Conclusions"
  },
  {
    "objectID": "oct09/25-10-09_correctionAtelierIA.html#plan",
    "href": "oct09/25-10-09_correctionAtelierIA.html#plan",
    "title": "2e séance atelier IA - révision",
    "section": "",
    "text": "(format de 2h) 1. Présentation de la série d’atelier 2. Qu’est-ce que l’IA ? 3. Rappel de la 1e séance : histoire, ce qu’il fallait retenir de la 1e séance 4. Place et importance de la correction 5. Outils généralistes 6. Outils spécialisés (été 2025) 7. Pistes pour l’évaluation des outils 8. Conclusions"
  },
  {
    "objectID": "seances/intro.html#plan",
    "href": "seances/intro.html#plan",
    "title": "Intro",
    "section": "Plan",
    "text": "Plan\nThéorie :\n\nPrésentation de la série d’atelier\nQu’est-ce que l’IA ?\nIntérêt d’étudier l’IA pour les SHS\nRetours historiques\nTypologie des IA\nCas d’usage et modélisation experte (ELIZA)\nPrincipe fondamentaux de l’apprentissage machine (modèles spécialisés)\nLes LLMs : les modèles généralistes\n\nPratique :\n\nvisualisation et manipulation d’une approche experte\nvisualisation du principe de vectorisation\nParamètres de chatbots (duck.ai)\nInterprétabilité des chatbots (Neuronpédia)\nPrompt Engineering (ChainForge)\nIntégration de chatbot localement (Ollama)"
  },
  {
    "objectID": "seances/intro.html#présentation-et-objectif-des-ateliers",
    "href": "seances/intro.html#présentation-et-objectif-des-ateliers",
    "title": "Intro",
    "section": "Présentation et objectif des ateliers",
    "text": "Présentation et objectif des ateliers\nFormat : 4 séances de 2heures, sans inscription, participation libre (à justifier pour le certificat des Humanités Numériques)\nThéorie et pratique en alternance au cours des deux heures.\nObjectifs de la série d’atelier :\n\nComprendre les fondamentaux de l’IA et son histoire\nObtenir des notions critiques sur le fonctionnement profond des outils\nTester et s’approprier des outils d’IA\nMaîtriser le vocabulaire de la discipline\n\nObjectifs de cet atelier :\n\nComprendre les différentes formes d’IA\nComprendre les enjeux liés à l’utilisation des LLM\nTester différents paramètres d’IA générative.\nInstaller localement des modèles de langue."
  },
  {
    "objectID": "seances/intro.html#quest-ce-que-lia",
    "href": "seances/intro.html#quest-ce-que-lia",
    "title": "Intro",
    "section": "Qu’est ce que l’IA ?",
    "text": "Qu’est ce que l’IA ?\n\nTout et rien : exemples : chatbot, détection sur des imageries médicales, HTR, DeepBlue.\nle dernier mot à la mode. Le ‘numérique’ des années 2020. (Vitali-Rosati 2025).\n\nDéfinition pratique : “un programme informatique qui effectue une prédiction.”\nÀ quoi sert d’étudier l’IA pour les chercheur.se.s en SHS"
  },
  {
    "objectID": "seances/intro.html#quest-ce-que-lia-1",
    "href": "seances/intro.html#quest-ce-que-lia-1",
    "title": "Intro",
    "section": "Qu’est-ce que l’IA ?",
    "text": "Qu’est-ce que l’IA ?\nDéfinition pratique : “un programme informatique qui effectue une prédiction.”"
  },
  {
    "objectID": "seances/intro.html#lia-et-les-shs",
    "href": "seances/intro.html#lia-et-les-shs",
    "title": "Intro",
    "section": "L’IA et les SHS",
    "text": "L’IA et les SHS\nQue peuvent faire les SHS pour l’IA ?\n\nparticiper à la réflexion actuelle sur son utilisation :\n\npositionnements de revues et de conférences (pose un cadre, parfois un précédent)\n\nproposer une théorie critique de l’IA décentrées de l’effet ‘benchmarking’ (i.e. comparaison des modèles ou des entreprises qui les mettent à disposition)\nproposer une avis sur l’utilisation de ces outils qui soit propre à sa discipline (ex: distinguer des usages en fonction des besoins particuliers de son domaine)."
  },
  {
    "objectID": "seances/intro.html#lia-et-les-shs-1",
    "href": "seances/intro.html#lia-et-les-shs-1",
    "title": "Intro",
    "section": "L’IA et les SHS",
    "text": "L’IA et les SHS\nÀ quoi sert d’étudier l’IA pour les chercheur.se.s en SHS"
  },
  {
    "objectID": "seances/intro.html#lia-et-les-shs-2",
    "href": "seances/intro.html#lia-et-les-shs-2",
    "title": "Intro",
    "section": "L’IA et les SHS",
    "text": "L’IA et les SHS\nQue peuvent faire les SHS pour l’IA ?\n\nparticiper à la réflexion actuelle sur son utilisation :\n\npositionnements de revues et de conférences (pose un cadre, parfois un précédent)\n\nproposer une théorie critique de l’IA décentrées de l’effet ‘benchmarking’ (i.e. comparaison des modèles ou des entreprises qui les mettent à disposition)\nproposer une avis sur l’utilisation de ces outils qui soit propre à sa discipline (ex: distinguer des usages en fonction des besoins particuliers de son domaine)."
  },
  {
    "objectID": "seances/intro.html#exemples-de-prises-de-position",
    "href": "seances/intro.html#exemples-de-prises-de-position",
    "title": "Intro",
    "section": "Exemples de prises de position",
    "text": "Exemples de prises de position\n\nBoth SUP and JHUP have increasingly embraced, tested, and deployed some AI tools and policies. Barbara has been clear in her support of responsible uses of AI and the necessity of leveraging these early days to stake a claim within the quickly evolving landscape. Like SUP, JHUP is building and testing its own tools for marketing, accessibility, and analytics, efforts which place our presses in a position to potentially build services that might in the future even benefit other university presses. (Mulliken 2025)\n\n\nwe offer recommendations for citing generative AI, defined as a tool that “can analyze or summarize content from a huge set of information, including web pages, books and other writing available on the internet, and use that data to create original new content” (Weed). (“How Do I Cite Generative AI in MLA Style?” 2023)\n\n\nThe uncomfortable truth for researchers and publishers who oppose AI slowly taking over human review is that they might not be able to prevent it. Should a researcher use AI to write the first pass of peer review and not disclose it — in contravention of publisher guidelines — that might not be detectable, says Hosseini, who is also one of the editors of the journal Accountability in Research. And if AI reviews become widespread, that could change the practice of science, says Priem. “Every researcher can run their own bespoke review service over the preprint/dataset landscape, flagging/extracting only the science they care about (at any “quality” level) they want that day,” he wrote on X earlier this year. That could start to eat into the roles of journals, by taking away the certification that peer review mediated by journals provides, he says. (Naddaf 2025)\n\n\nBuilding critical AI literacies is a process of empowerment that enables students and citizens to exercise independent judgment about whether or if to use this very new and largely untested commercial technology. (rutgersCriticalAILiteracies2024?)"
  },
  {
    "objectID": "seances/intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-1",
    "href": "seances/intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-1",
    "title": "Intro",
    "section": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 1)",
    "text": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 1)\n1940s : Science-fiction et roman d’Isaac Asimov Runaround en 1942.\nTuring (1950) : ‘can machines think?’\n‘intelligence artificielle’ : 1956\n\n« The word Artificial Intelligence was then officially coined about six years later, when in 1956 Marvin Minsky and John McCarthy (a computer scientist at Stanford) hosted the approximately eight-week-long Dartmouth Summer Research Project on Artificial Intelligence (DSRPAI) at Dartmouth College in New Hampshire. » (Haenlein and Kaplan 2019, 7)\n\n1966 : ELIZA (Weizenbaum 1966)\n1990-2000s : pic des systèmes experts et des arbres de décision. DeepBlue d’IBM (Campbell, Hoane, and Hsu 2002)."
  },
  {
    "objectID": "seances/intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-2",
    "href": "seances/intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-2",
    "title": "Intro",
    "section": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 2)",
    "text": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 2)\n2010s : pic des systèmes d’IA avec une modélisation distributionnelle du language (vecteur). Word2Vec (Mikolov et al. 2013), GloVE (Pennington, Socher, and Manning 2014). Parmi les avancées majeures de cette modélisation on compte le mécanisme d’attention (Vaswani et al. 2017) et l’encodage bidirectionnel BERT (Devlin et al. 2019) qui permettent des modèles très performants comme le GPT-3 d’OpenAI (Brown et al. 2020).\nActuellement : tendance à l’hybridation de ces modèles : Neuro-Symbolic Integration, Semantic Web Machine Learning (Marcus 2020; Breit et al. 2023)"
  },
  {
    "objectID": "seances/intro.html#typologie-de-lia",
    "href": "seances/intro.html#typologie-de-lia",
    "title": "Intro",
    "section": "Typologie de l’IA",
    "text": "Typologie de l’IA\n\nApproche experte ou modèle symbolique : modélisation d’un programme à partir de règles précises. Les règles doivent être applicables à de nouvelles données pour faire une prédiction.\nApproche inductive ou modèle d’apprentissage machine (machine learning) : modélisation d’un programme à partir d’un grand volume de données. Ce sont les motifs de répétitions qui permettent à la machine d’émettre une prédiction."
  },
  {
    "objectID": "seances/intro.html#ce-quil-faut-retenir",
    "href": "seances/intro.html#ce-quil-faut-retenir",
    "title": "Intro",
    "section": "Ce qu’il faut retenir",
    "text": "Ce qu’il faut retenir\n\nL’IA réfère à plusieurs type de modélisations pour la prédiction : une approche déductive et une approche inductive.\nOn parle ‘des saisons’ de l’IA pour évoquer l’attrait public de la discipline et son avancée depuis les années 1950.\nPar conséquent, certaines approches attirent l’attention à un moment donné, actuellement IA = chatbot voire ChatGPT.\nL’IA réfère à des algorithmes qui permettent d’automatiser une prise de décision et pas seulement à des programmes de génération textuelle."
  },
  {
    "objectID": "seances/intro.html#partons-dun-exemple",
    "href": "seances/intro.html#partons-dun-exemple",
    "title": "Intro",
    "section": "Partons d’un exemple",
    "text": "Partons d’un exemple\nObjectif : obtenir un programme capable de classer une phrase selon une thématique prédéfinie.\nExemple : Classification d’un texte soit en “parle de fruit” soit en “ne parle pas de fruit”."
  },
  {
    "objectID": "seances/intro.html#modéliser-une-approche-experte",
    "href": "seances/intro.html#modéliser-une-approche-experte",
    "title": "Intro",
    "section": "Modéliser une approche experte",
    "text": "Modéliser une approche experte\n\nfaire appel à un expert : un humain pour déterminer les règles qui définissent ce qui est une phrase parlant de fruits.\nexemple de règle possible : liste de mots comme ‘pomme, pommes, banane, poire etc.’ ordre des mots ou POS pour distinguer ‘orange’ couleur du fruit par exemple.\n\nUne approche qui sembler simpliste en apparence mais qui :\n\npeut s’avérer très complexe (ex: traduction)\nest la base de systèmes très performants\nentre dans une logique de lazy computing (Fujinaga 2025)\nrévèle les tâches de bas niveau pour passer d’une chaîne de caractères à un ensemble de caractéristiques : tokenisation, POS-tagging.\n\nProgramme de démo"
  },
  {
    "objectID": "seances/intro.html#exemple-dun-programme-conversationnel-génération-textuelle-avec-une-approche-experte-eliza",
    "href": "seances/intro.html#exemple-dun-programme-conversationnel-génération-textuelle-avec-une-approche-experte-eliza",
    "title": "Intro",
    "section": "Exemple d’un programme conversationnel /génération textuelle avec une approche experte ELIZA",
    "text": "Exemple d’un programme conversationnel /génération textuelle avec une approche experte ELIZA\nTry it yourself : ELIZA\n\nEliza is a pattern-matching automated psychiatrist. Given a set of rules in the form of input/output patterns, Eliza will attempt to recognize user input phrases and generate relevant psychobabble responses. Each rule is specified by an input pattern and a list of output patterns. A pattern is a sentence consisting of space-separated words and variables. (Connelly n.d.)\n\nExemple de literate programming (Knuth 1984) :\nLire le code d’ELIZA"
  },
  {
    "objectID": "seances/intro.html#approche-inductive-la-modélisation-vectorielle-et-le-machine-learning",
    "href": "seances/intro.html#approche-inductive-la-modélisation-vectorielle-et-le-machine-learning",
    "title": "Intro",
    "section": "Approche inductive : la modélisation vectorielle et le machine learning",
    "text": "Approche inductive : la modélisation vectorielle et le machine learning\n1e étape Modélisation des données\n\nConstitution d’un corpus : obtenir un ensemble important de documents.\nAttribution d’une classe à chaque document : annotation par un humain/expert, ground truth ou vérité de terrain.\nEncodage : Comptage des tokens dans l’ensemble du jeu de données et dans chaque phrase/document.\nOn obtient une représentation vectorielle = coordonnées dans un espace vectoriel à n dimensions.\n\n\nReprésentation vectorielle ou word embeddings2e étape Détermination de la logique de prédiction\nDifférentes logiques permettent de distinguer les données entre elles. Quelques exemples d’apprentissage machine classique :\n\nK-Nearest Neighbor -&gt; le token apartient à la même classe que ses voisins (au nombre K)\nArbre de décision -&gt; on construit un arbre de questions fermées qui dessine le jeu de données.\nRegression logistique -&gt; une ligne sépare l’espace vectoriel entre les deux classes\n\n3e étape Apprentissage\n\nDivision du jeu de données en données d’entrainement et données de test.\nCalcul des poids de chaque token (régression logistique ou arbre de décision) sur les données d’entrainement.\nPrédiction sur les données de test\nComparaison avec la vérité de terrain\nAjustement des poids : réitération de l’apprentissage si les prédictions sont insatisfaisantes. (Cette étape est très énergivore)\n\n4e étape Evaluation ou utilisation du modèle sur de nouvelles données\n\nDe nouvelles données (données d’évaluation sur une phase expériementale) qui n’ont jamais été vues par la machine, sont vectorisées aussi.\nLe programme entraîné effectue ses prédictions sur ces données."
  },
  {
    "objectID": "seances/intro.html#les-llms",
    "href": "seances/intro.html#les-llms",
    "title": "Intro",
    "section": "Les LLMs",
    "text": "Les LLMs\nExemple de LLMs : GPT-4, Mixtral, Gemini, Llama, Qwen, DeepSeek etc.\nLarge Language Models : 1. Encodage : Word embeddings ou plongement de mots obtenu par rapport à sa fréquence d’apparition en contexte avec chacun des autres mots de la langue à partir d’un volume de données textuelle gigantesque. Modèles de type BERT : encodage bilatéral avec méchanisme d’attention. 2. Spécialisation du modèle sous forme de couches neuronales pour une tâche ou une fonction précise. 3. Query et calcul pour chaque donnée en entrée du token le plus probable en sortie."
  },
  {
    "objectID": "seances/intro.html#en-résumé",
    "href": "seances/intro.html#en-résumé",
    "title": "Intro",
    "section": "En résumé",
    "text": "En résumé\nModèle de langue = modélisation de la langue dans son ensemble + capacité de prédiction.\nLes LLMs font de la prédiction de token :\n\nla génération de texte n’est pas la première ni la seule utilisation des LLMs.\nsoliciter un LLM pour générer un texte demande de recalculer le token le plus probable à chaque token -&gt; coût énergétique important."
  },
  {
    "objectID": "seances/intro.html#llms-et-chatbot",
    "href": "seances/intro.html#llms-et-chatbot",
    "title": "Intro",
    "section": "LLMs et chatbot",
    "text": "LLMs et chatbot\nParce que les LLMs sont lourds (plusieurs Gigas) et parce qu’il est coûteux en énergie d’effectuer les calculs qui permettent de déterminer le prochain token (plusieurs GPU), l’usage le plus courant des IA générative est via le site propriétaire qui va interroger le modèle sur un serveur distant. C’est la forme ChatGPT, Mistral.ai, etc."
  },
  {
    "objectID": "seances/intro.html#duck.ai",
    "href": "seances/intro.html#duck.ai",
    "title": "Intro",
    "section": "Duck.ai",
    "text": "Duck.ai\nduck.ai permet de comparer des modèles en interfaces chat tout en conservant des données privées."
  },
  {
    "objectID": "seances/intro.html#ollama",
    "href": "seances/intro.html#ollama",
    "title": "Intro",
    "section": "Ollama",
    "text": "Ollama\nIl est possible de faire tourner un SLM (small language model) localement. Pour ce faire : ollama est une bibliothèque qui permet de télécharger et d’utiliser localement un LLMs.\nInstallation et utilisation de Ollama\nTéléchargement de Ollama\nUtilisation de Ollama en invite de commande\nollama run llama3.2 -&gt; télécharge et lance le modèle.\n““” -&gt; pour des instructions longues\n/show info -&gt; information sur le modèle téléchargé\nollama list -&gt; liste des modèles téléchargés et utilisables\nollama rm llama3.2 -&gt; supprime un modèle"
  },
  {
    "objectID": "seances/intro.html#paramètres-dun-modèle",
    "href": "seances/intro.html#paramètres-dun-modèle",
    "title": "Intro",
    "section": "Paramètres d’un modèle",
    "text": "Paramètres d’un modèle\n\nLe seed (nombre que l’on peut choisir): les LLMs ont une variable aléatoire au moment de l’encodage des données et au moment du requêtage : le seed permet d’utiliser toujours le même ordre aléatoire, càd d’obtenir pour un même prompt toujours la même réponse. Enjeu de reproductibilité.\nLa température (valeur de 0 à 1): détermine le degré d’utilisation de la variable aléatoire. Une température élevée signifie que le modèle sera plus “créatif” car il donnera plus probablement un token qui a une probabilité absolue moindre dans son contexte.\ntop_k (valeur de 0 à 100): variable qui réduit la probabilité de générer des tokens absurdes. Une valeur élevée donne des réponses plus variées et une valeur basse des réponses plus conservatrices. (Défaut 40)\ntop_p (valeur de 0 à 1): Fonctionne avec le top_k. Une valeur haute donne un texte varié, une valeur basse, un texte conservateur. (Défaut: 0,9)\n\nSource : Documentation Ollama"
  },
  {
    "objectID": "seances/intro.html#model-steering",
    "href": "seances/intro.html#model-steering",
    "title": "Intro",
    "section": "Model Steering",
    "text": "Model Steering\nReconduire un modèle consiste à lui fournir des ordres qui vont modifier son comportement pour toutes les interactions.\nSteer model interactively on Neuronpedia\nTutoriel\nCréer un nouveau document ‘Modelfile’ sans extension.\nLinux : cat &gt; Modelfile puis CTRL+C :\n\nFROM llama3.2 PARAMETER temperature 1 top_k 100 top_p 1 seed 17 SYSTEM “Tu es un chien”\n\npuis CTRL+SHIFT+D et CTRL+D\nWindows cmd (Win+R): echo 'FROM llama3.2 PARAMETER temperature 1 top_k 100 top_p 1 seed 17 SYSTEM \"Tu es un chien\"' &gt; Modelfile (CTRL+SHIFT+D)\nOu c/c manuellement :\n\nFROM llama3.2 PARAMETER temperature 1 top_k 100 top_p 1 seed 17 SYSTEM “Tu es un chien”\n\nollama create chien -f Modelfile\nollama run chien"
  },
  {
    "objectID": "seances/intro.html#limites-des-interfaces-de-chat",
    "href": "seances/intro.html#limites-des-interfaces-de-chat",
    "title": "Intro",
    "section": "Limites des interfaces de chat",
    "text": "Limites des interfaces de chat\n‘hacker un LLM’ avec du prompt injection ou autres techniques de jailbreaking.\nIncitent database\n\nHidden prompts reportedly were discovered in at least 17 academic preprints on arXiv that purportedly instructed AI tools to deliver only positive peer reviews. The lead authors are reportedly affiliated with 14 institutions in eight countries, including Waseda University, KAIST, Peking University, and the University of Washington. The alleged concealed instructions, some of which were reportedly embedded using white text or tiny fonts, were purportedly intended to influence any reviewers who rely on AI tools. (https://incidentdatabase.ai/cite/1135)\n\nLes hallucinations : il n’y a pas d’hallucinations, toutes les générations produites par un LLMs ont la même teneur de vérité du point de vue de l’outil : le modèle ne peut pas évaluer sa réponse à l’aune d’un référentiel extérieur."
  },
  {
    "objectID": "seances/intro.html#études-critiques-de-lia",
    "href": "seances/intro.html#études-critiques-de-lia",
    "title": "Intro",
    "section": "Études critiques de l’IA",
    "text": "Études critiques de l’IA\nDiscipline émergente : Critical AI revue lancée en 2023.\nPistes de réflexions :\n\nUniformisation des pratiques et des modes de pensées : l’interface de chat est une façon de formaliser son problème, quid de la recherche de solution en interrogeant des moteurs de recherche, des bases de données ou des archives spécialisées ?\nDerrière l’apparente accessibilité de l’interface de chat, est-ce qu’on ne risque pas de creuser l’écart de la littératie numérique ?\nEst-ce que ces connaissances spécifiques, comme celles du code, qui impliquent des capacités de raisonnement alternatives, ne risquent pas de se retrouver suelement dans une forme d’élite intellectuelle ?\nComment peut-on définir une littéracie propre aux outils d’IA ?\nQuelle posture adopter ? Faut-il interdire l’usage dans la recherche ou l’enseignement, obliger une déclaration d’utilisation/citation ou encore laisser faire selon les usages et opter pour une approche pédagogique ?"
  },
  {
    "objectID": "seances/intro.html#ce-quil-faut-retenir-1",
    "href": "seances/intro.html#ce-quil-faut-retenir-1",
    "title": "Intro",
    "section": "Ce qu’il faut retenir",
    "text": "Ce qu’il faut retenir\n\nL’IA est amalgamé aux LLMs et en particulier aux interfaces de chatbots mais cela recouvre en réalité des processus algorithmiques variés.\nL’histoire de l’IA a montré qu’il y a des phases tant dans les approches valorisées que dans l’approbation de l’‘intelligence artificielle’ opposée à l’intelligence humaine.\nun système expert (symbolique) peut être aussi complexe et ‘intelligent’ qu’un LLM.\nLes systèmes d’IA n’ont pas de connaissance du réel et sont des modèles purement probabilistes.\nLes ‘halllucinations’ ne sont pas des anomalies, ce sont des erreurs que l’on qualifie a postériori comme telles.\nLes systèmes inductifs sont appropriés pour certaines tâches : classification, production de résumé. Leur point fort reste leur adaptabilité à de nouveaux contextes.\nLes chatbots sont des interfaces qui permettent un échange homme-machine en langue naturelle : l’exploitation des capacités inductives d’un LLMs ne nécessite pas de passer par une telle interface. Ex : classification, processus expérimental plus adapté à une utilisation sans cette interface."
  },
  {
    "objectID": "seances/intro.html#ressources-vues-pendant-latelier",
    "href": "seances/intro.html#ressources-vues-pendant-latelier",
    "title": "Intro",
    "section": "Ressources vues pendant l’atelier",
    "text": "Ressources vues pendant l’atelier\nDémo IA symbolique/IA connexioniste pour les ateliers\nDuck.ai : Comparaison de modèles sous forme de chatbot et paramétrage.\nChainForge : comparaison de prompts\nOllama et documentation : Téléchargement de LLM localement. Possibilité de steer un modèle.\nNeuronpedia ‘steer’ demo : Comparaison d’un modèle qui a été ‘redirigé’ ou non.\nNeuronpedia ‘circuit tracing’ demo : Explication du processus interne d’un LLM pour la prédiction d’un token à partir d’un prompt.\nIncident Database AI : Résumé des incidents et controverses relevées dans la presse lié aux IA (en anglais).\nCritical AI journal : Revue"
  },
  {
    "objectID": "seances/intro.html#bibliographie",
    "href": "seances/intro.html#bibliographie",
    "title": "Intro",
    "section": "Bibliographie",
    "text": "Bibliographie\n\n\n\n\n\n\n\nAmeisen, AUTHORS Emmanuel, Jack Lindsey, Adam Pearce, Wes Gurnee, Nicholas L. Turner, Brian Chen, Craig Citro, et al. 2025. “Circuit Tracing: Revealing Computational Graphs in Language Models.” Transformer Circuits. https://transformer-circuits.pub/2025/attribution-graphs/methods.html.\n\n\nBrown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. “Language Models Are Few-Shot Learners.” arXiv. https://doi.org/10.48550/arXiv.2005.14165.\n\n\nCampbell, Murray, A. Joseph Hoane, and Feng-hsiung Hsu. 2002. “Deep Blue.” Artificial Intelligence 134 (1): 57–83. https://doi.org/10.1016/S0004-3702(01)00129-1.\n\n\nConnelly, Daniel. n.d. “Eliza.py.” Eliza Emulation Python. https://dhconnelly.com/paip-python/docs/paip/eliza.html. Accessed August 20, 2025.\n\n\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.” In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), edited by Jill Burstein, Christy Doran, and Thamar Solorio, 4171–86. Minneapolis, Minnesota: Association for Computational Linguistics. https://doi.org/10.18653/v1/N19-1423.\n\n\nFujinaga, Ichiro. 2025. “On the virtues of lazy machines.” {Keynote}. Montréal.\n\n\n“How Do I Cite Generative AI in MLA Style?” 2023. MLA Style Center.\n\n\nKnuth, D. E. 1984. “Literate Programming.” The Computer Journal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nMarcus, Gary. 2020. “The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence.” arXiv. https://doi.org/10.48550/arXiv.2002.06177.\n\n\nMikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. “Efficient Estimation of Word Representations in Vector Space.” arXiv. https://doi.org/10.48550/arXiv.1301.3781.\n\n\nMulliken, Jasmine. 2025. “2025 AUPresses Week-in-Residence Report.”\n\n\nNaddaf, Miryam. 2025. “AI Is Transforming Peer Review — and Many Scientists Are Worried.” Nature 639 (8056): 852–54. https://doi.org/10.1038/d41586-025-00894-7.\n\n\nPennington, Jeffrey, Richard Socher, and Christopher Manning. 2014. “GloVe: Global Vectors for Word Representation.” In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), edited by Alessandro Moschitti, Bo Pang, and Walter Daelemans, 1532–43. Doha, Qatar: Association for Computational Linguistics. https://doi.org/10.3115/v1/D14-1162.\n\n\nRussell, Stuart J., and Peter Norvig. 2022. Artificial Intelligence: A Modern Approach. Fourth edition, global edition. Prentice Hall Series in Artificial Intelligence. Boston: Pearson.\n\n\nTuring, A. M. 1950. “Computing Machinery and Intelligence.” Mind LIX (236): 433–60. https://doi.org/10.1093/mind/LIX.236.433.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need.” arXiv. https://doi.org/10.48550/arXiv.1706.03762.\n\n\nVitali-Rosati, Marcello. 2025. “Manifeste Pour Des Études Critiques de l’Intelligence Artificielle.” Culture Numérique. Pour Une Philosophie Du Numérique.\n\n\nWeizenbaum, Joseph. 1966. “ELIZA—a Computer Program for the Study of Natural Language Communication Between Man and Machine.” Communications of the ACM 9 (1): 36–45. https://doi.org/10.1145/365153.365168."
  },
  {
    "objectID": "seances/25-10-09_correctionAtelierIA.html",
    "href": "seances/25-10-09_correctionAtelierIA.html",
    "title": "2e séance atelier IA - révision",
    "section": "",
    "text": "Date : 9 octobre 2025\n\n\n(format de 2h) 1. Présentation de la série d’atelier 2. Qu’est-ce que l’IA ? 3. Rappel de la 1e séance : histoire, ce qu’il fallait retenir de la 1e séance 4. Place et importance de la correction 5. Outils généralistes 6. Outils spécialisés (été 2025) 7. Pistes pour l’évaluation des outils 8. Conclusions"
  },
  {
    "objectID": "seances/25-10-09_correctionAtelierIA.html#plan",
    "href": "seances/25-10-09_correctionAtelierIA.html#plan",
    "title": "2e séance atelier IA - révision",
    "section": "",
    "text": "(format de 2h) 1. Présentation de la série d’atelier 2. Qu’est-ce que l’IA ? 3. Rappel de la 1e séance : histoire, ce qu’il fallait retenir de la 1e séance 4. Place et importance de la correction 5. Outils généralistes 6. Outils spécialisés (été 2025) 7. Pistes pour l’évaluation des outils 8. Conclusions"
  },
  {
    "objectID": "seances/intro.html#circuit-tracing",
    "href": "seances/intro.html#circuit-tracing",
    "title": "Intro",
    "section": "Circuit Tracing",
    "text": "Circuit Tracing\nInterprétation du méchanisme par lequel un modèle effectue produit une prédiction à partir d’un prompt.\nNeuronpedia ‘circuit tracing’ demo : Explication du processus interne d’un LLM pour la prédiction d’un token à partir d’un prompt.\n(Ameisen et al. 2025)"
  },
  {
    "objectID": "seances/intro2.html#plan",
    "href": "seances/intro2.html#plan",
    "title": "Intro",
    "section": "Plan",
    "text": "Plan\n\nPrésentation de la série d’atelier\nQu’est-ce que l’IA ?\nIntérêt d’étudier l’IA pour les SHS\nRetours historiques\nTypologie des IA\nCas d’usage et modélisation experte (ELIZA)\nCas d’usage et modélisation distributionnelle/vectorielle (vectorisation et prédiction)\nLes LLMs\nUsages des LLMs hors chatbots (demo)\nLLMs et chatbots (Duck.ai + Ollama)\nConclusions"
  },
  {
    "objectID": "seances/intro2.html#présentation-et-objectif-des-ateliers",
    "href": "seances/intro2.html#présentation-et-objectif-des-ateliers",
    "title": "Intro",
    "section": "Présentation et objectif des ateliers",
    "text": "Présentation et objectif des ateliers\nFormat : 4 séances de 2heures, sans inscription, participation libre (à justifier pour le certificat des Humanités Numériques)\nThéorie et pratique en alternance au cours des deux heures.\nObjectifs de la série d’atelier :\n\nComprendre les fondamentaux de l’IA et son histoire\nObtenir des notions critiques sur le fonctionnement profond des outils\nTester et s’approprier des outils d’IA\nMaîtriser le vocabulaire de la discipline\n\nObjectifs de cet atelier :\n\nComprendre les différentes formes d’IA\nComprendre les enjeux liés à l’utilisation des LLM\nTester différents paramètres d’IA générative.\nInstaller localement des modèles de langue."
  },
  {
    "objectID": "seances/intro2.html#certificat-canadien-en-humanités-numériques",
    "href": "seances/intro2.html#certificat-canadien-en-humanités-numériques",
    "title": "Intro",
    "section": "Certificat canadien en Humanités Numériques",
    "text": "Certificat canadien en Humanités Numériques\n\n\nCertificat canadien en HN\n\n\n\n \nInformation sur le certificat"
  },
  {
    "objectID": "seances/intro2.html#quest-ce-que-lia",
    "href": "seances/intro2.html#quest-ce-que-lia",
    "title": "Intro",
    "section": "Qu’est ce que l’IA ?",
    "text": "Qu’est ce que l’IA ?\n\nTout et rien : exemples : chatbot, détection sur des imageries médicales, HTR, DeepBlue.\nle dernier mot à la mode. Le ‘numérique’ des années 2020. (Vitali-Rosati 2025).\n\nDéfinition pratique : “un programme informatique qui effectue une prédiction.”\nÀ quoi sert d’étudier l’IA pour les chercheur.se.s en SHS"
  },
  {
    "objectID": "seances/intro2.html#lia-et-les-shs",
    "href": "seances/intro2.html#lia-et-les-shs",
    "title": "Intro",
    "section": "L’IA et les SHS",
    "text": "L’IA et les SHS\nQue peuvent faire les SHS pour l’IA ?\n\nparticiper à la réflexion actuelle sur son utilisation :\n\npositionnements de revues et de conférences (pose un cadre, parfois un précédent)\n\nproposer une théorie critique de l’IA décentrées de l’effet ‘benchmarking’ (i.e. comparaison des modèles ou des entreprises qui les mettent à disposition)\nproposer une avis sur l’utilisation de ces outils qui soit propre à sa discipline (ex: distinguer des usages en fonction des besoins particuliers de son domaine)."
  },
  {
    "objectID": "seances/intro2.html#exemples-de-prises-de-position",
    "href": "seances/intro2.html#exemples-de-prises-de-position",
    "title": "Intro",
    "section": "Exemples de prises de position",
    "text": "Exemples de prises de position\n\nBoth SUP and JHUP have increasingly embraced, tested, and deployed some AI tools and policies. Barbara has been clear in her support of responsible uses of AI and the necessity of leveraging these early days to stake a claim within the quickly evolving landscape. Like SUP, JHUP is building and testing its own tools for marketing, accessibility, and analytics, efforts which place our presses in a position to potentially build services that might in the future even benefit other university presses. (Mulliken 2025)\n\n\nwe offer recommendations for citing generative AI, defined as a tool that “can analyze or summarize content from a huge set of information, including web pages, books and other writing available on the internet, and use that data to create original new content” (Weed). (“How Do I Cite Generative AI in MLA Style?” 2023)\n\n\nThe uncomfortable truth for researchers and publishers who oppose AI slowly taking over human review is that they might not be able to prevent it. Should a researcher use AI to write the first pass of peer review and not disclose it — in contravention of publisher guidelines — that might not be detectable, says Hosseini, who is also one of the editors of the journal Accountability in Research. And if AI reviews become widespread, that could change the practice of science, says Priem. “Every researcher can run their own bespoke review service over the preprint/dataset landscape, flagging/extracting only the science they care about (at any “quality” level) they want that day,” he wrote on X earlier this year. That could start to eat into the roles of journals, by taking away the certification that peer review mediated by journals provides, he says. (Naddaf 2025)\n\n\nBuilding critical AI literacies is a process of empowerment that enables students and citizens to exercise independent judgment about whether or if to use this very new and largely untested commercial technology. (rutgersCriticalAILiteracies2024?)"
  },
  {
    "objectID": "seances/intro2.html#brève-histoire-de-lia-pt.-1",
    "href": "seances/intro2.html#brève-histoire-de-lia-pt.-1",
    "title": "Intro",
    "section": "Brève histoire de l’IA (pt. 1)",
    "text": "Brève histoire de l’IA (pt. 1)\n(1940s : Science-fiction et roman d’Isaac Asimov Runaround en 1942.)\n(Turing 1950) : ‘can machines think?’\n1956: ‘intelligence artificielle’, Minsky et McCarthy à la Dartmouth Summer Research Project on Artificial Intelligence (DSRPAI).\n1966 : ELIZA (Weizenbaum 1966)\n1990-2000s : pic des systèmes experts et des arbres de décision. DeepBlue d’IBM (Campbell, Hoane, and Hsu 2002)."
  },
  {
    "objectID": "seances/intro2.html#brève-histoire-de-lia-pt.-2",
    "href": "seances/intro2.html#brève-histoire-de-lia-pt.-2",
    "title": "Intro",
    "section": "Brève histoire de l’IA (pt. 2)",
    "text": "Brève histoire de l’IA (pt. 2)\n2010s : pic des systèmes d’IA avec une modélisation distributionnelle du language (vecteur). Word2Vec (Mikolov et al. 2013), GloVE (Pennington, Socher, and Manning 2014). Parmi les avancées majeures de cette modélisation on compte le mécanisme d’attention (Vaswani et al. 2017) et l’encodage bidirectionnel BERT (Devlin et al. 2019) qui permettent des modèles très performants comme le GPT-3 d’OpenAI (Brown et al. 2020).\nActuellement : tendance à l’hybridation de ces modèles : Neuro-Symbolic Integration, Semantic Web Machine Learning (Marcus 2020), {{&lt; cite \"kautzThirdAISummer2022\"&gt;}}, (Russell and Norvig 2022)"
  },
  {
    "objectID": "seances/intro2.html#typologie-de-lia",
    "href": "seances/intro2.html#typologie-de-lia",
    "title": "Intro",
    "section": "Typologie de l’IA",
    "text": "Typologie de l’IA\n\nApproche experte ou modèle symbolique : modélisation d’un programme à partir de règles précises. Les règles doivent être applicables à de nouvelles données pour faire une prédiction.\nApproche inductive ou modèle d’apprentissage machine (machine learning) : modélisation d’un programme à partir d’un grand volume de données. Ce sont les motifs de répétitions qui permettent à la machine d’émettre une prédiction."
  },
  {
    "objectID": "seances/intro2.html#ce-quil-faut-retenir",
    "href": "seances/intro2.html#ce-quil-faut-retenir",
    "title": "Intro",
    "section": "Ce qu’il faut retenir",
    "text": "Ce qu’il faut retenir\n\nL’IA réfère à plusieurs type de modélisations pour la prédiction : une approche déductive et une approche inductive.\nOn parle ‘des saisons’ de l’IA pour évoquer l’attrait public de la discipline et son avancée depuis les années 1950.\nPar conséquent, certaines approches attirent l’attention à un moment donné, actuellement IA = chatbot voire ChatGPT.\nL’IA réfère à des algorithmes qui permettent d’automatiser une prise de décision et pas seulement à des programmes de génération textuelle."
  },
  {
    "objectID": "seances/intro2.html#partons-dun-exemple",
    "href": "seances/intro2.html#partons-dun-exemple",
    "title": "Intro",
    "section": "Partons d’un exemple",
    "text": "Partons d’un exemple\nObjectif : obtenir un programme capable de classer une phrase selon une thématique prédéfinie.\nExemple : Classification d’un texte soit en “parle de fruit” soit en “ne parle pas de fruit”."
  },
  {
    "objectID": "seances/intro2.html#modéliser-une-approche-experte",
    "href": "seances/intro2.html#modéliser-une-approche-experte",
    "title": "Intro",
    "section": "Modéliser une approche experte",
    "text": "Modéliser une approche experte\n\nfaire appel à un expert : un humain pour déterminer les règles qui définissent ce qui est une phrase parlant de fruits.\nexemple de règle possible : liste de mots comme ‘pomme, pommes, banane, poire etc.’ ordre des mots ou POS pour distinguer ‘orange’ couleur du fruit par exemple.\n\nUne approche qui sembler simpliste en apparence mais qui :\n\npeut s’avérer très complexe (ex: traduction)\nest la base de systèmes très performants\nentre dans une logique de lazy computing (Fujinaga 2025)\nrévèle les tâches de bas niveau pour passer d’une chaîne de caractères à un ensemble de caractéristiques : tokenisation, POS-tagging.\n\nProgramme de démo"
  },
  {
    "objectID": "seances/intro2.html#exemple-dun-programme-conversationnel-génération-textuelle-avec-une-approche-experte-eliza",
    "href": "seances/intro2.html#exemple-dun-programme-conversationnel-génération-textuelle-avec-une-approche-experte-eliza",
    "title": "Intro",
    "section": "Exemple d’un programme conversationnel /génération textuelle avec une approche experte ELIZA",
    "text": "Exemple d’un programme conversationnel /génération textuelle avec une approche experte ELIZA\nTry it yourself : ELIZA\n\nEliza is a pattern-matching automated psychiatrist. Given a set of rules in the form of input/output patterns, Eliza will attempt to recognize user input phrases and generate relevant psychobabble responses. Each rule is specified by an input pattern and a list of output patterns. A pattern is a sentence consisting of space-separated words and variables. (Connelly n.d.)\n\nExemple de literate programming (Knuth 1984) :\nLire le code d’ELIZA"
  },
  {
    "objectID": "seances/intro2.html#approche-inductive-le-machine-learning-classique",
    "href": "seances/intro2.html#approche-inductive-le-machine-learning-classique",
    "title": "Intro",
    "section": "Approche inductive : le machine learning classique",
    "text": "Approche inductive : le machine learning classique\n1e étape Modélisation des données\n\nConstitution d’un corpus : obtenir un ensemble important de documents\nAnnotation : attribution d’une classe à chaque document par un humain/expert, ground truth ou vérité de terrain.\nEncodage vectoriel : Comptage des tokens dans l’ensemble du jeu de données et dans chaque phrase/document.\nOn obtient une représentation vectorielle = coordonnées dans un espace vectoriel à n dimensions.\n\n2e étape Choix de l’algorithme de classification\nDifférentes logiques permettent de distinguer les données entre elles. Quelques exemples d’apprentissage machine classique :\n\nK-Nearest Neighbor -&gt; le token apartient à la même classe que ses voisins (au nombre K)\nArbre de décision -&gt; on construit un arbre de questions fermées qui dessine le jeu de données.\nRegression logistique -&gt; une ligne sépare l’espace vectoriel entre les deux classes\n\n3e étape Entraînement supervisé : apprentissage spécialisé\nAjustement des poids (valeurs des vecteurs) à partir de données spécialisées\nProgramme de démo"
  },
  {
    "objectID": "seances/intro2.html#approche-inductive-généraliste-les-llms",
    "href": "seances/intro2.html#approche-inductive-généraliste-les-llms",
    "title": "Intro",
    "section": "Approche inductive généraliste : les LLMs",
    "text": "Approche inductive généraliste : les LLMs\nExemple de LLMs : BERT, GPT-4, Mixtral, Gemini, Llama, Qwen, DeepSeek etc.\nFoundational models : Pré-entrainement\nConstitution d’un corpus non annoté\nApprentissage auto-supervisé : le modèle apprend à prédire le mot suivant ou remplir un blanc dans une phrase.\nEncodage itératif : chaque mot/token est encodé en vecteur (embeddings) et le réseau ajuste ses poids en fonction du contexte.\nDès cette étape on obtient un modèle généraliste capable de faire des prédictions à partir d’une requête en langue naturelle.\nFine-tuning affinage.\nSpécialisation du modèle sur une tâche précise à partir d’un jeu de données annotées.\nAlignement\nInstruction-tuning : entraînement supervisé sur des données “question → réponse”.\nReinforcement Learning with Human Feedback : des annotateurs évaluent les sorties du modèle, et un apprentissage par renforcement ajuste les préférences du modèle."
  },
  {
    "objectID": "seances/intro2.html#en-résumé",
    "href": "seances/intro2.html#en-résumé",
    "title": "Intro",
    "section": "En résumé",
    "text": "En résumé\nModèle de langue = modélisation de la langue dans son ensemble + capacité de prédiction.\nLes LLMs font de la prédiction de token :\n\nla génération de texte n’est pas la première ni la seule utilisation des LLMs.\nsoliciter un LLM pour générer un texte demande de recalculer le token le plus probable à chaque token -&gt; coût énergétique important."
  },
  {
    "objectID": "seances/intro2.html#llms-et-chatbot",
    "href": "seances/intro2.html#llms-et-chatbot",
    "title": "Intro",
    "section": "LLMs et chatbot",
    "text": "LLMs et chatbot\nParce que les LLMs sont lourds (plusieurs Gigas) et parce qu’il est coûteux en énergie d’effectuer les calculs qui permettent de déterminer le prochain token (plusieurs GPU), l’usage le plus courant des IA générative est via le site propriétaire qui va interroger le modèle sur un serveur distant. C’est la forme ChatGPT, Mistral.ai, etc."
  },
  {
    "objectID": "seances/intro2.html#duck.ai",
    "href": "seances/intro2.html#duck.ai",
    "title": "Intro",
    "section": "Duck.ai",
    "text": "Duck.ai\nduck.ai permet de comparer des modèles en interfaces chat tout en conservant des données privées."
  },
  {
    "objectID": "seances/intro2.html#circuit-tracing",
    "href": "seances/intro2.html#circuit-tracing",
    "title": "Intro",
    "section": "Circuit Tracing",
    "text": "Circuit Tracing\nInterprétation du méchanisme par lequel un modèle effectue produit une prédiction à partir d’un prompt.\nNeuronpedia ‘circuit tracing’ demo : Explication du processus interne d’un LLM pour la prédiction d’un token à partir d’un prompt.\n(Ameisen et al. 2025)"
  },
  {
    "objectID": "seances/intro2.html#ollama",
    "href": "seances/intro2.html#ollama",
    "title": "Intro",
    "section": "Ollama",
    "text": "Ollama\nIl est possible de faire tourner un SLM (small language model) localement. Pour ce faire : ollama est une bibliothèque qui permet de télécharger et d’utiliser localement un LLMs.\nInstallation et utilisation de Ollama\nTéléchargement de Ollama\nUtilisation de Ollama en invite de commande\nollama run llama3.2 -&gt; télécharge et lance le modèle.\n““” -&gt; pour des instructions longues\n/show info -&gt; information sur le modèle téléchargé\nollama list -&gt; liste des modèles téléchargés et utilisables\nollama rm llama3.2 -&gt; supprime un modèle"
  },
  {
    "objectID": "seances/intro2.html#paramètres-dun-modèle",
    "href": "seances/intro2.html#paramètres-dun-modèle",
    "title": "Intro",
    "section": "Paramètres d’un modèle",
    "text": "Paramètres d’un modèle\n\nLe seed (nombre que l’on peut choisir): les LLMs ont une variable aléatoire au moment de l’encodage des données et au moment du requêtage : le seed permet d’utiliser toujours le même ordre aléatoire, càd d’obtenir pour un même prompt toujours la même réponse. Enjeu de reproductibilité.\nLa température (valeur de 0 à 1): détermine le degré d’utilisation de la variable aléatoire. Une température élevée signifie que le modèle sera plus “créatif” car il donnera plus probablement un token qui a une probabilité absolue moindre dans son contexte.\ntop_k (valeur de 0 à 100): variable qui réduit la probabilité de générer des tokens absurdes. Une valeur élevée donne des réponses plus variées et une valeur basse des réponses plus conservatrices. (Défaut 40)\ntop_p (valeur de 0 à 1): Fonctionne avec le top_k. Une valeur haute donne un texte varié, une valeur basse, un texte conservateur. (Défaut: 0,9)\n\nSource : Documentation Ollama"
  },
  {
    "objectID": "seances/intro2.html#model-steering-ou-system-message",
    "href": "seances/intro2.html#model-steering-ou-system-message",
    "title": "Intro",
    "section": "Model Steering ou System message",
    "text": "Model Steering ou System message\nReconduire un modèle consiste à lui fournir des ordres qui vont modifier son comportement pour toutes les interactions suivantes : cette instruction initiale est le “System message”.\nSteer model interactively on Neuronpedia\nTutoriel\nCréer un nouveau document ‘Modelfile’ sans extension.\nLinux : cat &gt; Modelfile puis CTRL+C :\n\nFROM llama3.2 PARAMETER temperature 1 top_k 100 top_p 1 seed 17 SYSTEM “Tu es un chien”\n\npuis CTRL+SHIFT+D et CTRL+D\nWindows cmd (Win+R): echo 'FROM llama3.2 PARAMETER temperature 1 top_k 100 top_p 1 seed 17 SYSTEM \"Tu es un chien\"' &gt; Modelfile (CTRL+SHIFT+D)\nOu c/c manuellement :\n\nFROM llama3.2 PARAMETER temperature 1 top_k 100 top_p 1 seed 17 SYSTEM “Tu es un chien”\n\nollama create chien -f Modelfile\nollama run chien"
  },
  {
    "objectID": "seances/intro2.html#limites-des-interfaces-de-chat",
    "href": "seances/intro2.html#limites-des-interfaces-de-chat",
    "title": "Intro",
    "section": "Limites des interfaces de chat",
    "text": "Limites des interfaces de chat\n‘hacker un LLM’ avec du prompt injection ou autres techniques de jailbreaking.\nIncitent database\n\nHidden prompts reportedly were discovered in at least 17 academic preprints on arXiv that purportedly instructed AI tools to deliver only positive peer reviews. The lead authors are reportedly affiliated with 14 institutions in eight countries, including Waseda University, KAIST, Peking University, and the University of Washington. The alleged concealed instructions, some of which were reportedly embedded using white text or tiny fonts, were purportedly intended to influence any reviewers who rely on AI tools. (https://incidentdatabase.ai/cite/1135)\n\nLes hallucinations : il n’y a pas d’hallucinations, toutes les générations produites par un LLMs ont la même teneur de vérité du point de vue de l’outil : le modèle ne peut pas évaluer sa réponse à l’aune d’un référentiel extérieur."
  },
  {
    "objectID": "seances/intro2.html#études-critiques-de-lia",
    "href": "seances/intro2.html#études-critiques-de-lia",
    "title": "Intro",
    "section": "Études critiques de l’IA",
    "text": "Études critiques de l’IA\nDiscipline émergente : Critical AI revue lancée en 2023.\nPistes de réflexions :\n\nUniformisation des pratiques et des modes de pensées : l’interface de chat est une façon de formaliser son problème, quid de la recherche de solution en interrogeant des moteurs de recherche, des bases de données ou des archives spécialisées ?\nDerrière l’apparente accessibilité de l’interface de chat, est-ce qu’on ne risque pas de creuser l’écart de la littératie numérique ?\nEst-ce que ces connaissances spécifiques, comme celles du code, qui impliquent des capacités de raisonnement alternatives, ne risquent pas de se retrouver suelement dans une forme d’élite intellectuelle ?\nComment peut-on définir une littéracie propre aux outils d’IA ?\nQuelle posture adopter ? Faut-il interdire l’usage dans la recherche ou l’enseignement, obliger une déclaration d’utilisation/citation ou encore laisser faire selon les usages et opter pour une approche pédagogique ?"
  },
  {
    "objectID": "seances/intro2.html#ce-quil-faut-retenir-1",
    "href": "seances/intro2.html#ce-quil-faut-retenir-1",
    "title": "Intro",
    "section": "Ce qu’il faut retenir",
    "text": "Ce qu’il faut retenir\n\nL’IA est amalgamé aux LLMs et en particulier aux interfaces de chatbots mais cela recouvre en réalité des processus algorithmiques variés.\nL’histoire de l’IA a montré qu’il y a des phases tant dans les approches valorisées que dans l’approbation de l’‘intelligence artificielle’ opposée à l’intelligence humaine.\nun système expert (symbolique) peut être aussi complexe et ‘intelligent’ qu’un LLM.\nLes systèmes d’IA n’ont pas de connaissance du réel et sont des modèles purement probabilistes.\nLes ‘halllucinations’ ne sont pas des anomalies, ce sont des erreurs que l’on qualifie a postériori comme telles.\nLes systèmes inductifs sont appropriés pour certaines tâches : classification, production de résumé. Leur point fort reste leur adaptabilité à de nouveaux contextes.\nLes chatbots sont des interfaces qui permettent un échange homme-machine en langue naturelle : l’exploitation des capacités inductives d’un LLMs ne nécessite pas de passer par une telle interface. Ex : classification, processus expérimental plus adapté à une utilisation sans cette interface."
  },
  {
    "objectID": "seances/intro2.html#ressources-vues-pendant-latelier",
    "href": "seances/intro2.html#ressources-vues-pendant-latelier",
    "title": "Intro",
    "section": "Ressources vues pendant l’atelier",
    "text": "Ressources vues pendant l’atelier\nDémo IA symbolique/IA connexioniste pour les ateliers\nDuck.ai : Comparaison de modèles sous forme de chatbot et paramétrage.\nOllama et documentation : Téléchargement de LLM localement. Possibilité de steer un modèle.\nNeuronpedia ‘steer’ demo : Comparaison d’un modèle qui a été ‘redirigé’ ou non.\nNeuronpedia ‘circuit tracing’ demo : Explication du processus interne d’un LLM pour la prédiction d’un token à partir d’un prompt.\nIncident Database AI : Résumé des incidents et controverses relevées dans la presse lié aux IA (en anglais).\nCritical AI journal : Revue"
  },
  {
    "objectID": "seances/intro2.html#annexe-glossaire",
    "href": "seances/intro2.html#annexe-glossaire",
    "title": "Intro",
    "section": "Annexe : glossaire",
    "text": "Annexe : glossaire\ndocument : ici une phrase\nclasses : ensemble thématique de la classification. Ex : “fruit” et “non fruit” pour la classification binaire de notre exemple.\njeu de données : ensemble des documents\napprentissage supervisé : méthode d’apprentissage machine à partir de classes connues.\napprentissage non-supervisé : méthode d’apprentissage machine sans connaître les classes à l’avance : a pour objectif de déterminer les caractéristiques discriminantes d’un jeu de données.\nvérité de terrain ou ground truth : annotation effectuée par un humain sur l’ensemble du jeu de données."
  },
  {
    "objectID": "seances/intro2.html#bibliographie",
    "href": "seances/intro2.html#bibliographie",
    "title": "Intro",
    "section": "Bibliographie",
    "text": "Bibliographie\n\n\n\n\n\n\n\nAmeisen, AUTHORS Emmanuel, Jack Lindsey, Adam Pearce, Wes Gurnee, Nicholas L. Turner, Brian Chen, Craig Citro, et al. 2025. “Circuit Tracing: Revealing Computational Graphs in Language Models.” Transformer Circuits. https://transformer-circuits.pub/2025/attribution-graphs/methods.html.\n\n\nBrown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. “Language Models Are Few-Shot Learners.” arXiv. https://doi.org/10.48550/arXiv.2005.14165.\n\n\nCampbell, Murray, A. Joseph Hoane, and Feng-hsiung Hsu. 2002. “Deep Blue.” Artificial Intelligence 134 (1): 57–83. https://doi.org/10.1016/S0004-3702(01)00129-1.\n\n\nConnelly, Daniel. n.d. “Eliza.py.” Eliza Emulation Python. https://dhconnelly.com/paip-python/docs/paip/eliza.html. Accessed August 20, 2025.\n\n\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.” In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), edited by Jill Burstein, Christy Doran, and Thamar Solorio, 4171–86. Minneapolis, Minnesota: Association for Computational Linguistics. https://doi.org/10.18653/v1/N19-1423.\n\n\nFujinaga, Ichiro. 2025. “On the virtues of lazy machines.” {Keynote}. Montréal.\n\n\n“How Do I Cite Generative AI in MLA Style?” 2023. MLA Style Center.\n\n\nKnuth, D. E. 1984. “Literate Programming.” The Computer Journal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nMarcus, Gary. 2020. “The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence.” arXiv. https://doi.org/10.48550/arXiv.2002.06177.\n\n\nMikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. “Efficient Estimation of Word Representations in Vector Space.” arXiv. https://doi.org/10.48550/arXiv.1301.3781.\n\n\nMulliken, Jasmine. 2025. “2025 AUPresses Week-in-Residence Report.”\n\n\nNaddaf, Miryam. 2025. “AI Is Transforming Peer Review — and Many Scientists Are Worried.” Nature 639 (8056): 852–54. https://doi.org/10.1038/d41586-025-00894-7.\n\n\nPennington, Jeffrey, Richard Socher, and Christopher Manning. 2014. “GloVe: Global Vectors for Word Representation.” In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), edited by Alessandro Moschitti, Bo Pang, and Walter Daelemans, 1532–43. Doha, Qatar: Association for Computational Linguistics. https://doi.org/10.3115/v1/D14-1162.\n\n\nRussell, Stuart J., and Peter Norvig. 2022. Artificial Intelligence: A Modern Approach. Fourth edition, global edition. Prentice Hall Series in Artificial Intelligence. Boston: Pearson.\n\n\nTuring, A. M. 1950. “Computing Machinery and Intelligence.” Mind LIX (236): 433–60. https://doi.org/10.1093/mind/LIX.236.433.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need.” arXiv. https://doi.org/10.48550/arXiv.1706.03762.\n\n\nVitali-Rosati, Marcello. 2025. “Manifeste Pour Des Études Critiques de l’Intelligence Artificielle.” Culture Numérique. Pour Une Philosophie Du Numérique.\n\n\nWeizenbaum, Joseph. 1966. “ELIZA—a Computer Program for the Study of Natural Language Communication Between Man and Machine.” Communications of the ACM 9 (1): 36–45. https://doi.org/10.1145/365153.365168."
  },
  {
    "objectID": "seances/intro.html#certificat-canadien-en-humanités-numériques",
    "href": "seances/intro.html#certificat-canadien-en-humanités-numériques",
    "title": "Intro",
    "section": "Certificat canadien en Humanités Numériques",
    "text": "Certificat canadien en Humanités Numériques\n\n\nCertificat canadien en HN\n\n\n\n \nInformation sur le certificat"
  },
  {
    "objectID": "seances/intro.html#brève-histoire-de-lia-pt.-1",
    "href": "seances/intro.html#brève-histoire-de-lia-pt.-1",
    "title": "Intro",
    "section": "Brève histoire de l’IA (pt. 1)",
    "text": "Brève histoire de l’IA (pt. 1)\n(1940s : Science-fiction et roman d’Isaac Asimov Runaround en 1942.)\n(Turing 1950) : ‘can machines think?’\n1956: ‘intelligence artificielle’, Minsky et McCarthy à la Dartmouth Summer Research Project on Artificial Intelligence (DSRPAI).\n1966 : ELIZA (Weizenbaum 1966)\n1990-2000s : pic des systèmes experts et des arbres de décision. DeepBlue d’IBM (Campbell, Hoane, and Hsu 2002)."
  },
  {
    "objectID": "seances/intro.html#brève-histoire-de-lia-pt.-2",
    "href": "seances/intro.html#brève-histoire-de-lia-pt.-2",
    "title": "Intro",
    "section": "Brève histoire de l’IA (pt. 2)",
    "text": "Brève histoire de l’IA (pt. 2)\n2010s : pic des systèmes d’IA avec une modélisation distributionnelle du language (vecteur). Word2Vec (Mikolov et al. 2013), GloVE (Pennington, Socher, and Manning 2014). Parmi les avancées majeures de cette modélisation on compte le mécanisme d’attention (Vaswani et al. 2017) et l’encodage bidirectionnel BERT (Devlin et al. 2019) qui permettent des modèles très performants comme le GPT-3 d’OpenAI (Brown et al. 2020).\nActuellement : tendance à l’hybridation de ces modèles : Neuro-Symbolic Integration, Semantic Web Machine Learning (Marcus 2020), {{&lt; cite \"kautzThirdAISummer2022\"&gt;}}, (Russell and Norvig 2022)"
  },
  {
    "objectID": "seances/intro.html#approche-inductive-le-machine-learning-classique",
    "href": "seances/intro.html#approche-inductive-le-machine-learning-classique",
    "title": "Intro",
    "section": "Approche inductive : le machine learning classique",
    "text": "Approche inductive : le machine learning classique\n1e étape Modélisation des données\n\nConstitution d’un corpus : obtenir un ensemble important de documents\nAnnotation : attribution d’une classe à chaque document par un humain/expert, ground truth ou vérité de terrain.\nEncodage vectoriel : Comptage des tokens dans l’ensemble du jeu de données et dans chaque phrase/document.\nOn obtient une représentation vectorielle = coordonnées dans un espace vectoriel à n dimensions.\n\n2e étape Choix de l’algorithme de classification\nDifférentes logiques permettent de distinguer les données entre elles. Quelques exemples d’apprentissage machine classique :\n\nK-Nearest Neighbor -&gt; le token apartient à la même classe que ses voisins (au nombre K)\nArbre de décision -&gt; on construit un arbre de questions fermées qui dessine le jeu de données.\nRegression logistique -&gt; une ligne sépare l’espace vectoriel entre les deux classes\n\n3e étape Entraînement supervisé : apprentissage spécialisé\nAjustement des poids (valeurs des vecteurs) à partir de données spécialisées\nProgramme de démo"
  },
  {
    "objectID": "seances/intro.html#approche-inductive-généraliste-les-llms",
    "href": "seances/intro.html#approche-inductive-généraliste-les-llms",
    "title": "Intro",
    "section": "Approche inductive généraliste : les LLMs",
    "text": "Approche inductive généraliste : les LLMs\nExemple de LLMs : BERT, GPT-4, Mixtral, Gemini, Llama, Qwen, DeepSeek etc.\nFoundational models : Pré-entrainement\nConstitution d’un corpus non annoté\nApprentissage auto-supervisé : le modèle apprend à prédire le mot suivant ou remplir un blanc dans une phrase.\nEncodage itératif : chaque mot/token est encodé en vecteur (embeddings) et le réseau ajuste ses poids en fonction du contexte.\nDès cette étape on obtient un modèle généraliste capable de faire des prédictions à partir d’une requête en langue naturelle.\nFine-tuning affinage.\nSpécialisation du modèle sur une tâche précise à partir d’un jeu de données annotées.\nAlignement\nInstruction-tuning : entraînement supervisé sur des données “question → réponse”.\nReinforcement Learning with Human Feedback : des annotateurs évaluent les sorties du modèle, et un apprentissage par renforcement ajuste les préférences du modèle."
  },
  {
    "objectID": "seances/intro.html#model-steering-ou-system-message",
    "href": "seances/intro.html#model-steering-ou-system-message",
    "title": "Intro",
    "section": "Model Steering ou System message",
    "text": "Model Steering ou System message\nReconduire un modèle consiste à lui fournir des ordres qui vont modifier son comportement pour toutes les interactions suivantes : cette instruction initiale est le “System message”.\nSteer model interactively on Neuronpedia\nTutoriel\nCréer un nouveau document ‘Modelfile’ sans extension.\nLinux : cat &gt; Modelfile puis CTRL+C :\n\nFROM llama3.2 PARAMETER temperature 1 top_k 100 top_p 1 seed 17 SYSTEM “Tu es un chien”\n\npuis CTRL+SHIFT+D et CTRL+D\nWindows cmd (Win+R): echo 'FROM llama3.2 PARAMETER temperature 1 top_k 100 top_p 1 seed 17 SYSTEM \"Tu es un chien\"' &gt; Modelfile (CTRL+SHIFT+D)\nOu c/c manuellement :\n\nFROM llama3.2 PARAMETER temperature 1 top_k 100 top_p 1 seed 17 SYSTEM “Tu es un chien”\n\nollama create chien -f Modelfile\nollama run chien"
  },
  {
    "objectID": "seances/intro.html#le-prompt-engineering",
    "href": "seances/intro.html#le-prompt-engineering",
    "title": "Intro",
    "section": "Le prompt engineering",
    "text": "Le prompt engineering\nRendre un prompt robuste et surtout permettre l’évaluation systématique d’une stratégie de prompt. Réintégrer une forme de modélisation de son problème pour optimiser un prompt : le template.\nChainForge : outil de comparaison de prompt : comparaison de modèle, comparaison de template (un texte qui inclut des variables) visualisation côte à côte des sorties."
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#plan-de-latelier",
    "href": "seances/atelier2-correction-auto.html#plan-de-latelier",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Plan de l’atelier",
    "text": "Plan de l’atelier\nThéorie :\n\nRappels sur les fondements de l’IA (30min) (AS)\nPrésentation historico-technique des systèmes de GEC (15min) (AS)\nChangement de paradigme : de l’ortho-typo à la reformulation voire la génération de contenu (10min) (CG + AS)\nProblématique : quel csq sur le travail de recherche ? (CG)\nChangement de système de valeur : négligence dans cette étape de relecture et correction qui a des csq épistémologiques (CG) (30min avec discussion)\nLangue = norme et normalisation politique (CG) (10min)\nPrésentation des outils (AS) (25min avec discussion)\nconclusion/ce qu’il faut retenir (5min)"
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#présentation-et-objectif-des-ateliers",
    "href": "seances/atelier2-correction-auto.html#présentation-et-objectif-des-ateliers",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Présentation et objectif des ateliers",
    "text": "Présentation et objectif des ateliers\nFormat : 4 séances de 2heures, sans inscription, participation libre (à justifier pour le certificat des Humanités Numériques)\nThéorie et pratique.\nObjectifs de la série d’atelier :\n\nComprendre les fondamentaux de l’IA et son histoire\nObtenir des notions critiques sur le fonctionnement profond des outils\nTester et s’approprier des outils d’IA\nMaîtriser le vocabulaire de la discipline\n\nObjectifs de cet atelier :\n\nCerner un cas d’usage courant des IA générative : la correction ortho-typographique.\nS’interroger l’impact de ces nouvelles pratiques dans le travail de recherche.\nTester et comparer des outils courants.\nDéfinir des critères pour effectuer un choix éclairé vis-à-vis des outils disponibles"
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#certificat-canadien-en-humanités-numériques",
    "href": "seances/atelier2-correction-auto.html#certificat-canadien-en-humanités-numériques",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Certificat canadien en Humanités Numériques",
    "text": "Certificat canadien en Humanités Numériques\n\n\nCertificat canadien en HN\n\n\n\n \nInformation sur le certificat"
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#quest-ce-que-lia",
    "href": "seances/atelier2-correction-auto.html#quest-ce-que-lia",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Qu’est ce que l’IA ?",
    "text": "Qu’est ce que l’IA ?\nDes programmes informatiques qui nous semblent dignes d’être comparé aux humains : une définition qui évolue avec les technologies.\nPeut-être depuis 2020, le dernier mot à la mode après ‘numérique’ dans les années 2010, et cyberespace dans les années 1990 et 2000.(Vitali-Rosati 2025).\n\nDéfinition pratique pour ces ateliers: un programme informatique qui effectue une prédiction."
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#rappels-de-lintroduction",
    "href": "seances/atelier2-correction-auto.html#rappels-de-lintroduction",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Rappels de l’introduction",
    "text": "Rappels de l’introduction\n\nLes programmes d’IA réfèrent à des processus algorithmiques variés et pas seulement à des chatbots type ChatGPT. \nL’histoire de l’IA montre qu’il y a des phases d’approbation publique et de désintérêt pour le terme et les technologies qu’il désigne.\nCe qu’on fait entrer dans la catégorie d’“intelligent” a changé. \nDeux grandes approches en IA : une approche déductive (IA symbolique, système expert) vs. déductive (IA connexionniste, modèle de langue).\nun système expert peut être aussi complexe et énergivore qu’un LLM.\nConcernant les LLMs : systèmes d’IA n’ont pas de connaissance du réel ou de ‘compréhension’ : les réponses sont probabilistes.\nLes hallucinations ne sont pas des anomalies, ce sont des erreurs que l’on qualifie a postériori comme telle.\nChatbots = interfaces en langue naturelle : l’exploitation des capacités inductives d’un LLMs ne nécessite pas de passer par une telle interface. Ex : classification.\nLes modèles propriétaires (pas en libre accès) ont des intérêts économiques : nature ‘sycophantique’ avérée."
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#la-correction",
    "href": "seances/atelier2-correction-auto.html#la-correction",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "La correction",
    "text": "La correction\n\n\nune étape négligée ou dévaluée ? quelle place dans notre système de valeurs ?\nqu’est-ce qui entre réellement dans cette étape ?\n\ncorrections orthographiques,\ncorrections typographiques,\nvérification de la mise en page, \ntraduction,\nvérification des sources,\namélioration du style, ton.\nreformulation selon le lectorat pressenti (prise en compte de la situation d’énonciation)\n\n\n\namélioration du contenu.\n\n\nLa correction bibliographique : ‘la barrière du dernier kilomètre’ (monjourBarriereDernierKilometre2025?)"
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#lalignement-des-valeurs",
    "href": "seances/atelier2-correction-auto.html#lalignement-des-valeurs",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "L’alignement des valeurs",
    "text": "L’alignement des valeurs\n\n« The problem of achieving agreement between our true preferences and the objective we put into the machine is called the value alignment problem: the values or objectives put into Value alignment problem the machine must be aligned with those of the human. » (Russell and Norvig 2022, 23)\n\nAutrement dit, si on laisse à la machine cette tâche c’est qu’on tend à l’estimer comme peu valorisante dans notre système de valeur actuel. Quelles conséquences est-ce que déléguer cette partie du travail a sur notre travail ?"
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#des-petites-corrections",
    "href": "seances/atelier2-correction-auto.html#des-petites-corrections",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Des ‘petites corrections’ ?",
    "text": "Des ‘petites corrections’ ?\n\nCurrently, academic publishers only allow the use of ChatGPT and similar tools to improve the readability and language of research articles. However, the ethical boundaries and acceptable usage of AI in academic writing are still undefined, and neither humans nor AI detection tools can reliably identify text generated by AI (homolakExploringAdoptionChatGPT2023?)\n\n\n\nIt is being increasingly observed that content generated by ChatGPT is going undeclared and undetected, resulting in its appearance in articles published in scholarly journals. […] The general policy among publishers states that AI tools must not be used to create, alter or manipulate original research data and results (Elsevier., 2023; Roche, 2024).(strzeleckiMyLastKnowledge2025?)\n\n\n\nArticles contenant des réponses de prompts\n\n\n\n\n\nArticles contenant des réponses explicites de ChatGPT"
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#quest-ce-que-la-relecture-correction",
    "href": "seances/atelier2-correction-auto.html#quest-ce-que-la-relecture-correction",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Qu’est-ce que la relecture-correction ?",
    "text": "Qu’est-ce que la relecture-correction ?\n\ncorrection ortho-typo\ndes énoncés grammaticalement justes ⇒ la grammaire c’est que des règles de combinaison, purement syntaxique, combinatoire sans sémantique. Règles systématiques et productives. Computation de séquences.\ndes énoncés qui font sens ⇒ sémantiquement correctes\nadéquation avec une situation d’énonciation ⇒ implique la pragmatique\nle style qui flirt avec les limites du correct\nla reformulation c’est encore autre chose"
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#les-étapes-de-la-correction",
    "href": "seances/atelier2-correction-auto.html#les-étapes-de-la-correction",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Les étapes de la correction",
    "text": "Les étapes de la correction\n\n\nla lecture\nétablir des critères de corrections : orthographes = règles de la langue, mais style etc.\nl’annotation = proposition\nla réécriture"
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#de-limportance-du-versionage",
    "href": "seances/atelier2-correction-auto.html#de-limportance-du-versionage",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "De l’importance du versionage",
    "text": "De l’importance du versionage\nLe LLM et l’interaction avec le LLM réduit les étapes de la correction au delà de son automatisation. Le LLM réécrit, il n’annote pas1, ne demande pas de clarifications ur les instructions données même si elles sont floues (‘améliore le texte’ est une instruction valide).\nUn processus de suppression qui est similaire aux logiques des éditeurs de texte WYSIWYG vs. le versionage qui rend compte du processus, entre dans une dimension de traçabilité et d’interprétabilité des choix effectués.\n\non peut cependant prompter un modèle pour qu’il le fasse."
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#sota-gec-grammar-error-correction",
    "href": "seances/atelier2-correction-auto.html#sota-gec-grammar-error-correction",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "SOTA GEC = Grammar Error correction",
    "text": "SOTA GEC = Grammar Error correction\nTâche de NLP voisine de la traduction automatique.\nSystème expert : très limités pour cette tâche. Grammaire = beaucoup de règles, parfois des règles d’idiomaticité pure (des colocations fortes).\nSystèmes inductifs ou approches data-driven :\nD’abord des classifieurs pour prédire le mots le plus probable dans une classe (préposition), puis statistical machine learning (STM) dans les années 2010 et particulièrement Neural machine translation (NMT). (wangComprehensiveSurveyGrammar2020?; bryantGrammaticalErrorCorrection2023?)\nNMT : Correspondance entre des phrases ou portions de phrases en entrée et des portions de phrases attestées en grand nombre (seq2seq) à partir de corpus parallèle. Le modèle algorithmique est entraîné sur une paire de langue (français-&gt;anglais)."
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#traduction-automatique-et-llms",
    "href": "seances/atelier2-correction-auto.html#traduction-automatique-et-llms",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Traduction automatique et LLMs",
    "text": "Traduction automatique et LLMs\nUn grand modèle de langue positionne chaque mot dans un espace vectoriel lors de sa phase d’apprentissage initiale à partir d’un grand volume de données en langue naturelle.\nAfin de retrouver donner une réponse le LLM généraliste comme GPT, Mistral, Qwen, Llama, situe la requête utilisateur dans son espace vectoriel et sélectionne les tokens les plus probables à partir du contexte donné (la requête utilisateur ou prompt et les tokens qu’il a déjà généré).\nLes LLMs sont donc généralistes, ils ne sont pas destinés à la traduction plus qu’à la correction d’erreurs grammaticales ou l’écriture créative.\nSuch divergences are well-documented in human translations (HT), where translators often make structural choices that vary significantly from the text originally written in the target language (Deng and Xue, 2017; Nikolaev et al., 2020). In contrast, traditional NMT outputs typically exhibit less diversity and more literal translations, lacking significant structural variation"
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#llm-vs-nmt-qualitativement",
    "href": "seances/atelier2-correction-auto.html#llm-vs-nmt-qualitativement",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "LLM vs NMT qualitativement",
    "text": "LLM vs NMT qualitativement\nNMT + littéral, + spécialisé LLM + verbeux (confabulation) mais plus proche de la traduction humaine pour ça.\n« We find that while LLMs often exhibit translation patterns more similar to human translations compared to traditional NMT models, they still diverge from originally authored text in the same language. Overall, we find that automatically translated sentences from both NMTs and LLMs are consistently identified with higher accuracy in O/T classification tasks than human-translated ones » (sizovAnalysingTranslationArtifacts2024?)\n« Furthermore, our frequency analysis of PoS tags reveals that LLMs align more closely with HT in their usage, especially in terms of adverbs, and auxiliary verbs, while NMT models tend to overproduce specific tags in shorter sentences. This suggests that LLMs, although not perfect, are making strides in mimicking human translation patterns. » (idem)\n« indicate that LLMs tend to produce translations that are less literal compared to NMT models »\n« What’s more, IBM announced the deprecation of Watson Language Translator, its NMT service, encouraging users to migrate to — guess what? — WatsonX LLMs. This move establishes IBM as one of the first tech giants to sunset its NMT efforts and focus on LLMs for automated translation purposes. » (ciesielskiNeuralMachineTranslation2024?)"
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#le-futur-de-la-traduction-automatique",
    "href": "seances/atelier2-correction-auto.html#le-futur-de-la-traduction-automatique",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Le futur de la traduction automatique",
    "text": "Le futur de la traduction automatique\nWe anticipate that, soon, LLMs will become a viable enterprise solution for translation. This will likely come when we move towards task-specific LLMs trained specifically for translation. These models will be smaller and more practical to deploy and maintain than today’s massive foundational models. (ciesielskiNeuralMachineTranslation2024?)"
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#back-to-gec",
    "href": "seances/atelier2-correction-auto.html#back-to-gec",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Back to GEC",
    "text": "Back to GEC\nLectures à faire :\n(kobayashiLargeLanguageModels2024?); (maityHowReadyAre2024?)\nKobayashi, M., Mita, M., & Komachi, M. (2024). Large Language Models Are State-of-the-Art Evaluator for Grammatical Error Correction (No. arXiv:2403.17540). arXiv. https://doi.org/10.48550/arXiv.2403.17540\nMaity, S., Deroy, A., & Sarkar, S. (2024). How Ready Are Generative Pre-trained Large Language Models for Explaining Bengali Grammatical Errors? (No. arXiv:2406.00039). arXiv. https://doi.org/10.48550/arXiv.2406.00039"
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#outils-généralistes",
    "href": "seances/atelier2-correction-auto.html#outils-généralistes",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Outils généralistes",
    "text": "Outils généralistes\nLLMs non entraînés : ChatGPT, modèles téléchargés localement (ollama).\n\ntrad auto : comparaison montre que les llm généraliste sosnt conversationnels mais pas experts. Influence du prompt (à base d’exemple, description de la tâche).\n\n\n\ndes modèles ‘généraliste’ avec une forte préférence pour l’anglais : quelle place pour les formes dialectales, pour les langues minoritaires. ?\n\nCàd qu’un LLM est toujours orienté."
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#outils-spécialisés-correction-écriture-académique",
    "href": "seances/atelier2-correction-auto.html#outils-spécialisés-correction-écriture-académique",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Outils spécialisés (correction, écriture académique)",
    "text": "Outils spécialisés (correction, écriture académique)\nhttps://www.editpad.org/ : AI detector, humanize AI text, Plagiarim checker, paraphrasing tool, story generator, text summarizer, AI essay writer etc. Probablement juste ChatGPT hooked à une interface avec un system-prompt. Apparamment mauvais according to Bordalejo et al. (2025)\n\nscreenshot editpadmaintenant corriger = masquer que le texte ne vient pas d’un humain, ou chercher à le détecter\nhttps://www.writefull.com/\nEffet de mode = disparition et apparition de solutions miracles\nGrammarly donne une note à partir des critères de formalité, 4 niveaux : correctness (corrige erreurs grammaticales), clarity (reformulation) engagement(option payante), delivery (payant), plagiarism detection (payant). Avec un ‘generative AI’ avec des prompts pre-écrit. -&gt; un browser plugin qui permet de s’en servir avec tous les sites google (docs, gmail, youtube comments).\n‘improve’ is an option of Generative AI. As is, just ‘improve’.\n“Grammarly is the AI communication partner trusted by over 40 million people, 50,000 organizations, and people at 96% of the Fortune 500.”\nquillbot\nIs QuillBot considered AI writing?\n2 years ago Updated \nEveryone’s talking about AI writing these days, and debate over its use — and misuse — rages. QuillBot has helped you grow and improve as a writer, but you may wonder if using it is considered AI writing. Good question. The short answer is “no.” QuillBot’s tools have specific uses, such as correcting grammar or paraphrasing sentences. It’s up to you to use the feedback and suggestions to create content that is solely your own. ChatGPT and similar AI writers, on the other hand, can generate essay-length text from a few prompts. That writing can then be presented with no changes. Since QuillBot is not considered AI writing, most plagiarism checkers will not flag its use.\nThat said, we make no guarantees if someone uses QuillBot on text generated by a tool like ChatGPT. Why not play it safe and craft the content yourself? (With QuillBot’s help, of course!)\nAntidote : https://www.antidote.info/fr/blogue/nouvelles/reformulation-et-intelligence-artificielle-antidote\nDes choix\nProLexis"
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#interrogation",
    "href": "seances/atelier2-correction-auto.html#interrogation",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Interrogation",
    "text": "Interrogation\nEst-ce que ces outils sont vraiment spécialisés ? Et comment le sont-ils ?\nil semble que les options de ‘generative AI’ sont simplement des prompts envoyés à un LLM via une API, ces outils ne possèdent pas forcément ‘leur modèle’, sinon ils ont fait du fine-tuning. Si l’utilisation du LLM est orientée par les dev du logiciel, il s’agit bien du même processus (l’utilisateurice peut seulement choisir une ‘reformulation’ du ton par exemple).\nLes avantages possibles qu’il pourrait y avoir : la sécurité des données (prompts cryptés) mais ce n’est même pas amené.\nOn voit que les outils se dirigent vers la ‘détection du plagiat’ et de la détection du l’‘utilisation d’IA’ : est-ce que on est dans unelogique de correction ou pas plut^to une logique de maquillage d’usages considérés par les maison d’édition et les universités comme illégitimes ?"
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#historique",
    "href": "seances/atelier2-correction-auto.html#historique",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Historique",
    "text": "Historique\n\nélément historiques : passage de système experts exemples (MT) à modèles data-driven (SMT puis NMT sur corpus parallèle en MT) -&gt; des modèles spécialisés dans la classification. -&gt; depuis 20 ans, des approches statistiques à la correction càd mise en parallèle d’une phrase en entrée et d’une phrase ou séquence présente dans le jeu de donnée.\nLLM généraliste : même modèle que NMT donc prédiction mais pas de spécialisation sur la tâche de correction ou traduction.\n\nAvant les LLM les outils de ‘corrections’ sont seuleemnt sur la correction ortho-typographique (on y reviendra) Maintenant les outils qui promettent de la correction dépassent les limites de la simple correction grammaticale."
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#limites-exposées",
    "href": "seances/atelier2-correction-auto.html#limites-exposées",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Limites exposées",
    "text": "Limites exposées\n\navec la MT on a 50 ans d’évaluation et de mesure statistiquues pour évaluer (score BLEU etc) mais pas avec la correction parcequ’on néglige ĉa.\nsi on transpos eles ccl de l’article [(sizovAnalysingTranslationArtifacts2024?) on voit que LLM = conversationnel, + idiomatique mais pas + expert ! Et surtout, les traducteurs apprécient travailler avec des NMT (!! syst neuronaux spécialisés) parce que erreurs prévisibles ! Output convainquant au premier abrood car ressemble au langue naturelle mais erreurs plus subtiles plus difficile à détecter."
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#pourquoi-est-ce-que-les-outils-incorporent-ajd-du-ai-powered",
    "href": "seances/atelier2-correction-auto.html#pourquoi-est-ce-que-les-outils-incorporent-ajd-du-ai-powered",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Pourquoi est-ce que les outils incorporent ajd du ‘AI powered’",
    "text": "Pourquoi est-ce que les outils incorporent ajd du ‘AI powered’\n\nles Systèmes existaient avant ChatGPT et opéraient de la même façon mais il fallait\nDes nouveaux usages, un ancrage\nintérêt économique à maintenir l’utilisateur sur la même plateforme donc intégration de LLM dans l’outil. (mais probablement juste une requête)."
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#pourquoi-est-ce-que-les-outils-incorporent-ajd-du-ai-powered-et-quel-impact-sur-nos-pratqieus-de-recherches-et-denseignement",
    "href": "seances/atelier2-correction-auto.html#pourquoi-est-ce-que-les-outils-incorporent-ajd-du-ai-powered-et-quel-impact-sur-nos-pratqieus-de-recherches-et-denseignement",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Pourquoi est-ce que les outils incorporent ajd du ‘AI powered’ et quel impact sur nos pratqieus de recherches et d’enseignement",
    "text": "Pourquoi est-ce que les outils incorporent ajd du ‘AI powered’ et quel impact sur nos pratqieus de recherches et d’enseignement\n\nles Systèmes existaient avant ChatGPT et opéraient de la même façon mais il fallait\nDes nouveaux usages, un ancrage\nintérêt économique à maintenir l’utilisateur sur la même plateforme donc intégration de LLM dans l’outil. (mais probablement juste une requête)."
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#quelle-conséquence-concrétement",
    "href": "seances/atelier2-correction-auto.html#quelle-conséquence-concrétement",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Quelle conséquence concrétement ?",
    "text": "Quelle conséquence concrétement ?\ndeux points de vue : - La correction a un impact sur la manière dont le texte est reçu. Le pdv des outils : peaufiner pour ‘convey at best’ tes idées, respecter les idées de l’auteurice. - “Écrire c’est réécrire.” donc laisser la correction à la machine c’est laisser une partie importante du travail intellectuel. - surtout si on considère les pratiques réelles où l’écriture est faite d’itération avec des étapes de corrections et des relectures. - ce qui était rationalisé dans le monde de l’imprimé avec le système ddes ‘épreuves’ à al soumission d’un manuscrit.\nÀ quel moment est-ce que cette étape intervient ? Et quelle est la conséquence d’automatiser cette étape ?\n\nau cours de la rédaction ?\n\névanouissement des versions intermédiaires (suppression vs. versioning) ?\n\nà la fin de la rédaction ?"
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#lalignement-des-valeurs-et-le-système-de-valeurs",
    "href": "seances/atelier2-correction-auto.html#lalignement-des-valeurs-et-le-système-de-valeurs",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "L’alignement des valeurs et le système de valeurs",
    "text": "L’alignement des valeurs et le système de valeurs\n\n« The problem of achieving agreement between our true preferences and the objective we put into the machine is called the value alignment problem: the values or objectives put into Value alignment problem the machine must be aligned with those of the human. » (Russell and Norvig 2022, 23)\n\nL’intelligence humaine commence là où celle de la machine s’arrête. Si on découvre de nouvelles capacités à la machine alors on enlève cette capicité de la définition de l’intelligence humaine.\nAutrement dit, si on laisse à la machine cette tâche c’est qu’on tend à l’estimer comme peu valorisante dans notre système de valeur actuel. Quelles conséquences est-ce que déléguer cette partie du travail a sur notre travail ?"
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#changement-de-paradigme",
    "href": "seances/atelier2-correction-auto.html#changement-de-paradigme",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Changement de paradigme",
    "text": "Changement de paradigme\nde la correction ortho-typo à la reformulation au fait de masquer le fait que le texte ait été écrit par une IA."
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#des-petites-corrections-finales",
    "href": "seances/atelier2-correction-auto.html#des-petites-corrections-finales",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Des ‘petites corrections finales’ ?",
    "text": "Des ‘petites corrections finales’ ?\n\nCurrently, academic publishers only allow the use of ChatGPT and similar tools to improve the readability and language of research articles. However, the ethical boundaries and acceptable usage of AI in academic writing are still undefined, and neither humans nor AI detection tools can reliably identify text generated by AI (homolakExploringAdoptionChatGPT2023?)\n\n\n\nIt is being increasingly observed that content generated by ChatGPT is going undeclared and undetected, resulting in its appearance in articles published in scholarly journals. […] The general policy among publishers states that AI tools must not be used to create, alter or manipulate original research data and results (Elsevier., 2023; Roche, 2024).(strzeleckiMyLastKnowledge2025?)\n\n\n\nArticles contenant des réponses de prompts\n\n\n\n\n\nArticles contenant des réponses explicites de ChatGPT"
  },
  {
    "objectID": "seances/atelier2-correction-auto.html#avant-présentation-outils",
    "href": "seances/atelier2-correction-auto.html#avant-présentation-outils",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Avant présentation outils",
    "text": "Avant présentation outils\n\nLangue = norme et normalisation politique (Clara)"
  },
  {
    "objectID": "seances/correction.html#plan-de-latelier",
    "href": "seances/correction.html#plan-de-latelier",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Plan de l’atelier",
    "text": "Plan de l’atelier\nThéorie :\n\nRappels sur les fondements de l’IA\nProblématique et annonce du plan\nMise en perspective\nDéfinition\nPrésentation historico-technique des systèmes de GEC\nChangement de paradigme : de l’ortho-typo à la reformulation voire la génération de contenu\nEnjeux/conséquence (questions) \nPrésentation des outils\nconclusion/ce qu’il faut retenir (5min)"
  },
  {
    "objectID": "seances/correction.html#présentation-et-objectif-des-ateliers",
    "href": "seances/correction.html#présentation-et-objectif-des-ateliers",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Présentation et objectif des ateliers",
    "text": "Présentation et objectif des ateliers\nFormat : 4 séances de 2 heures, sans inscription, participation libre (à justifier pour le certificat des Humanités Numériques)\nThéorie et pratique.\nObjectifs de la série d’atelier :\n\nComprendre les fondamentaux de l’IA et son histoire\nObtenir des notions critiques sur le fonctionnement profond des outils\nTester et s’approprier des outils d’IA\nMaîtriser le vocabulaire de la discipline\n\nObjectifs de cet atelier :\n\nCerner un cas d’usage courant des IA génératives : la correction ortho-typographique.\nContextualiser la correction (automatique)\nS’interroger sur l’impact de ces nouvelles pratiques dans le travail de recherche.\n\nDéfinir des critères pour effectuer un choix éclairé vis-à-vis des outils disponibles."
  },
  {
    "objectID": "seances/correction.html#certificat-canadien-en-humanités-numériques",
    "href": "seances/correction.html#certificat-canadien-en-humanités-numériques",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Certificat canadien en Humanités Numériques",
    "text": "Certificat canadien en Humanités Numériques\n\n\nCertificat canadien en HN\n\n\n\n \nInformation sur le certificat"
  },
  {
    "objectID": "seances/correction.html#quest-ce-que-lia",
    "href": "seances/correction.html#quest-ce-que-lia",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Qu’est ce que l’IA ?",
    "text": "Qu’est ce que l’IA ?\nDes programmes informatiques que nous estimons à la hauteur de l’intelligence humaine ? Le développement des technologies fait évoluer cette définition de l’intelligence non seulement artificielle mais aussi humaine.\n‘IA’ depuis 5 ans, a remplacé le ‘numérique’ des années 2010, et le ‘cyberespace’ des années 1990 et 2000.(Vitali-Rosati 2025).\nDéfinition pratique pour ces ateliers: “un programme informatique qui effectue une prédiction.”"
  },
  {
    "objectID": "seances/correction.html#rappels-de-lintroduction",
    "href": "seances/correction.html#rappels-de-lintroduction",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Rappels de l’introduction",
    "text": "Rappels de l’introduction\n\nLes programmes d’IA réfèrent à des processus algorithmiques variés et pas seulement à des chatbots type ChatGPT.\nL’IA est une discipline qui a plus de 75 ans (terme de 1956).\n(Turing 1950) a orienté la discipline vers un modèle ‘chatbot’. \nLes ‘saisons de l’IA’ suivent des phases d’approbation publique et de désintérêt pour le terme et les technologies qu’on place sous ce terme.\nCe qu’on fait entrer dans la catégorie d’“intelligent” a changé : le calcul savant est-il moins intelligent que le bavardage ?"
  },
  {
    "objectID": "seances/correction.html#historique",
    "href": "seances/correction.html#historique",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Historique",
    "text": "Historique\n\nélément historiques : passage de système experts exemples (MT) à modèles data-driven (SMT puis NMT sur corpus parallèle en MT) -&gt; des modèles spécialisés dans la classification. -&gt; depuis 20 ans, des approches statistiques à la correction càd mise en parallèle d’une phrase en entrée et d’une phrase ou séquence présente dans le jeu de donnée.\nLLM généraliste : même modèle que NMT donc prédiction mais pas de spécialisation sur la tâche de correction ou traduction.\n\nAvant les LLM les outils de ‘corrections’ sont seuleemnt sur la correction ortho-typographique (on y reviendra) Maintenant les outils qui promettent de la correction dépassent les limites de la simple correction grammaticale."
  },
  {
    "objectID": "seances/correction.html#pourquoi-est-ce-que-les-outils-incorporent-ajd-du-ai-powered-et-quel-impact-sur-nos-pratqieus-de-recherches-et-denseignement",
    "href": "seances/correction.html#pourquoi-est-ce-que-les-outils-incorporent-ajd-du-ai-powered-et-quel-impact-sur-nos-pratqieus-de-recherches-et-denseignement",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Pourquoi est-ce que les outils incorporent ajd du ‘AI powered’ et quel impact sur nos pratqieus de recherches et d’enseignement",
    "text": "Pourquoi est-ce que les outils incorporent ajd du ‘AI powered’ et quel impact sur nos pratqieus de recherches et d’enseignement\n\nles Systèmes existaient avant ChatGPT et opéraient de la même façon mais il fallait\nDes nouveaux usages, un ancrage\nintérêt économique à maintenir l’utilisateur sur la même plateforme donc intégration de LLM dans l’outil. (mais probablement juste une requête)."
  },
  {
    "objectID": "seances/correction.html#la-correction",
    "href": "seances/correction.html#la-correction",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "La correction",
    "text": "La correction\n\n\nune étape négligée ou dévaluée ? quelle place dans notre système de valeurs ?\nqu’est-ce qui entre réellement dans cette étape ?\n\ncorrections orthographiques,\ncorrections typographiques,\nvérification de la mise en page, \ntraduction,\nvérification des sources,\namélioration du style, ton.\nreformulation selon le lectorat pressenti (prise en compte de la situation d’énonciation)\n\n\n\namélioration du contenu.\n\n\nLa correction bibliographique : ‘la barrière du dernier kilomètre’ (monjourBarriereDernierKilometre2025?)"
  },
  {
    "objectID": "seances/correction.html#quelle-conséquence-concrétement",
    "href": "seances/correction.html#quelle-conséquence-concrétement",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Quelle conséquence concrétement ?",
    "text": "Quelle conséquence concrétement ?\ndeux points de vue : - La correction a un impact sur la manière dont le texte est reçu. Le pdv des outils : peaufiner pour ‘convey at best’ tes idées, respecter les idées de l’auteurice. - “Écrire c’est réécrire.” donc laisser la correction à la machine c’est laisser une partie importante du travail intellectuel. - surtout si on considère les pratiques réelles où l’écriture est faite d’itération avec des étapes de corrections et des relectures. - ce qui était rationalisé dans le monde de l’imprimé avec le système ddes ‘épreuves’ à al soumission d’un manuscrit.\nÀ quel moment est-ce que cette étape intervient ? Et quelle est la conséquence d’automatiser cette étape ?\n\nau cours de la rédaction ?\n\névanouissement des versions intermédiaires (suppression vs. versioning) ?\n\nà la fin de la rédaction ?"
  },
  {
    "objectID": "seances/correction.html#changement-de-paradigme",
    "href": "seances/correction.html#changement-de-paradigme",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Changement de paradigme",
    "text": "Changement de paradigme\n\nAvant les LLM, les outils de ‘corrections’ sont spécialisés pour la correction ortho-typographique. Maintenant les outils de correction dépassent les limites de la simple correction grammaticale.\n\nReformulation.\nGénération de texte.\nMasquer l’utilisation d’une IA."
  },
  {
    "objectID": "seances/correction.html#lalignement-des-valeurs-et-le-système-de-valeurs",
    "href": "seances/correction.html#lalignement-des-valeurs-et-le-système-de-valeurs",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "L’alignement des valeurs et le système de valeurs",
    "text": "L’alignement des valeurs et le système de valeurs\n\n« The problem of achieving agreement between our true preferences and the objective we put into the machine is called the value alignment problem: the values or objectives put into Value alignment problem the machine must be aligned with those of the human. » (Russell and Norvig 2022, 23)\n\nL’intelligence humaine commence là où celle de la machine s’arrête. Si on découvre de nouvelles capacités à la machine alors on enlève cette capicité de la définition de l’intelligence humaine. « More than fifteen years ago Hilary Putnam identified the old problem we face to this day: ‘The question that won’t go away is how much what we call intelligence presupposes the rest of human nature’ (1988: LET} » (McCarty 2005, 41)\nAutrement dit, si on laisse à la machine cette tâche c’est qu’on tend à l’estimer comme peu valorisante dans notre système de valeur actuel.\n► Quelles conséquences est-ce que déléguer cette partie du travail a sur notre travail ? Et sur notre définition de l’humain ?"
  },
  {
    "objectID": "seances/correction.html#des-petites-corrections-finales",
    "href": "seances/correction.html#des-petites-corrections-finales",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Des ‘petites’ corrections finales ?",
    "text": "Des ‘petites’ corrections finales ?\n\nCurrently, academic publishers only allow the use of ChatGPT and similar tools to improve the readability and language of research articles. However, the ethical boundaries and acceptable usage of AI in academic writing are still undefined, and neither humans nor AI detection tools can reliably identify text generated by AI (Homolak 2023)\n\n\n\nIt is being increasingly observed that content generated by ChatGPT is going undeclared and undetected, resulting in its appearance in articles published in scholarly journals. […] The general policy among publishers states that AI tools must not be used to create, alter or manipulate original research data and results (Elsevier., 2023; Roche, 2024).(Strzelecki 2025)\n\n\n\nArticles contenant des réponses de prompts\n\n\n\n\n\nArticles contenant des réponses explicites de ChatGPT\n\n\n\n► Est-ce que négliger l’écriture revient à négliger la lecture ?"
  },
  {
    "objectID": "seances/correction.html#quest-ce-que-la-relecture-correction",
    "href": "seances/correction.html#quest-ce-que-la-relecture-correction",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Qu’est-ce que la relecture-correction ?",
    "text": "Qu’est-ce que la relecture-correction ?\n\ncorrection ortho-typo\ndes énoncés grammaticalement justes ⇒ la grammaire c’est que des règles de combinaison, purement syntaxique, combinatoire sans sémantique. Règles systématiques et productives. Computation de séquences.\ndes énoncés qui font sens ⇒ sémantiquement correctes\nadéquation avec une situation d’énonciation ⇒ implique la pragmatique\nle style qui flirt avec les limites du correct\nla reformulation c’est encore autre chose"
  },
  {
    "objectID": "seances/correction.html#les-étapes-de-la-correction",
    "href": "seances/correction.html#les-étapes-de-la-correction",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Les étapes de la correction",
    "text": "Les étapes de la correction\n\nla lecture\nétablir des critères de corrections : orthographe = règles de la langue, mais style etc.\nl’annotation = proposition\nla réécriture\n\nLa correction est un processus itératif : c’est déjà une forme d’évaluation\n\n–&gt;"
  },
  {
    "objectID": "seances/correction.html#de-limportance-du-versionage",
    "href": "seances/correction.html#de-limportance-du-versionage",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "De l’importance du versionage",
    "text": "De l’importance du versionage\nLe LLM et l’interaction avec le LLM réduit les étapes de la correction au delà de son automatisation. Le LLM réécrit, il n’annote pas1, ne demande pas de clarifications ur les instructions données même si elles sont floues (‘améliore le texte’ est une instruction valide).\nUn processus de suppression qui est similaire aux logiques des éditeurs de texte WYSIWYG vs. le versionage qui rend compte du processus, entre dans une dimension de traçabilité et d’interprétabilité des choix effectués.\n\non peut cependant prompter un modèle pour qu’il le fasse."
  },
  {
    "objectID": "seances/correction.html#sota-gec-grammar-error-correction",
    "href": "seances/correction.html#sota-gec-grammar-error-correction",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "SOTA GEC = Grammar Error correction",
    "text": "SOTA GEC = Grammar Error correction\nTâche de NLP voisine de la traduction automatique.\nSystème expert : très limités pour cette tâche. Grammaire = beaucoup de règles, parfois des règles d’idiomaticité pure (des colocations fortes).\nSystèmes inductifs ou approches data-driven :\nD’abord des classifieurs pour prédire le mots le plus probable dans une classe (préposition), puis statistical machine learning (STM) dans les années 2010 et particulièrement Neural machine translation (NMT). (wangComprehensiveSurveyGrammar2020?; bryantGrammaticalErrorCorrection2023?)\nNMT : Correspondance entre des phrases ou portions de phrases en entrée et des portions de phrases attestées en grand nombre (seq2seq) à partir de corpus parallèle. Le modèle algorithmique est entraîné sur une paire de langue (français-&gt;anglais)."
  },
  {
    "objectID": "seances/correction.html#traduction-automatique-et-llms",
    "href": "seances/correction.html#traduction-automatique-et-llms",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Traduction automatique et LLMs",
    "text": "Traduction automatique et LLMs\nUn grand modèle de langue positionne chaque mot dans un espace vectoriel lors de sa phase d’apprentissage initiale à partir d’un grand volume de données en langue naturelle.\nAfin de donner une réponse le LLM (GPT, Mistral, Qwen, Llama etc.) situe la requête utilisateur dans son espace vectoriel et sélectionne les tokens les plus probables à partir du contexte donné (la requête utilisateur ou prompt et les tokens qu’il a déjà généré).\nLes LLMs sont donc généralistes, ils ne sont pas destinés à la traduction plus qu’à la correction d’erreurs grammaticales ou à l’écriture créative."
  },
  {
    "objectID": "seances/correction.html#llm-vs-nmt-qualitativement",
    "href": "seances/correction.html#llm-vs-nmt-qualitativement",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "LLM vs NMT qualitativement",
    "text": "LLM vs NMT qualitativement\nNMT + littéral, + spécialisé LLM + verbeux (confabulation) mais plus proche de la traduction humaine pour ça.\n« We find that while LLMs often exhibit translation patterns more similar to human translations compared to traditional NMT models, they still diverge from originally authored text in the same language. Overall, we find that automatically translated sentences from both NMTs and LLMs are consistently identified with higher accuracy in O/T classification tasks than human-translated ones » (sizovAnalysingTranslationArtifacts2024?)\n« Furthermore, our frequency analysis of PoS tags reveals that LLMs align more closely with HT in their usage, especially in terms of adverbs, and auxiliary verbs, while NMT models tend to overproduce specific tags in shorter sentences. This suggests that LLMs, although not perfect, are making strides in mimicking human translation patterns. » (idem)\n« indicate that LLMs tend to produce translations that are less literal compared to NMT models »\n« What’s more, IBM announced the deprecation of Watson Language Translator, its NMT service, encouraging users to migrate to — guess what? — WatsonX LLMs. This move establishes IBM as one of the first tech giants to sunset its NMT efforts and focus on LLMs for automated translation purposes. » (ciesielskiNeuralMachineTranslation2024?)"
  },
  {
    "objectID": "seances/correction.html#limites-exposées",
    "href": "seances/correction.html#limites-exposées",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Limites exposées",
    "text": "Limites exposées\n\navec la MT on a 50 ans d’évaluation et de mesure statistiquues pour évaluer (score BLEU etc) mais pas avec la correction parcequ’on néglige ĉa.\nsi on transpos eles ccl de l’article [(sizovAnalysingTranslationArtifacts2024?) on voit que LLM = conversationnel, + idiomatique mais pas + expert ! Et surtout, les traducteurs apprécient travailler avec des NMT (!! syst neuronaux spécialisés) parce que erreurs prévisibles ! Output convainquant au premier abrood car ressemble au langue naturelle mais erreurs plus subtiles plus difficile à détecter."
  },
  {
    "objectID": "seances/correction.html#le-futur-de-la-traduction-automatique",
    "href": "seances/correction.html#le-futur-de-la-traduction-automatique",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Le futur de la traduction automatique",
    "text": "Le futur de la traduction automatique\n\nWe anticipate that, soon, LLMs will become a viable enterprise solution for translation. This will likely come when we move towards task-specific LLMs trained specifically for translation. These models will be smaller and more practical to deploy and maintain than today’s massive foundational models. (Ciesielski 2024)\n\nLes LLMs font la traduction et l’évaluation de la traduction."
  },
  {
    "objectID": "seances/correction.html#back-to-gec",
    "href": "seances/correction.html#back-to-gec",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Back to GEC",
    "text": "Back to GEC\nLectures à faire :\n(kobayashiLargeLanguageModels2024?); (maityHowReadyAre2024?)\nKobayashi, M., Mita, M., & Komachi, M. (2024). Large Language Models Are State-of-the-Art Evaluator for Grammatical Error Correction (No. arXiv:2403.17540). arXiv. https://doi.org/10.48550/arXiv.2403.17540\nMaity, S., Deroy, A., & Sarkar, S. (2024). How Ready Are Generative Pre-trained Large Language Models for Explaining Bengali Grammatical Errors? (No. arXiv:2406.00039). arXiv. https://doi.org/10.48550/arXiv.2406.00039"
  },
  {
    "objectID": "seances/correction.html#avant-présentation-outils",
    "href": "seances/correction.html#avant-présentation-outils",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Avant présentation outils",
    "text": "Avant présentation outils\n\nLangue = norme et normalisation politique (Clara)"
  },
  {
    "objectID": "seances/correction.html#outils-généralistes",
    "href": "seances/correction.html#outils-généralistes",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Outils généralistes",
    "text": "Outils généralistes\nLLMs non spécialisé : ChatGPT, Mistral, Llama, Claude etc., modèles téléchargés localement (ollama).\nTenir compte des biais du modèle et de son interaction avec lui."
  },
  {
    "objectID": "seances/correction.html#outils-spécialisés-correction-écriture-académique",
    "href": "seances/correction.html#outils-spécialisés-correction-écriture-académique",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Outils spécialisés (correction, écriture académique)",
    "text": "Outils spécialisés (correction, écriture académique)\nhttps://www.editpad.org/ : AI detector, humanize AI text, Plagiarim checker, paraphrasing tool, story generator, text summarizer, AI essay writer etc. Probablement juste ChatGPT hooked à une interface avec un system-prompt. Apparamment mauvais according to Bordalejo et al. (2025)\n\nscreenshot editpadmaintenant corriger = masquer que le texte ne vient pas d’un humain, ou chercher à le détecter\nhttps://www.writefull.com/\nEffet de mode = disparition et apparition de solutions miracles\nGrammarly donne une note à partir des critères de formalité, 4 niveaux : correctness (corrige erreurs grammaticales), clarity (reformulation) engagement(option payante), delivery (payant), plagiarism detection (payant). Avec un ‘generative AI’ avec des prompts pre-écrit. -&gt; un browser plugin qui permet de s’en servir avec tous les sites google (docs, gmail, youtube comments).\n‘improve’ is an option of Generative AI. As is, just ‘improve’.\n“Grammarly is the AI communication partner trusted by over 40 million people, 50,000 organizations, and people at 96% of the Fortune 500.”\nquillbot\nIs QuillBot considered AI writing?\n2 years ago Updated \nEveryone’s talking about AI writing these days, and debate over its use — and misuse — rages. QuillBot has helped you grow and improve as a writer, but you may wonder if using it is considered AI writing. Good question. The short answer is “no.” QuillBot’s tools have specific uses, such as correcting grammar or paraphrasing sentences. It’s up to you to use the feedback and suggestions to create content that is solely your own. ChatGPT and similar AI writers, on the other hand, can generate essay-length text from a few prompts. That writing can then be presented with no changes. Since QuillBot is not considered AI writing, most plagiarism checkers will not flag its use.\nThat said, we make no guarantees if someone uses QuillBot on text generated by a tool like ChatGPT. Why not play it safe and craft the content yourself? (With QuillBot’s help, of course!)\nAntidote : https://www.antidote.info/fr/blogue/nouvelles/reformulation-et-intelligence-artificielle-antidote\nDes choix\nProLexis"
  },
  {
    "objectID": "seances/correction.html#interrogation",
    "href": "seances/correction.html#interrogation",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Interrogation",
    "text": "Interrogation\nEst-ce que ces outils sont vraiment spécialisés ? Et comment le sont-ils ?\nil semble que les options de ‘generative AI’ sont simplement des prompts envoyés à un LLM via une API, ces outils ne possèdent pas forcément ‘leur modèle’, sinon ils ont fait du fine-tuning. Si l’utilisation du LLM est orientée par les dev du logiciel, il s’agit bien du même processus (l’utilisateurice peut seulement choisir une ‘reformulation’ du ton par exemple).\nLes avantages possibles qu’il pourrait y avoir : la sécurité des données (prompts cryptés) mais ce n’est même pas amené.\nOn voit que les outils se dirigent vers la ‘détection du plagiat’ et de la détection du l’‘utilisation d’IA’ : est-ce que on est dans unelogique de correction ou pas plut^to une logique de maquillage d’usages considérés par les maison d’édition et les universités comme illégitimes ?"
  },
  {
    "objectID": "seances/correction.html#rappels-historiques-sur-lia",
    "href": "seances/correction.html#rappels-historiques-sur-lia",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Rappels historiques sur l’IA",
    "text": "Rappels historiques sur l’IA\n\nDeux grandes approches en IA : une approche déductive (IA symbolique, système expert) vs. approche inductive (IA connexionniste, modèle de langue).\nUn système expert peut être aussi complexe et énergivore qu’un LLM.\nUn LLM (large language model) est la modélisation sous forme de vecteurs de chaque élément d’un grand corpus (token ~mot) par rapport à cet ensemble.\n\nDémo visuelle"
  },
  {
    "objectID": "seances/correction.html#les-llms-en-contexte",
    "href": "seances/correction.html#les-llms-en-contexte",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Les LLMs en contexte",
    "text": "Les LLMs en contexte\n\nPour les LLMs, la ‘compréhension’ du monde n’est basée sur aucun référent ou aucune règle définie : les réponses sont probabilistes.\nLes hallucinations ne sont pas des anomalies, ce sont des erreurs que l’on qualifie a posteriori comme telle.\nAprès l’apprentissage de son corpus d’entrainement, une étape de reinforcement learning donne une saveur ou personnalité à un modèle.\nLes LLMs reflètent les intérêts économiques de leurs concepteurices: nature ‘sycophantique’ avérée.\nOn peut influencer le calcul de probabilité d’un modèle (température, top-k, seed) et donc sa personnalité (déterministe vs. créatif).\nOn peut aussi ‘orienter’ le comportement d’un modèle avec un system prompt.\n\nChatbots = interfaces en langue naturelle : l’exploitation des capacités inductives d’un LLMs ne nécessite pas de passer par une telle interface. Ex : classification avec de l’apprentissage machine (machine learning)."
  },
  {
    "objectID": "seances/correction.html#la-correction-derreur-grammaticales-automatique-grammar-error-correction",
    "href": "seances/correction.html#la-correction-derreur-grammaticales-automatique-grammar-error-correction",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "La correction d’erreur grammaticales automatique Grammar Error correction",
    "text": "La correction d’erreur grammaticales automatique Grammar Error correction\nTâche de Traitement Automatique des Langues (TAL ou Natural Language Processing, NLP) voisine de la traduction automatique (TA ou machine translation, MT)\nSystème expert : limité par des grammaires complexes, questions de pragmatique et d’idiomaticité.\nSystèmes inductifs ou approches data-driven : D’abord des classifieurs pour prédire le mots le plus probable dans une classe (préposition), puis statistical machine learning (SMT) dans les années 2010 et particulièrement Neural machine translation (NMT). (Wang et al. 2020; Bryant et al. 2023)\nNMT : Correspondance entre des phrases ou portions de phrases en entrée et des portions de phrases attestées en grand nombre (seq2seq) à partir de corpus parallèle. Le modèle algorithmique est entraîné sur une paire de langue (ex : français-&gt;anglais)."
  },
  {
    "objectID": "seances/correction.html#llm-vs-nmt-pour-la-traduction-automatique",
    "href": "seances/correction.html#llm-vs-nmt-pour-la-traduction-automatique",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "LLM vs NMT pour la Traduction automatique",
    "text": "LLM vs NMT pour la Traduction automatique\n\n\nNMT : traduction littérale , modèle spécialisé\nLLM : traduction plus idiomatique, tendance à la confabulation.\n\n\n« Furthermore, our frequency analysis of PoS tags reveals that LLMs align more closely with HT in their usage, especially in terms of adverbs, and auxiliary verbs, while NMT models tend to overproduce specific tags in shorter sentences. This suggests that LLMs, although not perfect, are making strides in mimicking human translation patterns. » (Sizov et al. 2024)\n\n\nLa fin de la NMT?\n\n« What’s more, IBM announced the deprecation of Watson Language Translator, its NMT service, encouraging users to migrate to — guess what? — WatsonX LLMs. This move establishes IBM as one of the first tech giants to sunset its NMT efforts and focus on LLMs for automated translation purposes. » (Ciesielski 2024)"
  },
  {
    "objectID": "seances/correction.html#question-dévaluation",
    "href": "seances/correction.html#question-dévaluation",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Question d’évaluation",
    "text": "Question d’évaluation\nLa traduction automatique : score BLEU (comparaison de la phrase traduite avec un référentiel de phrases bien traduites, score de proximité), WER (calcul du nombre de mot mal ou non traduit), METEOR etc.\nLa Grammar Error Correction (GEC) compare la phrase source (avec erreurs), la phrase corrigée et une phrase de référence (la ground truth donnée par un humain). Cette approche demande un corpus annoté en reference."
  },
  {
    "objectID": "seances/correction.html#métriques-traditionnelles-de-gec",
    "href": "seances/correction.html#métriques-traditionnelles-de-gec",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Métriques traditionnelles de GEC",
    "text": "Métriques traditionnelles de GEC\n\nEdit-Based Metrics :\n\nM² (MaxMatch) : On aligne les phrases corrigées par le système avec celles de référence (gold standard), puis on extrait les “edits” (opérations de correction : insertion, suppression, remplacement). On calcule précision, rappel, F0.5(donc précision pondérée deux fois plus que rappel).\nERRANT (Error Annotation Toolkit): alignement de l’hypothèse avec la phrase source et la phrase cible et classification du type d’erreur (morphologie, orthographe, syntaxe).\n\nSentence-Based metrics:\n\nGLEU (grammar-aware BLEU) : comparaison de n-grammes.\n\n\nCes mesures repose sur l’alignement entre une hypothèse et une référence figée."
  },
  {
    "objectID": "seances/correction.html#mesure-de-la-correction-sans-référence",
    "href": "seances/correction.html#mesure-de-la-correction-sans-référence",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Mesure de la correction sans référence",
    "text": "Mesure de la correction sans référence\nLes métriques basées sur un corpus de référence limitent la correction a une forme seulement.\nMesure sans référence (Napoles, Sakaguchi, and Tetreault 2016): comparaison directe de la phrase source (avec erreurs) et de la phrase corrigée avec un LLM.\nMéthodes d’évaluation avec un LLM:\n\nProximité/distance : Comparaison des vecteurs de la phrase source et celles de la phrase corrigée.\nPerplexité/log-probabilité : plus une phrase est fluide plus elle est probable (donc correcte). \nSpécialisation d’un LLM pour l’évaluation : Machine learning sur un corpus annoté avec des scores attribué ex: SOME (Yoshimura et al. 2020)\nLLM as judges : instruction en langues naturelles.\n\n\n« The decrease in correlation as the LLM scale decreases, such as with Llama 2 and GPT-3.5, suggests the importance of the LLM scale. Especially, the decrease in correlation when adding fluent corrected sentences (“+ Fluent corr.”) compared to “Base” implies that smaller-scale LLMs may not adequately consider the fluency of sentences. Possible reasons for this include issues such as LLM’s tendency to produce the same scores (Appendix C) and the inability to interpret the context of prompts as expected by users. However, GPT-4 consistently demonstrated a high correlation and provided more stable evaluations compared to traditional metrics. » (Kobayashi, Mita, and Komachi 2024)"
  },
  {
    "objectID": "seances/correction.html#les-limites-des-llms-as-judge-pour-la-gec",
    "href": "seances/correction.html#les-limites-des-llms-as-judge-pour-la-gec",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Les limites des LLMs-as-judge pour la GEC",
    "text": "Les limites des LLMs-as-judge pour la GEC\n\nPas toujours reproductible\nFavorise les langues bien dotées. Ex Bengali (Maity, Deroy, and Sarkar 2024)\nShankar et al. (2024) et le criteria drift : on ne sait pas avant de l’avoir expérimenté ce que le LLM est capable de faire correctement. Autrement dit : l’évaluation est un processus itératif."
  },
  {
    "objectID": "seances/correction.html#quelle-définition-de-la-correction",
    "href": "seances/correction.html#quelle-définition-de-la-correction",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Quelle définition de la correction ?",
    "text": "Quelle définition de la correction ?\n\n\nune étape négligée ou dévaluée ? quelle place dans notre système de valeurs ?\nqu’est-ce qui entre réellement dans cette étape ?\n\ncorrections orthographiques,\ncorrections typographiques,\nvérification de la mise en page,\ntraduction,\nvérification des sources,\namélioration du style, ton.\nreformulation selon le lectorat pressenti (prise en compte de la situation d’énonciation)\n\n\n\namélioration du contenu.\n\n\nLa correction bibliographique : ‘la barrière du dernier kilomètre’ (monjourBarriereDernierKilometre2025?)"
  },
  {
    "objectID": "seances/correction.html#effet-nivelant-et-influence-de-la-machine",
    "href": "seances/correction.html#effet-nivelant-et-influence-de-la-machine",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Effet nivelant et influence de la machine",
    "text": "Effet nivelant et influence de la machine\nLes moins bons traducteurs sont aidés par la TA mais les meilleurs traducteurs sont désavantagés par la TA. Effet limitant car tendance à se laisser influencer : réduction des intuitions de traduction et de la créativité traductionnelle.(Schumacher 2023)\nUne influence pas négligeable : même quand un.e participant.e n’a plus les recommandations de la machine, iel reproduit les erreurs des recommandations (Vicente and Matute 2023) : délégation cognitive ou cognitive offloading\n► Comment est-ce qu’on peut prendre conscience de ces biais (inconscients) ?"
  },
  {
    "objectID": "seances/correction.html#leffet-ai-powered",
    "href": "seances/correction.html#leffet-ai-powered",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "L’effet ‘AI-powered’",
    "text": "L’effet ‘AI-powered’\nLa correction automatique existe avant ChatGPT et les LLM offraient des techniques poussées de GEC mais il fallait encore que de nouveaux usages s’ancrent et qu’il y ait un intérêt économique à maintenir l’utilisateur sur la même plateforme d’où l’intégration de LLM dans l’outil."
  },
  {
    "objectID": "seances/correction.html#outils-spécialisés",
    "href": "seances/correction.html#outils-spécialisés",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Outils spécialisés",
    "text": "Outils spécialisés\nLes outils historiques (francophones)\nAntidote\nSources sur les technologies d’Antidotes :\nReformulation et IA (décembre 2023)\nChatGPT peut-il remplacer Antidote ?(https://www.antidote.info/fr/blogue/astuces-et-conseils/chatgpt-peutil-remplacer-antidote)\nUne combinaison d’outils spécialisés et utilisant des techniques diverses.\nProLexis (pas de vidéos youtube depuis 3 ans, ProLexis7) Outil professionel, analyseur syntaxique, interface à l’ancienne, powerpoint à l’ancienne.\nLes nouveaux outils\nEditPad : AI detector, humanize AI text, Plagiarim checker, paraphrasing tool, story generator, text summarizer, AI essay writer etc. Probablement juste ChatGPT hooked à une interface avec un system-prompt. Apparamment mauvais according to (bordalejoScarletCloakForest2025?)\n\nscreenshot editpadCorriger = masquer que le texte ne vient pas d’une machine, ou chercher à le détecter?\nWritefull: Title generator, Abstract generator, paraphraser, academizer.\nEffet de mode = disparition et apparition de solutions miracles (down le 22 septembre, up le 30 septembre mais bug)\nGrammarly donne une note à partir des critères de formalité, 4 niveaux : correctness (corrige erreurs grammaticales), clarity (reformulation) engagement (option payante), delivery (payant), plagiarism detection (payant). Option ‘generative AI’ avec des prompts pre-écrits qui restreignent l’usage. Et un browser plugin qui permet de s’en servir avec tous les sites google (docs, gmail, youtube comments).\nimprove est une option liée à “Generative AI” juste ‘améliorer’.\n\nquillbot\n\n“Is QuillBot considered AI writing? 2 years ago Updated Everyone’s talking about AI writing these days, and debate over its use — and misuse — rages. QuillBot has helped you grow and improve as a writer, but you may wonder if using it is considered AI writing. Good question. The short answer is “no.” QuillBot’s tools have specific uses, such as correcting grammar or paraphrasing sentences. It’s up to you to use the feedback and suggestions to create content that is solely your own. ChatGPT and similar AI writers, on the other hand, can generate essay-length text from a few prompts. That writing can then be presented with no changes. Since QuillBot is not considered AI writing, most plagiarism checkers will not flag its use.\n\n\nThat said, we make no guarantees if someone uses QuillBot on text generated by a tool like ChatGPT. Why not play it safe and craft the content yourself? (With QuillBot’s help, of course!)"
  },
  {
    "objectID": "seances/correction.html#tous-les-autres-outils",
    "href": "seances/correction.html#tous-les-autres-outils",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Tous les autres outils",
    "text": "Tous les autres outils\nPrise de note :\nNotion : génération de texte.\nEvernote: RAG\nRédaction de mail etc"
  },
  {
    "objectID": "seances/correction.html#bibliographie",
    "href": "seances/correction.html#bibliographie",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Bibliographie",
    "text": "Bibliographie\n\n\nBordalejo, Barbara, Davide Pafumi, Frank Onuh, A. K. M. Iftekhar Khalid, Morgan Slayde Pearce, and Daniel Paul O’Donnell. 2025. “‘Scarlet Cloak and the Forest Adventure’: A Preliminary Study of the Impact of AI on Commonly Used Writing Tools.” International Journal of Educational Technology in Higher Education 22 (1). https://doi.org/10.1186/s41239-025-00505-5.\n\n\nBryant, Christopher, Zheng Yuan, Muhammad Reza Qorib, Hannan Cao, Hwee Tou Ng, and Ted Briscoe. 2023. “Grammatical Error Correction: A Survey of the State of the Art.” Computational Linguistics, September, 643–701. https://doi.org/10.1162/coli_a_00478.\n\n\nCiesielski, Jourik. 2024. “Neural Machine Translation Versus Large Language Models.” https://multilingual.com/magazine/june-2024/neural-machine-translation-versus-large-language-models/.\n\n\nGuo, Yanzhu, Guokan Shang, Michalis Vazirgiannis, and Chloé Clavel. 2024. “The Curious Decline of Linguistic Diversity: Training Language Models on Synthetic Text.” arXiv. https://doi.org/10.48550/arXiv.2311.09807.\n\n\nHomolak, Jan. 2023. “Exploring the Adoption of ChatGPT in Academic Publishing: Insights and Lessons for Scientific Writing.” Croatian Medical Journal 64 (3): 205–7. https://doi.org/10.3325/cmj.2023.64.205.\n\n\nKobayashi, Masamune, Masato Mita, and Mamoru Komachi. 2024. “Large Language Models Are State-of-the-Art Evaluator for Grammatical Error Correction.” arXiv. https://doi.org/10.48550/arXiv.2403.17540.\n\n\nMaity, Subhankar, Aniket Deroy, and Sudeshna Sarkar. 2024. “How Ready Are Generative Pre-trained Large Language Models for Explaining Bengali Grammatical Errors?” arXiv. https://doi.org/10.48550/arXiv.2406.00039.\n\n\nMcCarty, Willard. 2005. Humanities Computing. Paperback edition. Basingstoke, Hampshire: Palgrave Macmillan.\n\n\nNapoles, Courtney, Keisuke Sakaguchi, and Joel Tetreault. 2016. “There’s No Comparison: Reference-less Evaluation Metrics in Grammatical Error Correction.” In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, 2109–15. Austin, Texas: Association for Computational Linguistics. https://doi.org/10.18653/v1/D16-1228.\n\n\nRussell, Stuart J., and Peter Norvig. 2022. Artificial Intelligence: A Modern Approach. Fourth edition, global edition. Prentice Hall Series in Artificial Intelligence. Boston: Pearson.\n\n\nSchumacher, Perrine. 2023. “La post-édition de traduction automatique en contexte d’apprentissage.” PhD thesis, Liège: Universite de Liege.\n\n\nShankar, Shreya, J. D. Zamfirescu-Pereira, Björn Hartmann, Aditya G. Parameswaran, and Ian Arawjo. 2024. “Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences.” arXiv. https://doi.org/10.48550/arXiv.2404.12272.\n\n\nShumailov, Ilia, Zakhar Shumaylov, Yiren Zhao, Nicolas Papernot, Ross Anderson, and Yarin Gal. 2024. “AI Models Collapse When Trained on Recursively Generated Data.” Nature 631 (8022): 755–59. https://doi.org/10.1038/s41586-024-07566-y.\n\n\nSizov, Fedor, Cristina España-Bonet, Josef Van Genabith, Roy Xie, and Koel Dutta Chowdhury. 2024. “Analysing Translation Artifacts: A Comparative Study of LLMs, NMTs, and Human Translations.” In Proceedings of the Ninth Conference on Machine Translation, 1183–99. Miami, Florida, USA: Association for Computational Linguistics. https://doi.org/10.18653/v1/2024.wmt-1.116.\n\n\nStrzelecki, Artur. 2025. “‘As of My Last Knowledge Update’: How Is Content Generated by ChatGPT Infiltrating Scientific Papers Published in Premier Journals?” Learned Publishing 38 (1): e1650. https://doi.org/10.1002/leap.1650.\n\n\nTuring, A. M. 1950. “Computing Machinery and Intelligence.” Mind LIX (236): 433–60. https://doi.org/10.1093/mind/LIX.236.433.\n\n\nVicente, Lucía, and Helena Matute. 2023. “Humans Inherit Artificial Intelligence Biases.” Scientific Reports 13 (1): 15737. https://doi.org/10.1038/s41598-023-42384-8.\n\n\nVitali-Rosati, Marcello. 2025. “Manifeste Pour Des Études Critiques de l’Intelligence Artificielle.” Culture Numérique. Pour Une Philosophie Du Numérique.\n\n\nWang, Yu, Yuelin Wang, Jie Liu, and Zhuo Liu. 2020. “A Comprehensive Survey of Grammar Error Correction.” arXiv. https://doi.org/10.48550/arXiv.2005.06600.\n\n\nYoshimura, Ryoma, Masahiro Kaneko, Tomoyuki Kajiwara, and Mamoru Komachi. 2020. “SOME: Reference-less Sub-Metrics Optimized for Manual Evaluations of Grammatical Error Correction.” In Proceedings of the 28th International Conference on Computational Linguistics, edited by Donia Scott, Nuria Bel, and Chengqing Zong, 6516–22. Barcelona, Spain (Online): International Committee on Computational Linguistics. https://doi.org/10.18653/v1/2020.coling-main.573."
  },
  {
    "objectID": "seances/correction.html#est-ce-que-ces-outils-offrent-un-gain-de-temps-selon-vous",
    "href": "seances/correction.html#est-ce-que-ces-outils-offrent-un-gain-de-temps-selon-vous",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Est-ce que ces outils offrent un gain de temps selon vous ?",
    "text": "Est-ce que ces outils offrent un gain de temps selon vous ?"
  },
  {
    "objectID": "seances/correction.html#uniformisation-de-la-langue",
    "href": "seances/correction.html#uniformisation-de-la-langue",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Uniformisation de la langue",
    "text": "Uniformisation de la langue\nmodel collapse\nlinguistic uniformisation"
  },
  {
    "objectID": "seances/correction.html#clara",
    "href": "seances/correction.html#clara",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Uniformisation de la langue",
    "text": "Uniformisation de la langue\nmodel collapse : (Shumailov et al. 2024)\nlinguistic uniformisation : Guo et al. (2024)\n► est-ce qu’il y a un “style ChatGPT” ?"
  },
  {
    "objectID": "seances/correction.html#la-promesse-du-gain-de-temps",
    "href": "seances/correction.html#la-promesse-du-gain-de-temps",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "La promesse du gain de temps",
    "text": "La promesse du gain de temps\n► Est-ce que ces outils offrent un gain de temps selon vous ?"
  },
  {
    "objectID": "seances/correction.html#intégration-dans-tous-les-autres-outils",
    "href": "seances/correction.html#intégration-dans-tous-les-autres-outils",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Intégration dans tous les autres outils",
    "text": "Intégration dans tous les autres outils\nPrise de note :\nNotion : génération de texte.\nEvernote: RAG\nRédaction de mail etc."
  },
  {
    "objectID": "seances/correction.html#à-retenir",
    "href": "seances/correction.html#à-retenir",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "À retenir",
    "text": "À retenir\n\nLa correction est un processus itératif qui implique une phase d’écriture, de lecture, d’annotation et de réécriture : l’IA a transformé ce paradigme à toutes les étapes.\nLes premiers correcteurs automatiques se sont concentrés sur la correction ortho-typographiques, avec les systèmes de GEC complexes depuis les années 2000 ces outils traitent de reformulation\nLa Grammar Error Correction est une tâche voisine de la Traduction automatique : les technologies sous jacentes sont partagées\nL’évaluation de la GEC et de la TA fait écho aux processus d’évaluation propre à la correction par un humain.\nAvec l’ancrage de nouvelles pratiques discrètes de l’IA, on assiste à une nouvelle phase : la correction comme écriture et comme masquage de l’utilisation d’IA générative. Et l’intégration d’outils dit d’IA dans toutes les applications de traitement de texte etc.\nLes promesses de gain de temps et de productivité cachent des enjeux économiques forts : on ne peut que rester méfiants face aux biais de ces outils tout en prennant conscience de ses propres influences."
  },
  {
    "objectID": "seances/correction.html#prochaines-séances",
    "href": "seances/correction.html#prochaines-séances",
    "title": "2e séance atelier IA - révision et correction automatique",
    "section": "Prochaines séances",
    "text": "Prochaines séances\n\nLes systèmes d’exploitation le 6 novembre avec Louis-Olivier\nLa Synthèse des sources et la recherche d’information le 15 janvier 2026."
  }
]