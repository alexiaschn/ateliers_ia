[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ateliers IA pour les SHS",
    "section": "",
    "text": "‘IA’ est le terme qui a envahit nos discours depuis quelques années. Vous saturez ? Nous aussi ! Cette série d’atelier vise à outiller chercheurs et chercheuses en SHS pour comprendre les fondements de cette discipline afin de dépasser à la fois les discours marketing qui imprègnent malgré nous l’espace public et les propos alarmistes des derniers réfractaires.\n\n\nIntroduire à la communauté universitaire en SHS les fondements de l’étude critique des IA avec une stratégie d’apprentissage par la prise en main. Aucun pré-requis en informatique n’est nécessaire : apportez simplement votre ordinateur.\n\nSensibiliser sur l’impact des nouvelles outils sur les pratiques de recherche et d’édition en contexte universitaire\nOrienter les chercheur.se.s vers des outils d’IA adaptés à la recherche et allignés avec les préconisations éthiques actuelles.\nEclaircir les amalgames courants au sujet de l’IA et les chatbots par l’acquisition de connaissances fondamentales en IA."
  },
  {
    "objectID": "25-10-09_correctionAtelierIA.html",
    "href": "25-10-09_correctionAtelierIA.html",
    "title": "2e séance atelier IA - révision",
    "section": "",
    "text": "Date : 9 octobre 2025\n\n\n(format de 2h) 1. Présentation de la série d’atelier 2. Qu’est-ce que l’IA ? 3. Rappel de la 1e séance : histoire, ce qu’il fallait retenir de la 1e séance 4. Place et importance de la correction 5. Outils généralistes 6. Outils spécialisés (été 2025) 7. Pistes pour l’évaluation des outils 8. Conclusions"
  },
  {
    "objectID": "25-10-09_correctionAtelierIA.html#plan",
    "href": "25-10-09_correctionAtelierIA.html#plan",
    "title": "2e séance atelier IA - révision",
    "section": "",
    "text": "(format de 2h) 1. Présentation de la série d’atelier 2. Qu’est-ce que l’IA ? 3. Rappel de la 1e séance : histoire, ce qu’il fallait retenir de la 1e séance 4. Place et importance de la correction 5. Outils généralistes 6. Outils spécialisés (été 2025) 7. Pistes pour l’évaluation des outils 8. Conclusions"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Intro",
    "section": "",
    "text": "Présentation de la série d’atelier\nQu’est-ce que l’IA ?\nIntérêt d’étudier l’IA pour les SHS\nRetours historiques\nTypologie des IA\nCas d’usage et modélisation experte (ELIZA)\nCas d’usage et modélisation distributionnelle/vectorielle (vectorisation et prédiction)\nLes LLMs\nUsages des LLMs hors chatbots (demo)\nLLMs et chatbots (Duck.ai + Ollama)\nConclusions"
  },
  {
    "objectID": "intro.html#plan",
    "href": "intro.html#plan",
    "title": "Intro",
    "section": "Plan",
    "text": "Plan\n\nPrésentation de la série d’atelier\nQu’est-ce que l’IA ?\nIntérêt d’étudier l’IA pour les SHS\nRetours historiques\nTypologie des IA\nCas d’usage et modélisation experte (ELIZA)\nCas d’usage et modélisation distributionnelle/vectorielle (vectorisation et prédiction)\nLes LLMs\nUsages des LLMs hors chatbots (demo)\nLLMs et chatbots (Duck.ai + Ollama)\nConclusions"
  },
  {
    "objectID": "intro.html#présentation-et-objectif-des-ateliers",
    "href": "intro.html#présentation-et-objectif-des-ateliers",
    "title": "Intro",
    "section": "Présentation et objectif des ateliers",
    "text": "Présentation et objectif des ateliers\nFormat : 4 séances de 2heures, sans inscription, participation libre (à justifier pour le certificat des Humanités Numériques)\nThéorie et pratique en alternance au cours des deux heures.\nObjectifs de la série d’atelier :\n\nComprendre les fondamentaux de l’IA et son histoire\nObtenir des notions critiques sur le fonctionnement profond des outils\nTester et s’approprier des outils d’IA\nMaîtriser le vocabulaire de la discipline\n\nObjectifs de cet atelier :\n\nComprendre les différentes formes d’IA\nComprendre les enjeux liés à l’utilisation des LLM\nUtiliser de l’IA en dehors d’une interface de tchat.\nTester les paramètres des chatbots\nInstaller localement des modèles de langue."
  },
  {
    "objectID": "intro.html#quest-ce-que-lia",
    "href": "intro.html#quest-ce-que-lia",
    "title": "Intro",
    "section": "Qu’est ce que l’IA ?",
    "text": "Qu’est ce que l’IA ?\n\nTout et rien : exemples : chatbot, détection sur des imageries médicales, HTR, DeepBlue.\nle dernier mot à la mode. Le ‘numérique’ des années 2020. (Vitali-Rosati 2025)."
  },
  {
    "objectID": "intro.html#quest-ce-que-lia-1",
    "href": "intro.html#quest-ce-que-lia-1",
    "title": "Intro",
    "section": "Qu’est-ce que l’IA ?",
    "text": "Qu’est-ce que l’IA ?\nDéfinition pratique : “un programme informatique qui effectue une prédiction.”"
  },
  {
    "objectID": "intro.html#lia-et-les-shs",
    "href": "intro.html#lia-et-les-shs",
    "title": "Intro",
    "section": "L’IA et les SHS",
    "text": "L’IA et les SHS\nÀ quoi sert d’étudier l’IA pour les chercheur.se.s en SHS ?"
  },
  {
    "objectID": "intro.html#lia-et-les-shs-1",
    "href": "intro.html#lia-et-les-shs-1",
    "title": "Intro",
    "section": "L’IA et les SHS",
    "text": "L’IA et les SHS\nÀ quoi sert d’étudier l’IA pour les chercheur.se.s en SHS"
  },
  {
    "objectID": "intro.html#lia-et-les-shs-2",
    "href": "intro.html#lia-et-les-shs-2",
    "title": "Intro",
    "section": "L’IA et les SHS",
    "text": "L’IA et les SHS\nQue peuvent faire les SHS pour l’IA ?\n\nparticiper à la réflexion actuelle sur son utilisation :\n\npositionnements de revues et de conférences sur son utilisation (pose un cadre, parfois un précédent)\n\nproposer une théorie critique de l’IA décentrées de l’effet ‘benchmarking’\nproposer une avis sur l’utilisation de ces outils qui soit propre à sa discipline."
  },
  {
    "objectID": "intro.html#exemples-de-prises-de-position",
    "href": "intro.html#exemples-de-prises-de-position",
    "title": "Intro",
    "section": "Exemples de prises de position",
    "text": "Exemples de prises de position\n\nBoth SUP and JHUP have increasingly embraced, tested, and deployed some AI tools and policies. Barbara has been clear in her support of responsible uses of AI and the necessity of leveraging these early days to stake a claim within the quickly evolving landscape. Like SUP, JHUP is building and testing its own tools for marketing, accessibility, and analytics, efforts which place our presses in a position to potentially build services that might in the future even benefit other university presses. (Mulliken 2025)\n\n\nwe offer recommendations for citing generative AI, defined as a tool that “can analyze or summarize content from a huge set of information, including web pages, books and other writing available on the internet, and use that data to create original new content” (Weed). (“How Do I Cite Generative AI in MLA Style?” 2023)\n\n\nThe uncomfortable truth for researchers and publishers who oppose AI slowly taking over human review is that they might not be able to prevent it. Should a researcher use AI to write the first pass of peer review and not disclose it — in contravention of publisher guidelines — that might not be detectable, says Hosseini, who is also one of the editors of the journal Accountability in Research. And if AI reviews become widespread, that could change the practice of science, says Priem. “Every researcher can run their own bespoke review service over the preprint/dataset landscape, flagging/extracting only the science they care about (at any “quality” level) they want that day,” he wrote on X earlier this year. That could start to eat into the roles of journals, by taking away the certification that peer review mediated by journals provides, he says. (Naddaf 2025)"
  },
  {
    "objectID": "intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-1",
    "href": "intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-1",
    "title": "Intro",
    "section": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 1)",
    "text": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 1)\n1940s : Science-fiction et roman d’Isaac Asimov Runaround en 1942.\nTuring (1950) : ‘can machines think?’\n‘intelligence artificielle’ : 1956\n\n« The word Artificial Intelligence was then officially coined about six years later, when in 1956 Marvin Minsky and John McCarthy (a computer scientist at Stanford) hosted the approximately eight-week-long Dartmouth Summer Research Project on Artificial Intelligence (DSRPAI) at Dartmouth College in New Hampshire. » (Haenlein and Kaplan 2019, 7)\n\n1966 : ELIZA (Weizenbaum 1966)\n1990-2000s : pic des systèmes experts et des arbres de décision. DeepBlue d’IBM (Campbell, Hoane, and Hsu 2002)."
  },
  {
    "objectID": "intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-2",
    "href": "intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-2",
    "title": "Intro",
    "section": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 2)",
    "text": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 2)\n2010s : pic des systèmes d’IA avec une modélisation distributionnelle du language (vecteur). Word2Vec (Mikolov et al. 2013), GloVE (Pennington, Socher, and Manning 2014). Parmi les avancées majeures de cette modélisation on compte le mécanisme d’attention (Vaswani et al. 2017) et l’encodage bidirectionnel BERT (Devlin et al. 2019) qui permettent des modèles très performants comme le GPT-3 d’OpenAI (Brown et al. 2020).\nActuellement : tendance à l’hybridation (Marcus 2020)"
  },
  {
    "objectID": "intro.html#typologie-de-lia",
    "href": "intro.html#typologie-de-lia",
    "title": "Intro",
    "section": "Typologie de l’IA",
    "text": "Typologie de l’IA\n\nApproche experte : modélisation d’un programme à partir de règles précises. Les règles doivent être applicables à de nouvelles données pour faire une prédiction.\nApproche distributionnelle : modélisation d’un programme à partir d’un grand volume de données. Ce sont les motifs de répétitions qui permettent à la machine d’émettre une prédiction."
  },
  {
    "objectID": "intro.html#ce-quil-faut-retenir",
    "href": "intro.html#ce-quil-faut-retenir",
    "title": "Intro",
    "section": "Ce qu’il faut retenir",
    "text": "Ce qu’il faut retenir\n\ndeux modélisations : une approche top-down et une approche sample-based.\n‘des saisons’ en IA càd que certaines approches attirent l’attention à un moment donné, actuellement IA = chatbot voire ChatGPT.\nl’IA réfère à des algorithmes qui permettent d’automatiser une prise de décision et pas seulement à des programmes de génération textuelle."
  },
  {
    "objectID": "25-07_programme_ateliersIA2526.html",
    "href": "25-07_programme_ateliersIA2526.html",
    "title": "Programme Atelier IA certificat",
    "section": "",
    "text": "Séance 1 : Introduction aux théories et à l’historique de l’IA et typologie des outils.\nDate : 11 septembre\nPrompt injection, hacker un LLM :\npartir d’une phrase d’exemple simple puis faire son découpage.\ntâche détection de spam :\nDÉCOUVRE TON CADEAU\nDemande de renseignements\n‘hallucination’ -&gt;\n\n\nSéance 2 : Thématique révision et correction automatique.\nDate 9 octobre\nDifférence entre un outil spécialisé et non-spécialisé.\n\nOutils généralistes\nChatGPT, LLM non entrainés.\n\n\nOutils spécialisés (correction, écriture académique)\nhttps://www.editpad.org/ : AI detector, humanize AI text, Plagiarim checker, paraphrasing tool, story generator, text summarizer, AI essay writer etc. Probablement juste ChatGPT hooked à une interface avec un system-prompt. Apparamment mauvais according to @bordalejoScarletCloakForest2025\nhttps://www.writefull.com/\nhttps://www.grammarly.com/\n\n\n\nSéance 3 : Thématique recherche d’information et synthèse des sources.\nDate: 15 janvier\n\n\nSéance 4 : Synthèse des outils et méthodologies pour l’évaluation qualitative et quantitative.\nDate : 12 mars"
  },
  {
    "objectID": "intro.html#bibliographie",
    "href": "intro.html#bibliographie",
    "title": "Intro",
    "section": "Bibliographie",
    "text": "Bibliographie\n\n\n\n\nBrown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. “Language Models Are Few-Shot Learners.” arXiv. https://doi.org/10.48550/arXiv.2005.14165.\n\n\nCampbell, Murray, A. Joseph Hoane, and Feng-hsiung Hsu. 2002. “Deep Blue.” Artificial Intelligence 134 (1): 57–83. https://doi.org/10.1016/S0004-3702(01)00129-1.\n\n\nConnelly, Daniel. n.d. “Eliza.py.” Eliza Emulation Python. https://dhconnelly.com/paip-python/docs/paip/eliza.html. Accessed August 20, 2025.\n\n\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.” In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), edited by Jill Burstein, Christy Doran, and Thamar Solorio, 4171–86. Minneapolis, Minnesota: Association for Computational Linguistics. https://doi.org/10.18653/v1/N19-1423.\n\n\nFujinaga, Ichiro. 2025. “On the virtues of lazy machines.” {Keynote}. Montréal.\n\n\nHaenlein, Michael, and Andreas Kaplan. 2019. “A Brief History of Artificial Intelligence: On the Past, Present, and Future of Artificial Intelligence.” California Management Review 61 (4): 5–14. https://doi.org/10.1177/0008125619864925.\n\n\n“How Do I Cite Generative AI in MLA Style?” 2023. MLA Style Center.\n\n\nKnuth, D. E. 1984. “Literate Programming.” The Computer Journal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nMarcus, Gary. 2020. “The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence.” arXiv. https://doi.org/10.48550/arXiv.2002.06177.\n\n\nMikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. “Efficient Estimation of Word Representations in Vector Space.” arXiv. https://doi.org/10.48550/arXiv.1301.3781.\n\n\nMulliken, Jasmine. 2025. “2025 AUPresses Week-in-Residence Report.”\n\n\nNaddaf, Miryam. 2025. “AI Is Transforming Peer Review — and Many Scientists Are Worried.” Nature 639 (8056): 852–54. https://doi.org/10.1038/d41586-025-00894-7.\n\n\nPennington, Jeffrey, Richard Socher, and Christopher Manning. 2014. “GloVe: Global Vectors for Word Representation.” In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), edited by Alessandro Moschitti, Bo Pang, and Walter Daelemans, 1532–43. Doha, Qatar: Association for Computational Linguistics. https://doi.org/10.3115/v1/D14-1162.\n\n\nTuring, A. M. 1950. “Computing Machinery and Intelligence.” Mind LIX (236): 433–60. https://doi.org/10.1093/mind/LIX.236.433.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need.” arXiv. https://doi.org/10.48550/arXiv.1706.03762.\n\n\nVitali-Rosati, Marcello. 2025. “Manifeste Pour Des Études Critiques de l’Intelligence Artificielle.” Culture Numérique. Pour Une Philosophie Du Numérique.\n\n\nWeizenbaum, Joseph. 1966. “ELIZA—a Computer Program for the Study of Natural Language Communication Between Man and Machine.” Communications of the ACM 9 (1): 36–45. https://doi.org/10.1145/365153.365168."
  },
  {
    "objectID": "intro.html#partons-dun-exemple",
    "href": "intro.html#partons-dun-exemple",
    "title": "Intro",
    "section": "Partons d’un exemple",
    "text": "Partons d’un exemple\nObjectif : obtenir un programme capable de classer une phrase selon une thématique prédéfinie.\nExemple : Classification d’un texte en “parle de fruit” vs. “ne parle pas de fruit”."
  },
  {
    "objectID": "intro.html#modéliser-une-approche-experte",
    "href": "intro.html#modéliser-une-approche-experte",
    "title": "Intro",
    "section": "Modéliser une approche experte",
    "text": "Modéliser une approche experte\n\nfaire appel à un expert : un humain pour déterminer les règles qui définissent ce qui est une phrase parlant de fruits.\nexemple de règle possible : liste de mots comme ‘pomme, pommes, banane, poire etc.’ ordre des mots ou POS pour distinguer ‘orange’ couleur du fruit par exemple.\n\nUne approche qui sembler simpliste en apparence mais qui :\n\npeut s’avérer très complexe (ex: traduction)\nest la base de systèmes très performants\nentre dans une logique de lazy computing (Fujinaga 2025)\nrévèle les tâches de bas niveau pour passer d’une chaîne de caractères à un ensemble de caractéristiques : tokenisation, POS-tagging.\n\nProgramme de démo"
  },
  {
    "objectID": "intro.html#exemple-dun-programme-conversationnel-génération-textuelle-avec-une-approche-experte-eliza",
    "href": "intro.html#exemple-dun-programme-conversationnel-génération-textuelle-avec-une-approche-experte-eliza",
    "title": "Intro",
    "section": "Exemple d’un programme conversationnel /génération textuelle avec une approche experte ELIZA",
    "text": "Exemple d’un programme conversationnel /génération textuelle avec une approche experte ELIZA\nTry it yourself : ELIZA\n\nEliza is a pattern-matching automated psychiatrist. Given a set of rules in the form of input/output patterns, Eliza will attempt to recognize user input phrases and generate relevant psychobabble responses. Each rule is specified by an input pattern and a list of output patterns. A pattern is a sentence consisting of space-separated words and variables. (Connelly n.d.)\n\nExemple de literate programming (Knuth 1984) :\nLire le code d’ELIZA"
  },
  {
    "objectID": "intro.html#modélisation-vectorielle-et-machine-learning",
    "href": "intro.html#modélisation-vectorielle-et-machine-learning",
    "title": "Intro",
    "section": "Modélisation vectorielle et machine learning",
    "text": "Modélisation vectorielle et machine learning\n\npartir d’un ensemble important d’exemples\ntravail d’annotation par un humain/expert: ground truth ou vérité de terrain.\n1 token = une caractéristique\ncomptage des tokens dans l’ensemble du jeu de données et dans chaque phrase/document.\nreprésentation vectorielle = coordonnées dans un espace vectoriel à n dimensions.\n\nVisualisation de traitement basique (NER, POS et vectorisation)\n\n\nmême traitement est effectué sur de nouvelles données\ndifférentes logiques pour classer la nouvelle donnée :\n\nK-Nearest Neighbor\nRegression logistique\n\n\nPoints forts :\n\nadaptable à des nouvelles données, notamment avec une tokenisation fragmentée"
  },
  {
    "objectID": "intro.html#les-llms",
    "href": "intro.html#les-llms",
    "title": "Intro",
    "section": "Les LLMs",
    "text": "Les LLMs\nExemple de LLMs : GPT-4, Mixtral, Gemini, Llama, Qwen, DeepSeek etc.\nLarge Language Models : 1. modélisation vectorielle de chaque mot de la langue par rapport à sa fréquence d’apparition en contexte avec chacun des autres mots de la langue, 2. spécialisation sous forme de couche neuronale pour une tâche ou une fonction précise. 3. query et calcul pour chaque donnée en entrée du token le plus probable en sortie"
  },
  {
    "objectID": "intro.html#duck.ai",
    "href": "intro.html#duck.ai",
    "title": "Intro",
    "section": "Duck.ai",
    "text": "Duck.ai\nduck.ai permet de comparer des modèles en interfaces chat tout en conservant des données privées : https://duck.ai"
  },
  {
    "objectID": "intro.html#ollama",
    "href": "intro.html#ollama",
    "title": "Intro",
    "section": "Ollama",
    "text": "Ollama\nIl est pourtant possible de faire tourner un SLM (small language model) localement. Pour ce faire : ollama est une bibliothèque qui permet de télécharger et d’utiliser localement un LLMs.\ntéléchargement\nhttps://ollama.com/download\ncommand line\nollama run llama3.2\n““” -&gt; pour des instructions longues\nollama list -&gt; liste des modèles téléchargés et utilisables\nollama rm llama3.2 -&gt; supprime un modèle"
  },
  {
    "objectID": "intro.html#paramètres-dun-modèle",
    "href": "intro.html#paramètres-dun-modèle",
    "title": "Intro",
    "section": "Paramètres d’un modèle",
    "text": "Paramètres d’un modèle\nPlusieurs paramètres importants et contrôlable :\n\nle seed :les LLMs ont une variable aléatoire dans leur paramètre : le seed permet d’utiliser toujours le même ordre aléatoire, càd d’obtenir pour un même prompt toujours la même réponse et ainsi de rendre reproductible une réponse.\nla température: détermine le degré d’utilisation de la variable aléatoire (mas o menos)\ntop_k : Reduces the probability of generating nonsense. A higher value (e.g. 100) will give more diverse answers, while a lower value (e.g. 10) will be more conservative. (Default: 40)\ntop_p: Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value (e.g., 0.5) will generate more focused and conservative text. (Default: 0.9)"
  },
  {
    "objectID": "intro.html#model-steering",
    "href": "intro.html#model-steering",
    "title": "Intro",
    "section": "model Steering",
    "text": "model Steering\nhttps://github.com/ollama/ollama/blob/main/docs/modelfile.md\nCréer un nouveau document ‘Modelfile’ sans extension touch Modelfile\nFROM llama3.2\nPARAMETER temperature 1\ntop_k 100\ntop_p 1\nseed 17\nSYSTEM \"Tu es un chien\"\nollama create chien -f Modelfile\nollama run chien"
  },
  {
    "objectID": "intro.html#limites-des-interfaces-de-chat",
    "href": "intro.html#limites-des-interfaces-de-chat",
    "title": "Intro",
    "section": "Limites des interfaces de chat",
    "text": "Limites des interfaces de chat\n\nles chatbots ont des limites : on peut ‘hacker un LLM’ avec du prompt injection ou autres techniques de Jailbreaking.\n\nIncitent database\n\nHidden prompts reportedly were discovered in at least 17 academic preprints on arXiv that purportedly instructed AI tools to deliver only positive peer reviews. The lead authors are reportedly affiliated with 14 institutions in eight countries, including Waseda University, KAIST, Peking University, and the University of Washington. The alleged concealed instructions, some of which were reportedly embedded using white text or tiny fonts, were purportedly intended to influence any reviewers who rely on AI tools. (https://incidentdatabase.ai/cite/1135)\n\n\nil n’y a pas d’hallucinations, toutes les générations produites par un LLMs ont la même teneur de vérité du pdv de l’outil : le modèle ne peut pas évaluer sa réponse à l’aune d’une ground truth comme dans sa phase d’entraînement.\nProblèmes et réflexions pour les SHS :\n\nuniformisation des pratiques, des modes de pensées : l’interface de chat est une façon de formaliser son problème, quid de la recherhce de solution en interrogeant des moteurs de recherche, des bdd ou archives spécialisées ?\nDerrière l’apparente accessibilité de l’interface de chat, est-ce qu’on ne risque pas de creuser l’écart de la littératie numérique ?\nEst-ce que ces connaissances spécifiques, comme celles du code, qui impliquent des capacités de raisonnement alternatives, ne risquent pas de se retrouver suelement dans une forme d’élite intellectuelle ?"
  },
  {
    "objectID": "intro.html#llms-et-non-chatbot",
    "href": "intro.html#llms-et-non-chatbot",
    "title": "Intro",
    "section": "LLMs et non chatbot",
    "text": "LLMs et non chatbot\nClassification (de token, de texte)"
  },
  {
    "objectID": "intro.html#llms-et-chatbot",
    "href": "intro.html#llms-et-chatbot",
    "title": "Intro",
    "section": "LLMs et chatbot",
    "text": "LLMs et chatbot\nParce que les LLMs sont lourds (plusieurs Gigas) et parce qu’il est coûteux en énergie d’effectuer les calculs qui permettent de déterminer le prochain token (plusieurs GPU), l’usage le plus courant des LLMs est via un site qui va interroger le modèle sur un serveur distant. C’est la forme ChatGPT, Mistral.ai, etc."
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "Ateliers IA pour les SHS",
    "section": "",
    "text": "‘IA’ est le terme qui a envahit nos discours depuis quelques années. Vous saturez ? Nous aussi ! Cette série d’atelier vise à outiller chercheurs et chercheuses en SHS pour comprendre les fondements de cette discipline afin de dépasser à la fois les discours marketing qui imprègnent malgré nous l’espace public et les propos alarmistes des derniers réfractaires.\n\n\nIntroduire à la communauté universitaire en SHS les fondements de l’étude critique des IA avec une stratégie d’apprentissage par la prise en main. Aucun pré-requis en informatique n’est nécessaire : apportez simplement votre ordinateur.\n\nSensibiliser sur l’impact des nouvelles outils sur les pratiques de recherche et d’édition en contexte universitaire\nOrienter les chercheur.se.s vers des outils d’IA adaptés à la recherche et allignés avec les préconisations éthiques actuelles.\nEclaircir les amalgames courants au sujet de l’IA et les chatbots par l’acquisition de connaissances fondamentales en IA."
  },
  {
    "objectID": "index.html#programme",
    "href": "index.html#programme",
    "title": "Ateliers IA pour les SHS",
    "section": "Programme",
    "text": "Programme\nSéances de 2 heures, sans inscription, participation libre.\nBibliothèques des Lettres et Sciences Humaines (15h30 - 17h30)\nSéance 1 : jeudi 11 septembre 2025 15:30: Introduction : comment distinguer l’IA de ChatGPT\nQu’est-ce qu’on entend exactement par Intelligence Artificielle aujourd’hui ? Pour ne pas se sentir dépassé par le discours ambiant sur ces nouvelles technologies et leurs grandes promesses, on vous propose une séance de rattrapage sur les fondements de l’IA. Venez apprendre la place des chatbots dans l’histoire de la discipline et comprendre l’intérêt d’étudier l’IA du point de vue des SHS.\n-&gt; Alexia Schneider & Marcello Vitali-Rosati\nSéance 2 : jeudi 09 octobre 2025 15:30 IA et la correction textuelle automatique : quels outils et quelles limites ?\nLes outils d’IA générative se sont désormais immiscés dans tous nos logiciels d’édition, aussi bien pour la rédaction de mail, de documents textuels que pour de l’assistance à la rédaction de fiction ou de dissertation, mais comment faire la différence entre toutes les formes de corrections possibles et mesurer l’intérêt et l’impact de ces outils dans nos pratiques. Cet atelier vise à outiller les chercheur.se.s en SHS sur les outils existants et offrir des pistes pour mesurer leur impact dans leurs pratiques individuelles.\n-&gt; Alexia Schneider & Clara Grometto\nSéance 3 : jeudi 15 janvier 2026 15:30 Synthèse des sources et Recherche d’Information\nOn vous a sûrement déjà dit que pour limiter les erreurs des IA génératives et pour s’assurer qu’une machine rende les bonnes informations, il fallait passer par un RAG. Mais qu’est-ce qu’un RAG et comment est-ce que ça fontionne exactement ? Dans cet atelier vous apprendrez à disséquer un outils de Recherche d’information associé à un outil de synthèse de texte.\n-&gt; Alexia Schneider\nSéance 4 : jeudi 12 mars 2026 15:30 Documentation des nouvelles pratiques liées à l’utilisation de l’IA : préconisations pour les SHS\nVoilà maintenant quelques années que l’IA est devenue monnaie courante et l’heure est désormais à la pérénisation des guides d’utilisation et des limites définies par les institutions de recherche et d’enseignement. Cet atelier présente les lignes directrices adoptées par les institutions en SHS ainsi que les méthodes de documentation existantes de ces nouvelles pratiques de rédaction, de correction et de recherche d’information."
  },
  {
    "objectID": "sept11/intro.html#plan",
    "href": "sept11/intro.html#plan",
    "title": "Intro",
    "section": "Plan",
    "text": "Plan\n\nPrésentation de la série d’atelier\nQu’est-ce que l’IA ?\nIntérêt d’étudier l’IA pour les SHS\nRetours historiques\nTypologie des IA\nCas d’usage et modélisation experte (ELIZA)\nCas d’usage et modélisation distributionnelle/vectorielle (vectorisation et prédiction)\nLes LLMs\nUsages des LLMs hors chatbots (demo)\nLLMs et chatbots (Duck.ai + Ollama)\nConclusions"
  },
  {
    "objectID": "sept11/intro.html#présentation-et-objectif-des-ateliers",
    "href": "sept11/intro.html#présentation-et-objectif-des-ateliers",
    "title": "Intro",
    "section": "Présentation et objectif des ateliers",
    "text": "Présentation et objectif des ateliers\nFormat : 4 séances de 2heures, sans inscription, participation libre (à justifier pour le certificat des Humanités Numériques)\nThéorie et pratique en alternance au cours des deux heures.\nObjectifs de la série d’atelier :\n\nComprendre les fondamentaux de l’IA et son histoire\nObtenir des notions critiques sur le fonctionnement profond des outils\nTester et s’approprier des outils d’IA\nMaîtriser le vocabulaire de la discipline\n\nObjectifs de cet atelier :\n\nComprendre les différentes formes d’IA\nComprendre les enjeux liés à l’utilisation des LLM\nUtiliser de l’IA en dehors d’une interface de tchat.\nTester les paramètres des chatbots\nInstaller localement des modèles de langue."
  },
  {
    "objectID": "sept11/intro.html#quest-ce-que-lia",
    "href": "sept11/intro.html#quest-ce-que-lia",
    "title": "Intro",
    "section": "Qu’est ce que l’IA ?",
    "text": "Qu’est ce que l’IA ?\n\nTout et rien : exemples : chatbot, détection sur des imageries médicales, HTR, DeepBlue.\nle dernier mot à la mode. Le ‘numérique’ des années 2020. (Vitali-Rosati 2025)."
  },
  {
    "objectID": "sept11/intro.html#quest-ce-que-lia-1",
    "href": "sept11/intro.html#quest-ce-que-lia-1",
    "title": "Intro",
    "section": "Qu’est-ce que l’IA ?",
    "text": "Qu’est-ce que l’IA ?\nDéfinition pratique : “un programme informatique qui effectue une prédiction.”"
  },
  {
    "objectID": "sept11/intro.html#lia-et-les-shs",
    "href": "sept11/intro.html#lia-et-les-shs",
    "title": "Intro",
    "section": "L’IA et les SHS",
    "text": "L’IA et les SHS\nÀ quoi sert d’étudier l’IA pour les chercheur.se.s en SHS ?"
  },
  {
    "objectID": "sept11/intro.html#lia-et-les-shs-1",
    "href": "sept11/intro.html#lia-et-les-shs-1",
    "title": "Intro",
    "section": "L’IA et les SHS",
    "text": "L’IA et les SHS\nÀ quoi sert d’étudier l’IA pour les chercheur.se.s en SHS"
  },
  {
    "objectID": "sept11/intro.html#lia-et-les-shs-2",
    "href": "sept11/intro.html#lia-et-les-shs-2",
    "title": "Intro",
    "section": "L’IA et les SHS",
    "text": "L’IA et les SHS\nQue peuvent faire les SHS pour l’IA ?\n\nparticiper à la réflexion actuelle sur son utilisation :\n\npositionnements de revues et de conférences (pose un cadre, parfois un précédent)\n\nproposer une théorie critique de l’IA décentrées de l’effet ‘benchmarking’ (i.e. comparaison des modèles ou des entreprises qui les mettent à disposition)\nproposer une avis sur l’utilisation de ces outils qui soit propre à sa discipline (ex: distinguer des usages en fonction des besoins particuliers de son domaine)."
  },
  {
    "objectID": "sept11/intro.html#exemples-de-prises-de-position",
    "href": "sept11/intro.html#exemples-de-prises-de-position",
    "title": "Intro",
    "section": "Exemples de prises de position",
    "text": "Exemples de prises de position\n\nBoth SUP and JHUP have increasingly embraced, tested, and deployed some AI tools and policies. Barbara has been clear in her support of responsible uses of AI and the necessity of leveraging these early days to stake a claim within the quickly evolving landscape. Like SUP, JHUP is building and testing its own tools for marketing, accessibility, and analytics, efforts which place our presses in a position to potentially build services that might in the future even benefit other university presses. (Mulliken 2025)\n\n\nwe offer recommendations for citing generative AI, defined as a tool that “can analyze or summarize content from a huge set of information, including web pages, books and other writing available on the internet, and use that data to create original new content” (Weed). (“How Do I Cite Generative AI in MLA Style?” 2023)\n\n\nThe uncomfortable truth for researchers and publishers who oppose AI slowly taking over human review is that they might not be able to prevent it. Should a researcher use AI to write the first pass of peer review and not disclose it — in contravention of publisher guidelines — that might not be detectable, says Hosseini, who is also one of the editors of the journal Accountability in Research. And if AI reviews become widespread, that could change the practice of science, says Priem. “Every researcher can run their own bespoke review service over the preprint/dataset landscape, flagging/extracting only the science they care about (at any “quality” level) they want that day,” he wrote on X earlier this year. That could start to eat into the roles of journals, by taking away the certification that peer review mediated by journals provides, he says. (Naddaf 2025)\n\n\nBuilding critical AI literacies is a process of empowerment that enables students and citizens to exercise independent judgment about whether or if to use this very new and largely untested commercial technology. (rutgersCriticalAILiteracies2024?)"
  },
  {
    "objectID": "sept11/intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-1",
    "href": "sept11/intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-1",
    "title": "Intro",
    "section": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 1)",
    "text": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 1)\n1940s : Science-fiction et roman d’Isaac Asimov Runaround en 1942.\nTuring (1950) : ‘can machines think?’\n‘intelligence artificielle’ : 1956\n\n« The word Artificial Intelligence was then officially coined about six years later, when in 1956 Marvin Minsky and John McCarthy (a computer scientist at Stanford) hosted the approximately eight-week-long Dartmouth Summer Research Project on Artificial Intelligence (DSRPAI) at Dartmouth College in New Hampshire. » (Haenlein and Kaplan 2019, 7)\n\n1966 : ELIZA (Weizenbaum 1966)\n1990-2000s : pic des systèmes experts et des arbres de décision. DeepBlue d’IBM (Campbell, Hoane, and Hsu 2002)."
  },
  {
    "objectID": "sept11/intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-2",
    "href": "sept11/intro.html#brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-2",
    "title": "Intro",
    "section": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 2)",
    "text": "Brève histoire de l’IA et des applications de linguistique computationnelle (pt. 2)\n2010s : pic des systèmes d’IA avec une modélisation distributionnelle du language (vecteur). Word2Vec (Mikolov et al. 2013), GloVE (Pennington, Socher, and Manning 2014). Parmi les avancées majeures de cette modélisation on compte le mécanisme d’attention (Vaswani et al. 2017) et l’encodage bidirectionnel BERT (Devlin et al. 2019) qui permettent des modèles très performants comme le GPT-3 d’OpenAI (Brown et al. 2020).\nActuellement : tendance à l’hybridation de ces modèles : Neuro-Symbolic Integration, Semantic Web Machine Learning (Marcus 2020; Breit et al. 2023)"
  },
  {
    "objectID": "sept11/intro.html#typologie-de-lia",
    "href": "sept11/intro.html#typologie-de-lia",
    "title": "Intro",
    "section": "Typologie de l’IA",
    "text": "Typologie de l’IA\n\nApproche experte ou modèle symbolique : modélisation d’un programme à partir de règles précises. Les règles doivent être applicables à de nouvelles données pour faire une prédiction.\nApproche inductive ou modèle d’apprentissage machine (machine learning) : modélisation d’un programme à partir d’un grand volume de données. Ce sont les motifs de répétitions qui permettent à la machine d’émettre une prédiction."
  },
  {
    "objectID": "sept11/intro.html#ce-quil-faut-retenir",
    "href": "sept11/intro.html#ce-quil-faut-retenir",
    "title": "Intro",
    "section": "Ce qu’il faut retenir",
    "text": "Ce qu’il faut retenir\n\nL’IA réfère à plusieurs type de modélisations pour la prédiction : une approche déductive et une approche inductive.\nOn parle ‘des saisons’ de l’IA pour évoquer l’attrait public de la discipline et son avancée depuis les années 1950.\nPar conséquent, certaines approches attirent l’attention à un moment donné, actuellement IA = chatbot voire ChatGPT.\nL’IA réfère à des algorithmes qui permettent d’automatiser une prise de décision et pas seulement à des programmes de génération textuelle."
  },
  {
    "objectID": "sept11/intro.html#partons-dun-exemple",
    "href": "sept11/intro.html#partons-dun-exemple",
    "title": "Intro",
    "section": "Partons d’un exemple",
    "text": "Partons d’un exemple\nObjectif : obtenir un programme capable de classer une phrase selon une thématique prédéfinie.\nExemple : Classification d’un texte soit en “parle de fruit” soit en “ne parle pas de fruit”.\nVocabulaire :\ndocument : ici une phrase\nclasses : ensemble thématique de la classification. Ex : “fruit” et “non fruit” pour la classification binaire de notre exemple.\njeu de données : ensemble des documents\napprentissage supervisé : méthode d’apprentissage machine à partir de classes connues.\napprentissage non-supervisé : méthode d’apprentissage machine sans connaître les classes à l’avance : a pour objectif de déterminer les caractéristiques discriminantes d’un jeu de données.\nvérité de terrain ou ground truth : annotation effectuée par un humain sur l’ensemble du jeu de données."
  },
  {
    "objectID": "sept11/intro.html#modéliser-une-approche-experte",
    "href": "sept11/intro.html#modéliser-une-approche-experte",
    "title": "Intro",
    "section": "Modéliser une approche experte",
    "text": "Modéliser une approche experte\n\nfaire appel à un expert : un humain pour déterminer les règles qui définissent ce qui est une phrase parlant de fruits.\nexemple de règle possible : liste de mots comme ‘pomme, pommes, banane, poire etc.’ ordre des mots ou POS pour distinguer ‘orange’ couleur du fruit par exemple.\n\nUne approche qui sembler simpliste en apparence mais qui :\n\npeut s’avérer très complexe (ex: traduction)\nest la base de systèmes très performants\nentre dans une logique de lazy computing (Fujinaga 2025)\nrévèle les tâches de bas niveau pour passer d’une chaîne de caractères à un ensemble de caractéristiques : tokenisation, POS-tagging.\n\nProgramme de démo"
  },
  {
    "objectID": "sept11/intro.html#exemple-dun-programme-conversationnel-génération-textuelle-avec-une-approche-experte-eliza",
    "href": "sept11/intro.html#exemple-dun-programme-conversationnel-génération-textuelle-avec-une-approche-experte-eliza",
    "title": "Intro",
    "section": "Exemple d’un programme conversationnel /génération textuelle avec une approche experte ELIZA",
    "text": "Exemple d’un programme conversationnel /génération textuelle avec une approche experte ELIZA\nTry it yourself : ELIZA\n\nEliza is a pattern-matching automated psychiatrist. Given a set of rules in the form of input/output patterns, Eliza will attempt to recognize user input phrases and generate relevant psychobabble responses. Each rule is specified by an input pattern and a list of output patterns. A pattern is a sentence consisting of space-separated words and variables. (Connelly n.d.)\n\nExemple de literate programming (Knuth 1984) :\nLire le code d’ELIZA"
  },
  {
    "objectID": "sept11/intro.html#modélisation-vectorielle-et-machine-learning",
    "href": "sept11/intro.html#modélisation-vectorielle-et-machine-learning",
    "title": "Intro",
    "section": "Modélisation vectorielle et machine learning",
    "text": "Modélisation vectorielle et machine learning\n\npartir d’un ensemble important d’exemples\ntravail d’annotation par un humain/expert: ground truth ou vérité de terrain.\n1 token = une caractéristique\ncomptage des tokens dans l’ensemble du jeu de données et dans chaque phrase/document.\nreprésentation vectorielle = coordonnées dans un espace vectoriel à n dimensions.\n\nVisualisation de traitement basique (NER, POS et vectorisation)\n\n\nmême traitement est effectué sur de nouvelles données\ndifférentes logiques pour classer la nouvelle donnée :\n\nK-Nearest Neighbor\nRegression logistique\n\n\nPoints forts :\n\nadaptable à des nouvelles données, notamment avec une tokenisation fragmentée"
  },
  {
    "objectID": "sept11/intro.html#les-llms",
    "href": "sept11/intro.html#les-llms",
    "title": "Intro",
    "section": "Les LLMs",
    "text": "Les LLMs\nExemple de LLMs : GPT-4, Mixtral, Gemini, Llama, Qwen, DeepSeek etc.\nLarge Language Models : 1. Encodage : Word embeddings ou plongement de mots obtenu par rapport à sa fréquence d’apparition en contexte avec chacun des autres mots de la langue à partir d’un volume de données textuelle gigantesque. Modèles de type BERT : encodage bilatéral avec méchanisme d’attention. 2. Spécialisation du modèle sous forme de couches neuronales pour une tâche ou une fonction précise. 3. Query et calcul pour chaque donnée en entrée du token le plus probable en sortie."
  },
  {
    "objectID": "sept11/intro.html#llms-et-non-chatbot",
    "href": "sept11/intro.html#llms-et-non-chatbot",
    "title": "Intro",
    "section": "LLMs et non chatbot",
    "text": "LLMs et non chatbot\nClassification (de token, de texte)"
  },
  {
    "objectID": "sept11/intro.html#llms-et-chatbot",
    "href": "sept11/intro.html#llms-et-chatbot",
    "title": "Intro",
    "section": "LLMs et chatbot",
    "text": "LLMs et chatbot\nParce que les LLMs sont lourds (plusieurs Gigas) et parce qu’il est coûteux en énergie d’effectuer les calculs qui permettent de déterminer le prochain token (plusieurs GPU), l’usage le plus courant des IA générative est via un site qui va interroger le modèle sur un serveur distant. C’est la forme ChatGPT, Mistral.ai, etc."
  },
  {
    "objectID": "sept11/intro.html#duck.ai",
    "href": "sept11/intro.html#duck.ai",
    "title": "Intro",
    "section": "Duck.ai",
    "text": "Duck.ai\nduck.ai permet de comparer des modèles en interfaces chat tout en conservant des données privées."
  },
  {
    "objectID": "sept11/intro.html#ollama",
    "href": "sept11/intro.html#ollama",
    "title": "Intro",
    "section": "Ollama",
    "text": "Ollama\nIl est possible de faire tourner un SLM (small language model) localement. Pour ce faire : ollama est une bibliothèque qui permet de télécharger et d’utiliser localement un LLMs.\nInstallation et utilisation de Ollama\nTéléchargement de Ollama\nUtilisation de Ollama en invite de commande\nVia l’invite de commande\nollama run llama3.2 -&gt; télécharge et lance le modèle.\n““” -&gt; pour des instructions longues\n/show info -&gt; information sur le modèle téléchargé\nollama list -&gt; liste des modèles téléchargés et utilisables\nollama rm llama3.2 -&gt; supprime un modèle"
  },
  {
    "objectID": "sept11/intro.html#paramètres-dun-modèle",
    "href": "sept11/intro.html#paramètres-dun-modèle",
    "title": "Intro",
    "section": "Paramètres d’un modèle",
    "text": "Paramètres d’un modèle\n\nLe seed (nombre que l’on peut choisir): les LLMs ont une variable aléatoire au moment de l’encodage des données et au moment du requêtage : le seed permet d’utiliser toujours le même ordre aléatoire, càd d’obtenir pour un même prompt toujours la même réponse. Enjeu de reproductibilité.\nLa température (valeur de 0 à 1): détermine le degré d’utilisation de la variable aléatoire. Une température élevée signifie que le modèle sera plus “créatif” car il donnera plus probablement un token qui a une probabilité absolue moindre dans son contexte.\ntop_k (valeur de 0 à 100): variable qui réduit la probabilité de générer des tokens absurdes. Une valeur élevée donne des réponses plus variées et une valeur basse des réponses plus conservatrices. (Défaut 40)\ntop_p (valeur de 0 à 1): Fonctionne avec le top_k. Une valeur haute donne un texte varié, une valeur basse, un texte conservateur. (Défaut: 0,9)\n\nSource : Documentation Ollama"
  },
  {
    "objectID": "sept11/intro.html#model-steering",
    "href": "sept11/intro.html#model-steering",
    "title": "Intro",
    "section": "Model Steering",
    "text": "Model Steering\nReconduire un modèle consiste à lui fournir des ordres qui vont modifier son comportement pour toutes les interactions.\nTutoriel\nCréer un nouveau document ‘Modelfile’ sans extension.\nLinux : cat &gt; Modelfile puis CTRL+C :\n\nFROM llama3.2 PARAMETER temperature 1 top_k 100 top_p 1 seed 17 SYSTEM “Tu es un chien”\n\npuis CTRL+SHIFT+D et CTRL+D\nWindows cmd (Win+R): echo 'FROM llama3.2 PARAMETER temperature 1 top_k 100 top_p 1 seed 17 SYSTEM \"Tu es un chien\"' &gt; Modelfile (CTRL+SHIFT+D)\nOu c/c manuellement :\n\nFROM llama3.2 PARAMETER temperature 1 top_k 100 top_p 1 seed 17 SYSTEM “Tu es un chien”\n\nollama create chien -f Modelfile\nollama run chien"
  },
  {
    "objectID": "sept11/intro.html#limites-des-interfaces-de-chat",
    "href": "sept11/intro.html#limites-des-interfaces-de-chat",
    "title": "Intro",
    "section": "Limites des interfaces de chat",
    "text": "Limites des interfaces de chat\n\nles chatbots ont des limites : on peut ‘hacker un LLM’ avec du prompt injection ou autres techniques de jailbreaking.\n\nIncitent database\n\nHidden prompts reportedly were discovered in at least 17 academic preprints on arXiv that purportedly instructed AI tools to deliver only positive peer reviews. The lead authors are reportedly affiliated with 14 institutions in eight countries, including Waseda University, KAIST, Peking University, and the University of Washington. The alleged concealed instructions, some of which were reportedly embedded using white text or tiny fonts, were purportedly intended to influence any reviewers who rely on AI tools. (https://incidentdatabase.ai/cite/1135)\n\n\nil n’y a pas d’hallucinations, toutes les générations produites par un LLMs ont la même teneur de vérité du pdv de l’outil : le modèle ne peut pas évaluer sa réponse à l’aune d’une ground truth comme dans sa phase d’entraînement."
  },
  {
    "objectID": "sept11/intro.html#bibliographie",
    "href": "sept11/intro.html#bibliographie",
    "title": "Intro",
    "section": "Bibliographie",
    "text": "Bibliographie\n\n\n\n\nBreit, Anna, Laura Waltersdorfer, Fajar J. Ekaputra, Marta Sabou, Andreas Ekelhart, Andreea Iana, Heiko Paulheim, et al. 2023. “Combining Machine Learning and Semantic Web: A Systematic Mapping Study.” ACM Computing Surveys 55 (14s): 313:1–41. https://doi.org/10.1145/3586163.\n\n\nBrown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. “Language Models Are Few-Shot Learners.” arXiv. https://doi.org/10.48550/arXiv.2005.14165.\n\n\nCampbell, Murray, A. Joseph Hoane, and Feng-hsiung Hsu. 2002. “Deep Blue.” Artificial Intelligence 134 (1): 57–83. https://doi.org/10.1016/S0004-3702(01)00129-1.\n\n\nConnelly, Daniel. n.d. “Eliza.py.” Eliza Emulation Python. https://dhconnelly.com/paip-python/docs/paip/eliza.html. Accessed August 20, 2025.\n\n\nDevlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.” In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), edited by Jill Burstein, Christy Doran, and Thamar Solorio, 4171–86. Minneapolis, Minnesota: Association for Computational Linguistics. https://doi.org/10.18653/v1/N19-1423.\n\n\nFujinaga, Ichiro. 2025. “On the virtues of lazy machines.” {Keynote}. Montréal.\n\n\nHaenlein, Michael, and Andreas Kaplan. 2019. “A Brief History of Artificial Intelligence: On the Past, Present, and Future of Artificial Intelligence.” California Management Review 61 (4): 5–14. https://doi.org/10.1177/0008125619864925.\n\n\n“How Do I Cite Generative AI in MLA Style?” 2023. MLA Style Center.\n\n\nKnuth, D. E. 1984. “Literate Programming.” The Computer Journal 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\nMarcus, Gary. 2020. “The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence.” arXiv. https://doi.org/10.48550/arXiv.2002.06177.\n\n\nMikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. “Efficient Estimation of Word Representations in Vector Space.” arXiv. https://doi.org/10.48550/arXiv.1301.3781.\n\n\nMulliken, Jasmine. 2025. “2025 AUPresses Week-in-Residence Report.”\n\n\nNaddaf, Miryam. 2025. “AI Is Transforming Peer Review — and Many Scientists Are Worried.” Nature 639 (8056): 852–54. https://doi.org/10.1038/d41586-025-00894-7.\n\n\nPennington, Jeffrey, Richard Socher, and Christopher Manning. 2014. “GloVe: Global Vectors for Word Representation.” In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), edited by Alessandro Moschitti, Bo Pang, and Walter Daelemans, 1532–43. Doha, Qatar: Association for Computational Linguistics. https://doi.org/10.3115/v1/D14-1162.\n\n\nTuring, A. M. 1950. “Computing Machinery and Intelligence.” Mind LIX (236): 433–60. https://doi.org/10.1093/mind/LIX.236.433.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need.” arXiv. https://doi.org/10.48550/arXiv.1706.03762.\n\n\nVitali-Rosati, Marcello. 2025. “Manifeste Pour Des Études Critiques de l’Intelligence Artificielle.” Culture Numérique. Pour Une Philosophie Du Numérique.\n\n\nWeizenbaum, Joseph. 1966. “ELIZA—a Computer Program for the Study of Natural Language Communication Between Man and Machine.” Communications of the ACM 9 (1): 36–45. https://doi.org/10.1145/365153.365168."
  },
  {
    "objectID": "sept11/intro.html#approche-inductive-la-modélisation-vectorielle-et-le-machine-learning",
    "href": "sept11/intro.html#approche-inductive-la-modélisation-vectorielle-et-le-machine-learning",
    "title": "Intro",
    "section": "Approche inductive : la modélisation vectorielle et le machine learning",
    "text": "Approche inductive : la modélisation vectorielle et le machine learning\n1e étape Modélisation des données\n\nConstitution d’un corpus : obtenir un ensemble important de documents.\nAttribution d’une classe à chaque document : annotation par un humain/expert, ground truth ou vérité de terrain.\nEncodage : Comptage des tokens dans l’ensemble du jeu de données et dans chaque phrase/document.\nOn obtient une représentation vectorielle = coordonnées dans un espace vectoriel à n dimensions.\n\n\nReprésentation vectorielle ou word embeddings2e étape Détermination de la logique de prédiction\nDifférentes logiques permettent de distinguer les données entre elles. Quelques exemples d’apprentissage machine classique :\n\nK-Nearest Neighbor -&gt; le token apartient à la même classe que ses voisins (au nombre K)\nArbre de décision -&gt; on construit un arbre de questions fermées qui dessine le jeu de données.\nRegression logistique -&gt; une ligne sépare l’espace vectoriel entre les deux classes\n\n3e étape Apprentissage\n\nDivision du jeu de données en données d’entrainement et données de test.\nCalcul des poids de chaque token (régression logistique ou arbre de décision) sur les données d’entrainement.\nPrédiction sur les données de test\nComparaison avec la vérité de terrain\nAjustement des poids : réitération de l’apprentissage si les prédictions sont insatisfaisantes. (Cette étape est très énergivore)\n\n4e étape Evaluation ou utilisation du modèle sur de nouvelles données\n\nDe nouvelles données (données d’évaluation sur une phase expériementale) qui n’ont jamais été vues par la machine, sont vectorisées aussi.\nLe programme entraîné effectue ses prédictions sur ces données."
  },
  {
    "objectID": "sept11/intro.html#en-résumé",
    "href": "sept11/intro.html#en-résumé",
    "title": "Intro",
    "section": "En résumé",
    "text": "En résumé\nModèle de langue = modélisation de la langue dans son ensemble + capacité de prédiction.\nLes LLMs font de la prédiction de token :\n\nla génération de texte n’est pas la première ni la seule utilisation des LLMs.\nsoliciter un LLM pour générer un texte demande de recalculer le token le plus probable à chaque token -&gt; coût énergétique important."
  },
  {
    "objectID": "sept11/intro.html#études-critiques-de-lia",
    "href": "sept11/intro.html#études-critiques-de-lia",
    "title": "Intro",
    "section": "Études critiques de l’IA",
    "text": "Études critiques de l’IA\nDiscipline émergeante : Critical AI revue lancée en 2023.\nPistes de réflexions :\n\nUniformisation des pratiques et des modes de pensées : l’interface de chat est une façon de formaliser son problème, quid de la recherche de solution en interrogeant des moteurs de recherche, des bases de données ou des archives spécialisées ?\nDerrière l’apparente accessibilité de l’interface de chat, est-ce qu’on ne risque pas de creuser l’écart de la littératie numérique ?\nEst-ce que ces connaissances spécifiques, comme celles du code, qui impliquent des capacités de raisonnement alternatives, ne risquent pas de se retrouver suelement dans une forme d’élite intellectuelle ?\nComment peut-on définir une littéracie propre aux outils d’IA ?\nQuelle posture adopter ? Faut-il interdire l’usage dans la recherche ou l’enseignement, obliger une déclaration d’utilisation/citation ou encore laisser faire selon les usages et opter pour une approche pédagogique ?"
  },
  {
    "objectID": "sept11/intro.html#ce-quil-faut-retenir-1",
    "href": "sept11/intro.html#ce-quil-faut-retenir-1",
    "title": "Intro",
    "section": "Ce qu’il faut retenir",
    "text": "Ce qu’il faut retenir\n\nL’IA est amalgamé aux LLMs et en particulier aux interfaces de chatbots mais cela recouvre en réalité des processus algorithmiques variés.\nL’histoire de l’IA a montré qu’il y a des phases tant dans les approches valorisées que dans l’approbation de l’‘intelligence artificielle’ opposée à l’intelligence humaine.\nun système expert (symbolique) peut être aussi complexe et ‘intelligent’ qu’un LLM.\nLes systèmes d’IA n’ont pas de connaissance du réel et sont des modèles purement probabilistes.\nLes ‘halllucinations’ ne sont pas des anomalies, ce sont des erreurs que l’on qualifie a postériori comme telles.\nLes systèmes inductifs sont appropriés pour certaines tâches : classification, production de résumé. Leur point fort reste leur adaptabilité à de nouveaux contextes.\nLes chatbots sont des interfaces qui permettent un échange homme-machine en langue naturelle : l’exploitation des capacités inductives d’un LLMs ne nécessite pas de passer par une telle interface. Ex : classification, processus expérimental plus adapté à une utilisation sans cette interface."
  },
  {
    "objectID": "sept11/intro.html#ressources-vues-pendant-latelier",
    "href": "sept11/intro.html#ressources-vues-pendant-latelier",
    "title": "Intro",
    "section": "Ressources vues pendant l’atelier",
    "text": "Ressources vues pendant l’atelier\nDuck.ai\nOllama et documentation\nspaCy\nIncident Database AI\nCritical AI journal"
  },
  {
    "objectID": "ressources.html",
    "href": "ressources.html",
    "title": "Ressources des ateliers",
    "section": "",
    "text": "Programme de démo\n\n\n\nDuck.ai\nOllama et documentation\n\n\n\nspaCy\nnltk"
  },
  {
    "objectID": "ressources.html#démonstration-pour-les-ateliers",
    "href": "ressources.html#démonstration-pour-les-ateliers",
    "title": "Ressources des ateliers",
    "section": "",
    "text": "Programme de démo"
  },
  {
    "objectID": "ressources.html#chatbots",
    "href": "ressources.html#chatbots",
    "title": "Ressources des ateliers",
    "section": "",
    "text": "Duck.ai\nOllama et documentation"
  },
  {
    "objectID": "ressources.html#librairies-python-pour-le-traitement-automatique-des-langues",
    "href": "ressources.html#librairies-python-pour-le-traitement-automatique-des-langues",
    "title": "Ressources des ateliers",
    "section": "",
    "text": "spaCy\nnltk"
  },
  {
    "objectID": "oct09/25-10-09_correctionAtelierIA.html",
    "href": "oct09/25-10-09_correctionAtelierIA.html",
    "title": "2e séance atelier IA - révision",
    "section": "",
    "text": "Date : 9 octobre 2025\n\n\n(format de 2h) 1. Présentation de la série d’atelier 2. Qu’est-ce que l’IA ? 3. Rappel de la 1e séance : histoire, ce qu’il fallait retenir de la 1e séance 4. Place et importance de la correction 5. Outils généralistes 6. Outils spécialisés (été 2025) 7. Pistes pour l’évaluation des outils 8. Conclusions"
  },
  {
    "objectID": "oct09/25-10-09_correctionAtelierIA.html#plan",
    "href": "oct09/25-10-09_correctionAtelierIA.html#plan",
    "title": "2e séance atelier IA - révision",
    "section": "",
    "text": "(format de 2h) 1. Présentation de la série d’atelier 2. Qu’est-ce que l’IA ? 3. Rappel de la 1e séance : histoire, ce qu’il fallait retenir de la 1e séance 4. Place et importance de la correction 5. Outils généralistes 6. Outils spécialisés (été 2025) 7. Pistes pour l’évaluation des outils 8. Conclusions"
  }
]