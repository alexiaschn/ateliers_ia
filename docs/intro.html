<!DOCTYPE html>
<html lang="en"><head>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/tabby.min.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.42">

  <meta name="author" content="Alexia Schneider alexia.schneider@umontreal.ca (UdeM), Marcello Vitali-Rosati marcello.vitali.rosati@umontreal.ca (UdeM)">
  <meta name="dcterms.date" content="2025-09-11">
  <title>Intro</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="site_libs/revealjs/dist/theme/quarto-2f366650f320edcfcf53d73c80250a32.css">
  <link href="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Intro</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Alexia Schneider <code>alexia.schneider@umontreal.ca</code> (UdeM), Marcello Vitali-Rosati <code>marcello.vitali.rosati@umontreal.ca</code> (UdeM) 
</div>
</div>
</div>

  <p class="date">2025-09-11</p>
</section>
<section id="plan" class="slide level2 scrollable">
<h2>Plan</h2>
<ol type="1">
<li class="fragment">Présentation de la série d’atelier</li>
<li class="fragment">Qu’est-ce que l’IA ?</li>
<li class="fragment">Intérêt d’étudier l’IA pour les SHS</li>
<li class="fragment">Retours historiques</li>
<li class="fragment">Typologie des IA</li>
<li class="fragment">Cas d’usage et modélisation experte (ELIZA)</li>
<li class="fragment">Cas d’usage et modélisation distributionnelle/vectorielle (vectorisation et prédiction)</li>
<li class="fragment">Les LLMs</li>
<li class="fragment">Usages des LLMs hors chatbots (demo)</li>
<li class="fragment">LLMs et chatbots (Duck.ai + Ollama)</li>
<li class="fragment">Conclusions</li>
</ol>
</section>
<section id="présentation-et-objectif-des-ateliers" class="slide level2">
<h2>Présentation et objectif des ateliers</h2>
<p>Format : 4 séances de 2heures, sans inscription, participation libre (à justifier pour le certificat des Humanités Numériques)</p>
<p>Théorie et pratique en alternance au cours des deux heures.</p>
<p>Objectifs de la série d’atelier :</p>
<ul>
<li class="fragment">Comprendre les fondamentaux de l’IA et son histoire</li>
<li class="fragment">Obtenir des notions critiques sur le fonctionnement profond des outils</li>
<li class="fragment">Tester et s’approprier des outils d’IA</li>
<li class="fragment">Maîtriser le vocabulaire de la discipline</li>
</ul>
<p>Objectifs de cet atelier :</p>
<ul>
<li class="fragment">Comprendre les différentes formes d’IA</li>
<li class="fragment">Comprendre les enjeux liés à l’utilisation des LLM</li>
<li class="fragment">Utiliser de l’IA en dehors d’une interface de tchat.</li>
<li class="fragment">Tester les paramètres des chatbots</li>
<li class="fragment">Installer localement des modèles de langue.</li>
</ul>
</section>
<section id="quest-ce-que-lia" class="slide level2">
<h2>Qu’est ce que l’IA ?</h2>
<ul>
<li class="fragment"><p>Tout et rien : exemples : chatbot, détection sur des imageries médicales, HTR, DeepBlue.</p></li>
<li class="fragment"><p>le dernier mot à la mode. Le ‘numérique’ des années 2020. <span class="citation" data-cites="vitali-rosatiManifestePourEtudes2025">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Vitali-Rosati 2025</a>)</span>.</p></li>
</ul>
</section>
<section id="quest-ce-que-lia-1" class="slide level2">
<h2>Qu’est-ce que l’IA ?</h2>
<p>Définition pratique : “un programme informatique qui effectue une prédiction.”</p>
</section>
<section id="lia-et-les-shs" class="slide level2">
<h2>L’IA et les SHS</h2>
<p>À quoi sert d’étudier l’IA pour les chercheur.se.s en SHS ?</p>
</section>
<section id="lia-et-les-shs-1" class="slide level2">
<h2>L’IA et les SHS</h2>
<p><del>À quoi sert d’étudier l’IA pour les chercheur.se.s en SHS</del></p>
</section>
<section id="lia-et-les-shs-2" class="slide level2">
<h2>L’IA et les SHS</h2>
<p>Que peuvent faire les SHS pour l’IA ?</p>
<ul>
<li class="fragment">participer à la réflexion actuelle sur son utilisation :
<ul>
<li class="fragment">positionnements de revues et de conférences sur son utilisation (pose un cadre, parfois un précédent)</li>
</ul></li>
<li class="fragment">proposer une théorie critique de l’IA décentrées de l’effet ‘benchmarking’</li>
<li class="fragment">proposer une avis sur l’utilisation de ces outils qui soit propre à sa discipline.</li>
</ul>
</section>
<section id="exemples-de-prises-de-position" class="slide level2">
<h2>Exemples de prises de position</h2>
<blockquote>
<p>Both SUP and JHUP have increasingly embraced, tested, and deployed some AI tools and policies. Barbara has been clear in her support of responsible uses of AI and the necessity of leveraging these early days to stake a claim within the quickly evolving landscape. Like SUP, JHUP is building and testing its own tools for marketing, accessibility, and analytics, efforts which place our presses in a position to potentially build services that might in the future even benefit other university presses. <span class="citation" data-cites="mulliken2025AUPressesWeekinResidence2025">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Mulliken 2025</a>)</span></p>
</blockquote>
<blockquote>
<p>we offer recommendations for citing generative AI, defined as a tool that “can analyze or summarize content from a huge set of information, including web pages, books and other writing available on the internet, and use that data to create original new content” (Weed). <span class="citation" data-cites="HowCiteGenerative2023">(<a href="#/bibliographie" role="doc-biblioref" onclick=""><span>“How Do <span>I</span> Cite Generative <span>AI</span> in <span>MLA</span> Style?”</span> 2023</a>)</span></p>
</blockquote>
<blockquote>
<p>The uncomfortable truth for researchers and publishers who oppose AI slowly taking over human review is that they might not be able to prevent it. Should a researcher use AI to write the first pass of peer review and not disclose it — in contravention of publisher guidelines — that might not be detectable, says Hosseini, who is also one of the editors of the journal Accountability in Research. And if AI reviews become widespread, that could change the practice of science, says Priem. “Every researcher can run their own bespoke review service over the preprint/dataset landscape, flagging/extracting only the science they care about (at any “quality” level) they want that day,” he wrote on X earlier this year. That could start to eat into the roles of journals, by taking away the certification that peer review mediated by journals provides, he says. <span class="citation" data-cites="naddafAITransformingPeer2025">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Naddaf 2025</a>)</span></p>
</blockquote>
</section>
<section id="brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-1" class="slide level2">
<h2>Brève histoire de l’IA et des applications de linguistique computationnelle (pt.&nbsp;1)</h2>
<p>1940s : Science-fiction et roman d’Isaac Asimov <em>Runaround</em> en 1942.</p>
<p><span class="citation" data-cites="turingComputingMachineryIntelligence1950">Turing (<a href="#/bibliographie" role="doc-biblioref" onclick="">1950</a>)</span> : ‘can machines think?’</p>
<p>‘intelligence artificielle’ : 1956</p>
<blockquote>
<p>« The word Artificial Intelligence was then officially coined about six years later, when in 1956 Marvin Minsky and John McCarthy (a computer scientist at Stanford) hosted the approximately eight-week-long Dartmouth Summer Research Project on Artificial Intelligence (DSRPAI) at Dartmouth College in New Hampshire. » <span class="citation" data-cites="haenleinBriefHistoryArtificial2019">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Haenlein and Kaplan 2019, 7</a>)</span></p>
</blockquote>
<p>1966 : ELIZA <span class="citation" data-cites="weizenbaumELIZAComputerProgram1966">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Weizenbaum 1966</a>)</span></p>
<p>1990-2000s : pic des systèmes experts et des arbres de décision. DeepBlue d’IBM <span class="citation" data-cites="campbellDeepBlue2002">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Campbell, Hoane, and Hsu 2002</a>)</span>.</p>
</section>
<section id="brève-histoire-de-lia-et-des-applications-de-linguistique-computationnelle-pt.-2" class="slide level2">
<h2>Brève histoire de l’IA et des applications de linguistique computationnelle (pt.&nbsp;2)</h2>
<p>2010s : pic des systèmes d’IA avec une modélisation distributionnelle du language (vecteur). Word2Vec <span class="citation" data-cites="mikolovEfficientEstimationWord2013">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Mikolov et al. 2013</a>)</span>, GloVE <span class="citation" data-cites="penningtonGloVeGlobalVectors2014">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Pennington, Socher, and Manning 2014</a>)</span>. Parmi les avancées majeures de cette modélisation on compte le mécanisme d’attention <span class="citation" data-cites="vaswaniAttentionAllYou2017">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Vaswani et al. 2017</a>)</span> et l’encodage bidirectionnel BERT <span class="citation" data-cites="devlinBERTPretrainingDeep2019">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Devlin et al. 2019</a>)</span> qui permettent des modèles très performants comme le GPT-3 d’OpenAI <span class="citation" data-cites="brownLanguageModelsAre2020">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Brown et al. 2020</a>)</span>.</p>
<p>Actuellement : tendance à l’hybridation <span class="citation" data-cites="marcusNextDecadeAI2020">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Marcus 2020</a>)</span></p>
</section>
<section id="typologie-de-lia" class="slide level2">
<h2>Typologie de l’IA</h2>
<ul>
<li class="fragment"><p>Approche experte : modélisation d’un programme à partir de <strong>règles</strong> précises. Les règles doivent être applicables à de nouvelles données pour faire une prédiction.</p></li>
<li class="fragment"><p>Approche distributionnelle : modélisation d’un programme à partir d’un grand volume de données. Ce sont les <strong>motifs de répétitions</strong> qui permettent à la machine d’émettre une prédiction.</p></li>
</ul>
</section>
<section id="ce-quil-faut-retenir" class="slide level2">
<h2>Ce qu’il faut retenir</h2>
<ul>
<li class="fragment">deux modélisations : une approche <em>top-down</em> et une approche <em>sample-based</em>.</li>
<li class="fragment">‘des saisons’ en IA càd que certaines approches attirent l’attention à un moment donné, actuellement IA = chatbot voire ChatGPT.</li>
<li class="fragment">l’IA réfère à des algorithmes qui permettent d’automatiser une prise de décision et pas seulement à des programmes de génération textuelle.</li>
</ul>
</section>
<section id="partons-dun-exemple" class="slide level2">
<h2>Partons d’un exemple</h2>
<p>Objectif : obtenir un programme capable de classer une phrase selon une thématique prédéfinie.</p>
<p>Exemple : Classification d’un texte en “parle de fruit” vs.&nbsp;“ne parle pas de fruit”.</p>
</section>
<section id="modéliser-une-approche-experte" class="slide level2">
<h2>Modéliser une approche experte</h2>
<ul>
<li class="fragment">faire appel à un expert : un humain pour déterminer les règles qui définissent ce qui est une phrase parlant de fruits.</li>
<li class="fragment">exemple de règle possible : liste de mots comme ‘pomme, pommes, banane, poire etc.’ ordre des mots ou POS pour distinguer ‘orange’ couleur du fruit par exemple.</li>
</ul>
<p>Une approche qui sembler simpliste en apparence mais qui :</p>
<ul>
<li class="fragment">peut s’avérer très complexe (ex: traduction)</li>
<li class="fragment">est la base de systèmes très performants</li>
<li class="fragment">entre dans une logique de <em>lazy computing</em> <span class="citation" data-cites="fujinagaVirtuesLazyMachines2025">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Fujinaga 2025</a>)</span></li>
<li class="fragment">révèle les tâches de bas niveau pour passer d’une chaîne de caractères à un ensemble de caractéristiques : tokenisation, POS-tagging.</li>
</ul>
<p><a href="https://demo-atelier.streamlit.app/">Programme de démo</a></p>
</section>
<section id="exemple-dun-programme-conversationnel-génération-textuelle-avec-une-approche-experte-eliza" class="slide level2">
<h2>Exemple d’un programme conversationnel /génération textuelle avec une approche experte ELIZA</h2>
<p>Try it yourself : <a href="https://anthay.github.io/eliza.html">ELIZA</a></p>
<blockquote>
<p>Eliza is a pattern-matching automated psychiatrist. Given a set of rules in the form of input/output patterns, Eliza will attempt to recognize user input phrases and generate relevant psychobabble responses. Each rule is specified by an input pattern and a list of output patterns. A pattern is a sentence consisting of space-separated words and variables. <span class="citation" data-cites="connellyElizapy">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Connelly n.d.</a>)</span></p>
</blockquote>
<p>Exemple de <em>literate programming</em> <span class="citation" data-cites="knuthLiterateProgramming1984">(<a href="#/bibliographie" role="doc-biblioref" onclick="">Knuth 1984</a>)</span> :</p>
<p><a href="https://dhconnelly.com/paip-python/docs/paip/eliza.html">Lire le code d’ELIZA</a></p>
</section>
<section id="modélisation-vectorielle-et-machine-learning" class="slide level2">
<h2>Modélisation vectorielle et machine learning</h2>
<ul>
<li class="fragment">partir d’un ensemble important d’exemples</li>
<li class="fragment">travail d’annotation par un humain/expert: <em>ground truth</em> ou vérité de terrain.</li>
<li class="fragment">1 token = une caractéristique</li>
<li class="fragment">comptage des tokens dans l’ensemble du jeu de données et dans chaque phrase/document.</li>
<li class="fragment">représentation vectorielle = coordonnées dans un espace vectoriel à <em>n</em> dimensions.</li>
</ul>
<p>Visualisation de traitement basique (NER, POS et vectorisation)</p>
<!-- PROGRAMME TOKEN_CLASSIFICATION À DEPLOYER  -->
<ul>
<li class="fragment">même traitement est effectué sur de nouvelles données</li>
<li class="fragment">différentes logiques pour classer la nouvelle donnée :
<ul>
<li class="fragment">K-Nearest Neighbor</li>
<li class="fragment">Regression logistique</li>
</ul></li>
</ul>
<p>Points forts :</p>
<ul>
<li class="fragment">adaptable à des nouvelles données, notamment avec une tokenisation fragmentée</li>
</ul>
</section>
<section id="les-llms" class="slide level2">
<h2>Les LLMs</h2>
<p>Exemple de LLMs : GPT-4, Mixtral, Gemini, Llama, Qwen, DeepSeek etc.</p>
<p>Large Language Models : 1. modélisation vectorielle de chaque mot de la langue par rapport à sa fréquence d’apparition en contexte avec chacun des autres mots de la langue, 2. spécialisation sous forme de couche neuronale pour une tâche ou une fonction précise. 3. query et calcul pour chaque donnée en entrée du token le plus probable en sortie</p>
</section>
<section id="llms-et-non-chatbot" class="slide level2">
<h2>LLMs et non chatbot</h2>
<p>Classification (de token, de texte)</p>
<!-- démo NER -->
</section>
<section id="llms-et-chatbot" class="slide level2">
<h2>LLMs et chatbot</h2>
<p>Parce que les LLMs sont lourds (plusieurs Gigas) et parce qu’il est coûteux en énergie d’effectuer les calculs qui permettent de déterminer le prochain token (plusieurs GPU), l’usage le plus courant des LLMs est via un site qui va interroger le modèle sur un serveur distant. C’est la forme ChatGPT, Mistral.ai, etc.</p>
</section>
<section id="duck.ai" class="slide level2">
<h2>Duck.ai</h2>
<p>duck.ai permet de comparer des modèles en interfaces chat tout en conservant des données privées : https://duck.ai</p>
<!-- démonstration de duckai et des paramètres -->
</section>
<section id="ollama" class="slide level2">
<h2>Ollama</h2>
<p>Il est pourtant possible de faire tourner un SLM (small language model) localement. Pour ce faire : <code>ollama</code> est une bibliothèque qui permet de télécharger et d’utiliser localement un LLMs.</p>
<h3 id="téléchargement">téléchargement</h3>
<p>https://ollama.com/download</p>
<p>command line</p>
<p>ollama run llama3.2</p>
<p>““” -&gt; pour des instructions longues</p>
<p>ollama list -&gt; liste des modèles téléchargés et utilisables</p>
<p>ollama rm llama3.2 -&gt; supprime un modèle</p>
</section>
<section id="paramètres-dun-modèle" class="slide level2">
<h2>Paramètres d’un modèle</h2>
<p>Plusieurs paramètres importants et contrôlable :</p>
<ul>
<li class="fragment">le seed :les LLMs ont une variable aléatoire dans leur paramètre : le seed permet d’utiliser toujours le même ordre aléatoire, càd d’obtenir pour un même prompt toujours la même réponse et ainsi de rendre reproductible une réponse.</li>
<li class="fragment">la température: détermine le degré d’utilisation de la variable aléatoire (mas o menos)</li>
<li class="fragment">top_k : Reduces the probability of generating nonsense. A higher value (e.g.&nbsp;100) will give more diverse answers, while a lower value (e.g.&nbsp;10) will be more conservative. (Default: 40)</li>
<li class="fragment">top_p: Works together with top-k. A higher value (e.g., 0.95) will lead to more diverse text, while a lower value (e.g., 0.5) will generate more focused and conservative text. (Default: 0.9)</li>
</ul>
</section>
<section id="model-steering" class="slide level2">
<h2>model Steering</h2>
<p>https://github.com/ollama/ollama/blob/main/docs/modelfile.md</p>
<p>Créer un nouveau document ‘Modelfile’ sans extension <code>touch Modelfile</code></p>
<pre><code>FROM llama3.2
PARAMETER temperature 1
top_k 100
top_p 1
seed 17
SYSTEM "Tu es un chien"</code></pre>
<p>ollama create chien -f Modelfile</p>
<p>ollama run chien</p>
</section>
<section id="limites-des-interfaces-de-chat" class="slide level2">
<h2>Limites des interfaces de chat</h2>
<ul>
<li class="fragment">les chatbots ont des limites : on peut ‘hacker un LLM’ avec du <em>prompt injection</em> ou autres techniques de <em>Jailbreaking</em>.</li>
</ul>
<p><a href="https://incidentdatabase.ai/">Incitent database</a></p>
<blockquote>
<p>Hidden prompts reportedly were discovered in at least 17 academic preprints on arXiv that purportedly instructed AI tools to deliver only positive peer reviews. The lead authors are reportedly affiliated with 14 institutions in eight countries, including Waseda University, KAIST, Peking University, and the University of Washington. The alleged concealed instructions, some of which were reportedly embedded using white text or tiny fonts, were purportedly intended to influence any reviewers who rely on AI tools. (https://incidentdatabase.ai/cite/1135)</p>
</blockquote>
<ul>
<li class="fragment"><p>il n’y a pas d’hallucinations, toutes les générations produites par un LLMs ont la même teneur de vérité du pdv de l’outil : le modèle ne peut pas évaluer sa réponse à l’aune d’une <em>ground truth</em> comme dans sa phase d’entraînement.</p></li>
<li class="fragment"><p>Problèmes et réflexions pour les SHS :</p>
<ul>
<li class="fragment"><p>uniformisation des pratiques, des modes de pensées : l’interface de chat est une façon de formaliser son problème, quid de la recherhce de solution en interrogeant des moteurs de recherche, des bdd ou archives spécialisées ?</p></li>
<li class="fragment"><p>Derrière l’apparente accessibilité de l’interface de chat, est-ce qu’on ne risque pas de creuser l’écart de la littératie numérique ?</p></li>
<li class="fragment"><p>Est-ce que ces connaissances spécifiques, comme celles du code, qui impliquent des capacités de raisonnement alternatives, ne risquent pas de se retrouver suelement dans une forme d’élite intellectuelle ?</p></li>
</ul></li>
</ul>
</section>
<section id="ce-quil-faut-retenir-de-la-séance" class="title-slide slide level1 center">
<h1>Ce qu’il faut retenir de la séance</h1>
<ul>
<li class="fragment">l’IA est un terme ajd employé à tort poru parler des LLMs mais qui recouvre en réalité des processus algorithmiques variés et pas seulement des chatbots type ChatGPT.</li>
<li class="fragment">l’histoire de l’IA a montré qu’il y a des phases</li>
<li class="fragment">les autres systèmes ne sont pas plus ni moins ‘intelligent’.</li>
<li class="fragment">un système expert peut être aussi complexe et énergivore que du machine learning (mais dans les faits plus rarement).</li>
<li class="fragment">les systèmes d’IA n’ont pas de connaissance du réel (et celleux qui disent le contraire essaient de vendre des choses à l’heure actuelle)</li>
<li class="fragment">par csq les halllucinations ne sont pas des anomalies, ce sont des erreurs que l’on qualifie a postériori comme telle.</li>
<li class="fragment">les systèmes inductifs sont appropriés pour des certaines tâches : classification, production de résumé. Leur point fort reste l’adaptation à des contextes de textes ou d’images variés.</li>
<li class="fragment">les chatbots sont des interfaces qui permettent un échange homme-machine en langue naturelle : l’exploitation des capacités inductives d’un LLMs ne nécessite pas de passer par une telle interface. Ex : classification, processus expérimental plus adapté à une utilisation sans cette interface.</li>
</ul>
</section>

<section>
<section id="ressources-vues-pendant-latelier" class="title-slide slide level1 center">
<h1>Ressources vues pendant l’atelier</h1>
<p>https://spacy.io/usage</p>
<p>https://incidentdatabase.ai/</p>
<p>https://duck.ai</p>
<p>Ollama Installation : https://ollama.com/download Documentation : https://github.com/ollama/ollama/blob/main/docs/modelfile.md</p>
</section>
<section id="bibliographie" class="slide level2 smaller scrollable">
<h2>Bibliographie</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-brownLanguageModelsAre2020" class="csl-entry" role="listitem">
Brown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. <span>“Language <span>Models</span> Are <span>Few-Shot Learners</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2005.14165">https://doi.org/10.48550/arXiv.2005.14165</a>.
</div>
<div id="ref-campbellDeepBlue2002" class="csl-entry" role="listitem">
Campbell, Murray, A. Joseph Hoane, and Feng-hsiung Hsu. 2002. <span>“Deep <span>Blue</span>.”</span> <em>Artificial Intelligence</em> 134 (1): 57–83. <a href="https://doi.org/10.1016/S0004-3702(01)00129-1">https://doi.org/10.1016/S0004-3702(01)00129-1</a>.
</div>
<div id="ref-connellyElizapy" class="csl-entry" role="listitem">
Connelly, Daniel. n.d. <span>“Eliza.py.”</span> <em>Eliza Emulation Python</em>. https://dhconnelly.com/paip-python/docs/paip/eliza.html. Accessed August 20, 2025.
</div>
<div id="ref-devlinBERTPretrainingDeep2019" class="csl-entry" role="listitem">
Devlin, Jacob, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. <span>“<span>BERT</span>: <span class="nocase">Pre-training</span> of <span>Deep Bidirectional Transformers</span> for <span>Language Understanding</span>.”</span> In <em>Proceedings of the 2019 <span>Conference</span> of the <span>North American Chapter</span> of the <span>Association</span> for <span>Computational Linguistics</span>: <span>Human Language Technologies</span>, <span>Volume</span> 1 (<span>Long</span> and <span>Short Papers</span>)</em>, edited by Jill Burstein, Christy Doran, and Thamar Solorio, 4171–86. Minneapolis, Minnesota: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/N19-1423">https://doi.org/10.18653/v1/N19-1423</a>.
</div>
<div id="ref-fujinagaVirtuesLazyMachines2025" class="csl-entry" role="listitem">
Fujinaga, Ichiro. 2025. <span>“<span>On the virtues of lazy machines</span>.”</span> {Keynote}. Montr<span>é</span>al.
</div>
<div id="ref-haenleinBriefHistoryArtificial2019" class="csl-entry" role="listitem">
Haenlein, Michael, and Andreas Kaplan. 2019. <span>“A <span>Brief History</span> of <span>Artificial Intelligence</span>: <span>On</span> the <span>Past</span>, <span>Present</span>, and <span>Future</span> of <span>Artificial Intelligence</span>.”</span> <em>California Management Review</em> 61 (4): 5–14. <a href="https://doi.org/10.1177/0008125619864925">https://doi.org/10.1177/0008125619864925</a>.
</div>
<div id="ref-HowCiteGenerative2023" class="csl-entry" role="listitem">
<span>“How Do <span>I</span> Cite Generative <span>AI</span> in <span>MLA</span> Style?”</span> 2023. <em>MLA Style Center</em>.
</div>
<div id="ref-knuthLiterateProgramming1984" class="csl-entry" role="listitem">
Knuth, D. E. 1984. <span>“Literate <span>Programming</span>.”</span> <em>The Computer Journal</em> 27 (2): 97–111. <a href="https://doi.org/10.1093/comjnl/27.2.97">https://doi.org/10.1093/comjnl/27.2.97</a>.
</div>
<div id="ref-marcusNextDecadeAI2020" class="csl-entry" role="listitem">
Marcus, Gary. 2020. <span>“The <span>Next Decade</span> in <span>AI</span>: <span>Four Steps Towards Robust Artificial Intelligence</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2002.06177">https://doi.org/10.48550/arXiv.2002.06177</a>.
</div>
<div id="ref-mikolovEfficientEstimationWord2013" class="csl-entry" role="listitem">
Mikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. <span>“Efficient <span>Estimation</span> of <span>Word Representations</span> in <span>Vector Space</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1301.3781">https://doi.org/10.48550/arXiv.1301.3781</a>.
</div>
<div id="ref-mulliken2025AUPressesWeekinResidence2025" class="csl-entry" role="listitem">
Mulliken, Jasmine. 2025. <span>“2025 <span class="nocase">AUPresses Week-in-Residence Report</span>.”</span>
</div>
<div id="ref-naddafAITransformingPeer2025" class="csl-entry" role="listitem">
Naddaf, Miryam. 2025. <span>“<span>AI</span> Is Transforming Peer Review — and Many Scientists Are Worried.”</span> <em>Nature</em> 639 (8056): 852–54. <a href="https://doi.org/10.1038/d41586-025-00894-7">https://doi.org/10.1038/d41586-025-00894-7</a>.
</div>
<div id="ref-penningtonGloVeGlobalVectors2014" class="csl-entry" role="listitem">
Pennington, Jeffrey, Richard Socher, and Christopher Manning. 2014. <span>“<span>GloVe</span>: <span>Global Vectors</span> for <span>Word Representation</span>.”</span> In <em>Proceedings of the 2014 <span>Conference</span> on <span>Empirical Methods</span> in <span>Natural Language Processing</span> (<span>EMNLP</span>)</em>, edited by Alessandro Moschitti, Bo Pang, and Walter Daelemans, 1532–43. Doha, Qatar: Association for Computational Linguistics. <a href="https://doi.org/10.3115/v1/D14-1162">https://doi.org/10.3115/v1/D14-1162</a>.
</div>
<div id="ref-turingComputingMachineryIntelligence1950" class="csl-entry" role="listitem">
Turing, A. M. 1950. <span>“Computing <span>Machinery</span> and <span>Intelligence</span>.”</span> <em>Mind</em> LIX (236): 433–60. <a href="https://doi.org/10.1093/mind/LIX.236.433">https://doi.org/10.1093/mind/LIX.236.433</a>.
</div>
<div id="ref-vaswaniAttentionAllYou2017" class="csl-entry" role="listitem">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. <span>“Attention <span>Is All You Need</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1706.03762">https://doi.org/10.48550/arXiv.1706.03762</a>.
</div>
<div id="ref-vitali-rosatiManifestePourEtudes2025" class="csl-entry" role="listitem">
Vitali-Rosati, Marcello. 2025. <span>“Manifeste Pour Des <span class="nocase"><span>É</span>tudes Critiques</span> de l’<span>Intelligence Artificielle</span>.”</span> <em>Culture Num<span>é</span>rique. Pour Une Philosophie Du Num<span>é</span>rique</em>.
</div>
<div id="ref-weizenbaumELIZAComputerProgram1966" class="csl-entry" role="listitem">
Weizenbaum, Joseph. 1966. <span>“<span>ELIZA</span>—a Computer Program for the Study of Natural Language Communication Between Man and Machine.”</span> <em>Communications of the ACM</em> 9 (1): 36–45. <a href="https://doi.org/10.1145/365153.365168">https://doi.org/10.1145/365153.365168</a>.
</div>
</div>
</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="site_libs/revealjs/plugin/search/search.js"></script>
  <script src="site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>