@article{bordalejoScarletCloakForest2025,
  title = {``{{Scarlet Cloak}} and the {{Forest Adventure}}'': A Preliminary Study of the Impact of {{AI}} on Commonly Used Writing Tools},
  shorttitle = {``{{Scarlet Cloak}} and the {{Forest Adventure}}''},
  author = {Bordalejo, Barbara and Pafumi, Davide and Onuh, Frank and Khalid, A. K. M. Iftekhar and Pearce, Morgan Slayde and O'Donnell, Daniel Paul},
  year = {2025},
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {22},
  number = {1},
  doi = {10.1186/s41239-025-00505-5},
  urldate = {2025-02-09},
  abstract = {This paper explores the growing complexity of detecting and differentiating generative AI from other AI interventions. Initially prompted by noticing how tools like Grammarly were being flagged by AI detection software, it examines how these popular tools such as Grammarly, EditPad, Writefull, and AI models such as ChatGPT and Microsoft Bing Copilot affect human-generated texts and how accurately current AI-detection systems, including Turnitin and GPTZero, can assess texts for use of these tools. The results highlight that widely used writing aids, even those not primarily generative, can trigger false positives in AI detection tools. In order to provide a dataset, the authors applied different AI-enhanced tools to a number of texts of different styles that were written prior to the development of consumer AI tools, and evaluated their impact through key metrics such as readability, perplexity, and burstiness. The findings reveal that tools like Grammarly that subtly enhance readability also trigger detection and increase false positives, especially for non-native speakers. In general, paraphrasing tools score low values in AI detection software, allowing the changes to go mostly unnoticed by the software. However, the use of Microsoft Bing Copilot and Writefull on our selected texts were able to eschew AI detection fairly consistently. To exacerbate this problem, traditional AI detectors like Turnitin and GPTZero struggle to reliably differentiate between legitimate paraphrasing and AI generation, undermining their utility for enforcing academic integrity. The study concludes by urging educators to focus on managing interactions with AI in academic settings rather than outright banning its use. It calls for the creation of policies and guidelines that acknowledge the evolving role of AI in writing, emphasizing the need to interpret detection scores cautiously to avoid penalizing students unfairly. In addition, encouraging openness on how AI is used in writing could alleviate concerns in the research and writing process for both students and academics. The paper recommends a shift toward teaching responsible AI usage rather than pursuing rigid bans or relying on detection metrics that may not accurately capture misconduct.},
  langid = {english},
  file = {/home/schn/snap/zotero-snap/common/Zotero/storage/MWKLR676/Bordalejo et al. - 2025 - “Scarlet Cloak and the Forest Adventure” a preliminary study of the impact of AI on commonly used w.pdf}
}

@article{bryantGrammaticalErrorCorrection2023,
  title = {Grammatical {{Error Correction}}: {{A Survey}} of the {{State}} of the {{Art}}},
  shorttitle = {Grammatical {{Error Correction}}},
  author = {Bryant, Christopher and Yuan, Zheng and Qorib, Muhammad Reza and Cao, Hannan and Ng, Hwee Tou and Briscoe, Ted},
  year = {2023},
  month = sep,
  journal = {Computational Linguistics},
  pages = {643--701},
  publisher = {MIT Press},
  address = {Cambridge, MA},
  doi = {10.1162/coli_a_00478},
  urldate = {2025-09-22},
  abstract = {Grammatical Error Correction (GEC) is the task of automatically detecting and correcting errors in text. The task not only includes the correction of grammatical errors, such as missing prepositions and mismatched subject--verb agreement, but also orthographic and semantic errors, such as misspellings and word choice errors, respectively. The field has seen significant progress in the last decade, motivated in part by a series of five shared tasks, which drove the development of rule-based methods, statistical classifiers, statistical machine translation, and finally neural machine translation systems, which represent the current dominant state of the art. In this survey paper, we condense the field into a single article and first outline some of the linguistic challenges of the task, introduce the most popular datasets that are available to researchers (for both English and other languages), and summarize the various methods and techniques that have been developed with a particular focus on artificial error generation. We next describe the many different approaches to evaluation as well as concerns surrounding metric reliability, especially in relation to subjective human judgments, before concluding with an overview of recent progress and suggestions for future work and remaining challenges. We hope that this survey will serve as a comprehensive resource for researchers who are new to the field or who want to be kept apprised of recent developments.},
  file = {/home/schn/snap/zotero-snap/common/Zotero/storage/D3JFB27Q/Bryant et al. - 2023 - Grammatical Error Correction A Survey of the State of the Art.pdf}
}

@misc{ciesielskiNeuralMachineTranslation2024,
  title = {Neural {{Machine Translation Versus Large Language Models}}},
  author = {Ciesielski, Jourik},
  year = {2024},
  month = jun,
  urldate = {2025-09-22},
  abstract = {In this article, leaders from six of the world's most influential language companies share their perspectives on the best approach to automated translation.},
  howpublished = {https://multilingual.com/magazine/june-2024/neural-machine-translation-versus-large-language-models/},
  langid = {american},
  file = {/home/schn/snap/zotero-snap/common/Zotero/storage/92GDH3WQ/neural-machine-translation-versus-large-language-models.html;/home/schn/snap/zotero-snap/common/Zotero/storage/VNJMA5E7/neural-machine-translation-versus-large-language-models.html}
}

@misc{guoCuriousDeclineLinguistic2024,
  title = {The {{Curious Decline}} of {{Linguistic Diversity}}: {{Training Language Models}} on {{Synthetic Text}}},
  shorttitle = {The {{Curious Decline}} of {{Linguistic Diversity}}},
  author = {Guo, Yanzhu and Shang, Guokan and Vazirgiannis, Michalis and Clavel, Chlo{\'e}},
  year = {2024},
  month = apr,
  number = {arXiv:2311.09807},
  eprint = {2311.09807},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.09807},
  urldate = {2025-03-18},
  abstract = {This study investigates the consequences of training language models on synthetic data generated by their predecessors, an increasingly prevalent practice given the prominence of powerful generative models. Diverging from the usual emphasis on performance metrics, we focus on the impact of this training methodology on linguistic diversity, especially when conducted recursively over time. To assess this, we adapt and develop a set of novel metrics targeting lexical, syntactic, and semantic diversity, applying them in recursive finetuning experiments across various natural language generation tasks in English. Our findings reveal a consistent decrease in the diversity of the model outputs through successive iterations, especially remarkable for tasks demanding high levels of creativity. This trend underscores the potential risks of training language models on synthetic text, particularly concerning the preservation of linguistic richness. Our study highlights the need for careful consideration of the long-term effects of such training approaches on the linguistic capabilities of language models.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/home/schn/snap/zotero-snap/common/Zotero/storage/MT6A2X95/Guo et al. - 2024 - The Curious Decline of Linguistic Diversity Training Language Models on Synthetic Text.pdf}
}

@article{homolakExploringAdoptionChatGPT2023,
  title = {Exploring the Adoption of {{ChatGPT}} in Academic Publishing: Insights and Lessons for Scientific Writing},
  shorttitle = {Exploring the Adoption of {{ChatGPT}} in Academic Publishing},
  author = {Homolak, Jan},
  year = {2023},
  month = jun,
  journal = {Croatian Medical Journal},
  volume = {64},
  number = {3},
  pages = {205--207},
  issn = {1332-8166},
  doi = {10.3325/cmj.2023.64.205},
  langid = {english},
  pmcid = {PMC10332292},
  pmid = {37391919}
}

@misc{kobayashiLargeLanguageModels2024,
  title = {Large {{Language Models Are State-of-the-Art Evaluator}} for {{Grammatical Error Correction}}},
  author = {Kobayashi, Masamune and Mita, Masato and Komachi, Mamoru},
  year = {2024},
  month = may,
  number = {arXiv:2403.17540},
  eprint = {2403.17540},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.17540},
  urldate = {2025-09-22},
  abstract = {Large Language Models (LLMs) have been reported to outperform existing automatic evaluation metrics in some tasks, such as text summarization and machine translation. However, there has been a lack of research on LLMs as evaluators in grammatical error correction (GEC). In this study, we investigate the performance of LLMs in GEC evaluation by employing prompts designed to incorporate various evaluation criteria inspired by previous research. Our extensive experimental results demonstrate that GPT-4 achieved Kendall's rank correlation of 0.662 with human judgments, surpassing all existing methods. Furthermore, in recent GEC evaluations, we have underscored the significance of the LLMs scale and particularly emphasized the importance of fluency among evaluation criteria.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {/home/schn/snap/zotero-snap/common/Zotero/storage/YU4UAN7K/Kobayashi et al. - 2024 - Large Language Models Are State-of-the-Art Evaluator for Grammatical Error Correction.pdf;/home/schn/snap/zotero-snap/common/Zotero/storage/I6M6Z9SG/2403.html;/home/schn/snap/zotero-snap/common/Zotero/storage/P5DGYT56/2403.html}
}

@misc{maityHowReadyAre2024,
  title = {How {{Ready Are Generative Pre-trained Large Language Models}} for {{Explaining Bengali Grammatical Errors}}?},
  author = {Maity, Subhankar and Deroy, Aniket and Sarkar, Sudeshna},
  year = {2024},
  month = may,
  number = {arXiv:2406.00039},
  eprint = {2406.00039},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.00039},
  urldate = {2025-09-22},
  abstract = {Grammatical error correction (GEC) tools, powered by advanced generative artificial intelligence (AI), competently correct linguistic inaccuracies in user input. However, they often fall short in providing essential natural language explanations, which are crucial for learning languages and gaining a deeper understanding of the grammatical rules. There is limited exploration of these tools in low-resource languages such as Bengali. In such languages, grammatical error explanation (GEE) systems should not only correct sentences but also provide explanations for errors. This comprehensive approach can help language learners in their quest for proficiency. Our work introduces a real-world, multi-domain dataset sourced from Bengali speakers of varying proficiency levels and linguistic complexities. This dataset serves as an evaluation benchmark for GEE systems, allowing them to use context information to generate meaningful explanations and high-quality corrections. Various generative pre-trained large language models (LLMs), including GPT-4 Turbo, GPT-3.5 Turbo, Text-davinci-003, Text-babbage-001, Text-curie-001, Text-ada-001, Llama-2-7b, Llama-2-13b, and Llama-2-70b, are assessed against human experts for performance comparison. Our research underscores the limitations in the automatic deployment of current state-of-the-art generative pre-trained LLMs for Bengali GEE. Advocating for human intervention, our findings propose incorporating manual checks to address grammatical errors and improve feedback quality. This approach presents a more suitable strategy to refine the GEC tools in Bengali, emphasizing the educational aspect of language learning.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {/home/schn/snap/zotero-snap/common/Zotero/storage/MUTWZNC7/Maity et al. - 2024 - How Ready Are Generative Pre-trained Large Language Models for Explaining Bengali Grammatical Errors.pdf;/home/schn/snap/zotero-snap/common/Zotero/storage/9KB9NHNI/2406.html;/home/schn/snap/zotero-snap/common/Zotero/storage/L3XECAGW/2406.html}
}

@book{mccartyHumanitiesComputing2005,
  title = {Humanities {{Computing}}},
  author = {McCarty, Willard},
  year = {2005},
  edition = {Paperback edition},
  publisher = {Palgrave Macmillan},
  address = {Basingstoke, Hampshire},
  isbn = {978-1-4039-3504-5 978-1-137-44042-6},
  lccn = {AZ105 .M245 2014},
  keywords = {commente,Digital humanities,Humanities,Information storage and retrieval systems,lu,Research Data processing},
  file = {/home/schn/snap/zotero-snap/common/Zotero/storage/YYXNRKV9/McCarty - 2014 - Humanities Computing.pdf}
}

@misc{monjourBarriereDernierKilometre2025,
  title = {{La barri{\`e}re du dernier kilom{\`e}tre}},
  author = {Monjour, Servanne and Sauret, Nicolas},
  year = {2025},
  month = may,
  address = {Toronto},
  langid = {french}
}

@inproceedings{napolesTheresNoComparison2016,
  title = {There's {{No Comparison}}: {{Reference-less Evaluation Metrics}} in {{Grammatical Error Correction}}},
  shorttitle = {There's {{No Comparison}}},
  booktitle = {Proceedings of the 2016 {{Conference}} on {{Empirical Methods}} in {{Natural}}           {{Language Processing}}},
  author = {Napoles, Courtney and Sakaguchi, Keisuke and Tetreault, Joel},
  year = {2016},
  pages = {2109--2115},
  publisher = {Association for Computational Linguistics},
  address = {Austin, Texas},
  doi = {10.18653/v1/D16-1228},
  urldate = {2025-09-30},
  abstract = {Current methods for automatically evaluating grammatical error correction (GEC) systems rely on gold-standard references. However, these methods suffer from penalizing grammatical edits that are correct but not in the gold standard. We show that reference-less grammaticality metrics correlate very strongly with human judgments and are competitive with the leading reference-based evaluation metrics. By interpolating both methods, we achieve state-of-the-art correlation with human judgments. Finally, we show that GEC metrics are much more reliable when they are calculated at the sentence level instead of the corpus level. We have set up a CodaLab site for benchmarking GEC output using a common dataset and different evaluation metrics.},
  langid = {english},
  file = {/home/schn/snap/zotero-snap/common/Zotero/storage/B9C6T938/Napoles et al. - 2016 - There's No Comparison Reference-less Evaluation Metrics in Grammatical Error Correction.pdf}
}

@book{russellArtificialIntelligenceModern2022,
  title = {Artificial Intelligence: A Modern Approach},
  shorttitle = {Artificial Intelligence},
  author = {Russell, Stuart J. and Norvig, Peter},
  year = {2022},
  series = {Prentice {{Hall}} Series in Artificial Intelligence},
  edition = {Fourth edition, global edition},
  publisher = {Pearson},
  address = {Boston},
  abstract = {The most comprehensive, up-to-date introduction to the theory and practice of artificial intelligence The long-anticipated revision of Artificial Intelligence: A Modern Approach explores the full breadth and depth of the field of artificial intelligence (AI). The 4th Edition brings readers up to date on the latest technologies, present concepts in a more unified manner, and offers new or expanded coverage of machine learning, deep learning, transfer learning, multi agent systems, robotics, natural language processing, causality, probabilistic programming, privacy, fairness, and safe AI},
  collaborator = {Chang, Ming-wei and Devlin, Jacob and Dragan, Anca and Forsyth, David and Goodfellow, Ian and Malik, Jitendra and Mansinghka, Vikash and Pearl, Judea and Wooldridge, Michael J.},
  isbn = {978-1-292-40113-3 978-1-292-40117-1},
  langid = {english},
  file = {/home/schn/snap/zotero-snap/common/Zotero/storage/CJY9RW9U/Russell et Norvig - 2022 - Artificial intelligence a modern approach.pdf}
}

@phdthesis{schumacherPosteditionTraductionAutomatique2023,
  title = {{La post-{\'e}dition de traduction automatique en contexte d'apprentissage}},
  author = {Schumacher, Perrine},
  year = {2023},
  month = aug,
  address = {Li{\`e}ge},
  langid = {french},
  school = {Universite de Liege}
}

@misc{shankarWhoValidatesValidators2024a,
  title = {Who {{Validates}} the {{Validators}}? {{Aligning LLM-Assisted Evaluation}} of {{LLM Outputs}} with {{Human Preferences}}},
  shorttitle = {Who {{Validates}} the {{Validators}}?},
  author = {Shankar, Shreya and {Zamfirescu-Pereira}, J. D. and Hartmann, Bj{\"o}rn and Parameswaran, Aditya G. and Arawjo, Ian},
  year = {2024},
  month = apr,
  number = {arXiv:2404.12272},
  eprint = {2404.12272},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2404.12272},
  urldate = {2025-09-04},
  abstract = {Due to the cumbersome nature of human evaluation and limitations of code-based evaluation, Large Language Models (LLMs) are increasingly being used to assist humans in evaluating LLM outputs. Yet LLM-generated evaluators simply inherit all the problems of the LLMs they evaluate, requiring further human validation. We present a mixed-initiative approach to ``validate the validators''---aligning LLM-generated evaluation functions (be it prompts or code) with human requirements. Our interface, EvalGen, provides automated assistance to users in generating evaluation criteria and implementing assertions. While generating candidate implementations (Python functions, LLM grader prompts), EvalGen asks humans to grade a subset of LLM outputs; this feedback is used to select implementations that better align with user grades. A qualitative study finds overall support for EvalGen but underscores the subjectivity and iterative process of alignment. In particular, we identify a phenomenon we dub criteria drift: users need criteria to grade outputs, but grading outputs helps users define criteria. What is more, some criteria appears dependent on the specific LLM outputs observed (rather than independent criteria that can be defined a priori), raising serious questions for approaches that assume the independence of evaluation from observation of model outputs. We present our interface and implementation details, a comparison of our algorithm with a baseline approach, and implications for the design of future LLM evaluation assistants.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Artificial Intelligence (cs.AI),Computer Science - Artificial Intelligence,Computer Science - Human-Computer Interaction,FOS: Computer and information sciences,Human-Computer Interaction (cs.HC)},
  file = {/home/schn/snap/zotero-snap/common/Zotero/storage/3YDITZMC/Shankar et al. - 2024 - Who Validates the Validators Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences.pdf}
}

@article{shumailovAIModelsCollapse2024,
  title = {{{AI}} Models Collapse When Trained on Recursively Generated Data},
  author = {Shumailov, Ilia and Shumaylov, Zakhar and Zhao, Yiren and Papernot, Nicolas and Anderson, Ross and Gal, Yarin},
  year = {2024},
  month = jul,
  journal = {Nature},
  volume = {631},
  number = {8022},
  pages = {755--759},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-024-07566-y},
  urldate = {2025-03-26},
  abstract = {Abstract                            Stable diffusion revolutionized image creation from descriptive text. GPT-2 (ref.\,               1               ), GPT-3(.5) (ref.\,               2               ) and GPT-4 (ref.\,               3               ) demonstrated high performance across a variety of language tasks. ChatGPT introduced such language models to the public. It is now clear that generative artificial intelligence (AI) such as large language models (LLMs) is here to stay and will substantially change the ecosystem of online text and images. Here we consider what may happen to GPT-\{               n               \} once LLMs contribute much of the text found online. We find that indiscriminate use of model-generated content in training causes irreversible defects in the resulting models, in which tails of the original content distribution disappear. We refer to this effect as `model collapse' and show that it can occur in LLMs as well as in variational autoencoders (VAEs) and Gaussian mixture models (GMMs). We build theoretical intuition behind the phenomenon and portray its ubiquity among all learned generative models. We demonstrate that it must be taken seriously if we are to sustain the benefits of training from large-scale data scraped from the web. Indeed, the value of data collected about genuine human interactions with systems will be increasingly valuable in the presence of LLM-generated content in data crawled from the Internet.},
  langid = {english},
  file = {/home/schn/snap/zotero-snap/common/Zotero/storage/94L95E7C/Shumailov et al. - 2024 - AI models collapse when trained on recursively generated data.pdf}
}

@inproceedings{sizovAnalysingTranslationArtifacts2024,
  title = {Analysing {{Translation Artifacts}}: {{A Comparative Study}} of {{LLMs}}, {{NMTs}}, and {{Human Translations}}},
  shorttitle = {Analysing {{Translation Artifacts}}},
  booktitle = {Proceedings of the {{Ninth Conference}} on {{Machine Translation}}},
  author = {Sizov, Fedor and {Espa{\~n}a-Bonet}, Cristina and Van Genabith, Josef and Xie, Roy and Dutta Chowdhury, Koel},
  year = {2024},
  pages = {1183--1199},
  publisher = {Association for Computational Linguistics},
  address = {Miami, Florida, USA},
  doi = {10.18653/v1/2024.wmt-1.116},
  urldate = {2025-09-22},
  langid = {english},
  file = {/home/schn/snap/zotero-snap/common/Zotero/storage/5K7UFK88/Sizov et al. - 2024 - Analysing Translation Artifacts A Comparative Study of LLMs, NMTs, and Human Translations.pdf}
}

@article{strzeleckiMyLastKnowledge2025,
  title = {`{{As}} of My Last Knowledge Update': {{How}} Is Content Generated by {{{\textsc{ChatGPT}}}} Infiltrating Scientific Papers Published in Premier Journals?},
  shorttitle = {`{{As}} of My Last Knowledge Update'},
  author = {Strzelecki, Artur},
  year = {2025},
  month = jan,
  journal = {Learned Publishing},
  volume = {38},
  number = {1},
  pages = {e1650},
  issn = {0953-1513, 1741-4857},
  doi = {10.1002/leap.1650},
  urldate = {2025-09-21},
  abstract = {Abstract             The aim of this paper is to highlight the situation whereby content generated by the large language model ChatGPT is appearing in peer-reviewed papers in journals by recognized publishers. The paper demonstrates how to identify sections that indicate that a text fragment was generated, that is, entirely created, by ChatGPT. To prepare an illustrative compilation of papers that appear in journals indexed in the Web of Science and Scopus databases and possessing Impact Factor and CiteScore indicators, the SPAR4SLR method was used, which is mainly applied in systematic literature reviews. Three main findings are presented: in highly regarded premier journals, articles appear that bear the hallmarks of the content generated by AI large language models, whose use was not declared by the authors (1); many of these identified papers are already receiving citations from other scientific works, also placed in journals found in scientific databases (2); and, most of the identified papers belong to the disciplines of medicine and computer science, but there are also articles that belong to disciplines such as environmental science, engineering, sociology, education, economics and management (3). This paper aims to continue and add to the recently initiated discussion on the use of large language models like ChatGPT in the creation of scholarly works.},
  langid = {english}
}

@article{turingComputingMachineryIntelligence1950,
  title = {Computing {{Machinery}} and {{Intelligence}}},
  author = {Turing, A. M.},
  year = {1950},
  month = oct,
  journal = {Mind},
  volume = {LIX},
  number = {236},
  pages = {433--460},
  issn = {0026-4423},
  doi = {10.1093/mind/LIX.236.433},
  urldate = {2025-04-02},
  file = {/home/schn/snap/zotero-snap/common/Zotero/storage/G2DRA7SU/Turing - 1950 - Computing Machinery and Intelligence.pdf;/home/schn/snap/zotero-snap/common/Zotero/storage/LXFVJKSM/TURING - 1950 - I.—COMPUTING MACHINERY AND INTELLIGENCE.pdf;/home/schn/snap/zotero-snap/common/Zotero/storage/3YUZVLGI/986238.html;/home/schn/snap/zotero-snap/common/Zotero/storage/IJGLTCWL/986238.html}
}

@article{vicenteHumansInheritArtificial2023,
  title = {Humans Inherit Artificial Intelligence Biases},
  author = {Vicente, Luc{\'i}a and Matute, Helena},
  year = {2023},
  month = oct,
  journal = {Scientific Reports},
  volume = {13},
  number = {1},
  pages = {15737},
  issn = {2045-2322},
  doi = {10.1038/s41598-023-42384-8},
  urldate = {2025-09-25},
  abstract = {Abstract             Artificial intelligence recommendations are sometimes erroneous and biased. In our research, we hypothesized that people who perform a (simulated) medical diagnostic task assisted by a biased AI system will reproduce the model's bias in their own decisions, even when they move to a context without AI support. In three experiments, participants completed a medical-themed classification task with or without the help of a biased AI system. The biased recommendations by the AI influenced participants' decisions. Moreover, when those participants, assisted by the AI, moved on to perform the task without assistance, they made the same errors as the AI had made during the previous phase. Thus, participants' responses mimicked AI bias even when the AI was no longer making suggestions. These results provide evidence of human inheritance of AI bias.},
  langid = {english},
  file = {/home/schn/snap/zotero-snap/common/Zotero/storage/CBSJUCDL/Vicente et Matute - 2023 - Humans inherit artificial intelligence biases.pdf}
}

@misc{vitali-rosatiManifestePourEtudes2025a,
  title = {Manifeste Pour Des {{{\'E}tudes Critiques}} de l'{{Intelligence Artificielle}}},
  author = {{Vitali-Rosati}, Marcello},
  year = {2025},
  month = apr,
  journal = {Culture num{\'e}rique. Pour une philosophie du num{\'e}rique},
  urldate = {2025-07-15},
  abstract = {Blogue de Marcello Vitali-Rosati},
  langid = {english},
  file = {/home/schn/snap/zotero-snap/common/Zotero/storage/EQKI9NVY/manifeste-ecia.html}
}

@misc{wangComprehensiveSurveyGrammar2020,
  title = {A {{Comprehensive Survey}} of {{Grammar Error Correction}}},
  author = {Wang, Yu and Wang, Yuelin and Liu, Jie and Liu, Zhuo},
  year = {2020},
  month = may,
  number = {arXiv:2005.06600},
  eprint = {2005.06600},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2005.06600},
  urldate = {2025-09-10},
  abstract = {Grammar error correction (GEC) is an important application aspect of natural language processing techniques. The past decade has witnessed significant progress achieved in GEC for the sake of increasing popularity of machine learning and deep learning, especially in late 2010s when near human-level GEC systems are available. However, there is no prior work focusing on the whole recapitulation of the progress. We present the first survey in GEC for a comprehensive retrospect of the literature in this area. We first give the introduction of five public datasets, data annotation schema, two important shared tasks and four standard evaluation metrics. More importantly, we discuss four kinds of basic approaches, including statistical machine translation based approach, neural machine translation based approach, classification based approach and language model based approach, six commonly applied performance boosting techniques for GEC systems and two data augmentation methods. Since GEC is typically viewed as a sister task of machine translation, many GEC systems are based on neural machine translation (NMT) approaches, where the neural sequence-to-sequence model is applied. Similarly, some performance boosting techniques are adapted from machine translation and are successfully combined with GEC systems for enhancement on the final performance. Furthermore, we conduct an analysis in level of basic approaches, performance boosting techniques and integrated GEC systems based on their experiment results respectively for more clear patterns and conclusions. Finally, we discuss five prospective directions for future GEC researches.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/schn/snap/zotero-snap/common/Zotero/storage/5DSB6USV/Wang et al. - 2020 - A Comprehensive Survey of Grammar Error Correction.pdf;/home/schn/snap/zotero-snap/common/Zotero/storage/9PJFD44K/2005.html;/home/schn/snap/zotero-snap/common/Zotero/storage/VFBJB6PA/2005.html}
}

@inproceedings{yoshimuraReferencelessSubMetricsOptimized2020,
  title = {{{SOME}}: {{Reference-less Sub-Metrics Optimized}} for {{Manual Evaluations}} of {{Grammatical Error Correction}}},
  shorttitle = {{{SOME}}},
  booktitle = {Proceedings of the 28th {{International Conference}} on {{Computational Linguistics}}},
  author = {Yoshimura, Ryoma and Kaneko, Masahiro and Kajiwara, Tomoyuki and Komachi, Mamoru},
  editor = {Scott, Donia and Bel, Nuria and Zong, Chengqing},
  year = {2020},
  month = dec,
  pages = {6516--6522},
  publisher = {International Committee on Computational Linguistics},
  address = {Barcelona, Spain (Online)},
  doi = {10.18653/v1/2020.coling-main.573},
  urldate = {2025-09-30},
  abstract = {We propose a reference-less metric trained on manual evaluations of system outputs for grammatical error correction (GEC). Previous studies have shown that reference-less metrics are promising; however, existing metrics are not optimized for manual evaluations of the system outputs because no dataset of the system output exists with manual evaluation. This study manually evaluates outputs of GEC systems to optimize the metrics. Experimental results show that the proposed metric improves correlation with the manual evaluation in both system- and sentence-level meta-evaluation. Our dataset and metric will be made publicly available.},
  file = {/home/schn/snap/zotero-snap/common/Zotero/storage/Z3QJHWLZ/Yoshimura et al. - 2020 - SOME Reference-less Sub-Metrics Optimized for Manual Evaluations of Grammatical Error Correction.pdf}
}
